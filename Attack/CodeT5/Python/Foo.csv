#LINE# #TAB# if c < 0: #LINE# #TAB# #TAB# return False #LINE# #TAB# if c == '\x00': #LINE# #TAB# #TAB# return True #LINE# #TAB# if c == '\x1b': #LINE# #TAB# #TAB# return True #LINE# #TAB# return False
"#LINE# #TAB# gr_low = float(ctypes.c_float)() #LINE# #TAB# gr_upper = float(ctypes.c_float)() #LINE# #TAB# _foo(ctypes.c_void_p(p_state), gr_low, gr_upper, ctypes.c_int(idx_image), #LINE# #TAB# #TAB# ctypes.c_int(idx_chain)) #LINE# #TAB# return gr_low, gr_upper"
"#LINE# #TAB# command_name = argv[0] #LINE# #TAB# if not command_name.endswith('.py'): #LINE# #TAB# #TAB# command_name += '.py' #LINE# #TAB# args = argv[1:] #LINE# #TAB# return command_name, args"
#LINE# #TAB# raw_str = str(raw) #LINE# #TAB# assert len(raw_str) == 17 #LINE# #TAB# header_len = 2 #LINE# #TAB# if raw_str[header_len] == 252: #LINE# #TAB# #TAB# header_len = 4 #LINE# #TAB# return raw_str[header_len:]
#LINE# #TAB# if gain >= 1: #LINE# #TAB# #TAB# return str(gain) + '.' + str(peak) #LINE# #TAB# else: #LINE# #TAB# #TAB# return ''
"#LINE# #TAB# if isinstance(e, urllib.error.HTTPError) and e.code in ('503', '408', '500' #LINE# #TAB# #TAB# ): #LINE# #TAB# #TAB# return True #LINE# #TAB# if isinstance(e, BadStatusLine): #LINE# #TAB# #TAB# return True #LINE# #TAB# return False"
#LINE# #TAB# try: #LINE# #TAB# #TAB# ct = page.headers['Content-Type'] #LINE# #TAB# except KeyError: #LINE# #TAB# #TAB# ct = page.headers['Content-Type'] #LINE# #TAB# return ct
"#LINE# #TAB# if cut: #LINE# #TAB# #TAB# value = float(value) #LINE# #TAB# elif maximum: #LINE# #TAB# #TAB# value = float(maximum) #LINE# #TAB# if minimum: #LINE# #TAB# #TAB# if isinstance(value, (int, float)): #LINE# #TAB# #TAB# #TAB# return int(value) #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# return float(value) #LINE# #TAB# elif pad: #LINE# #TAB# #TAB# return value #LINE# #TAB# else: #LINE# #TAB# #TAB# return value"
#LINE# #TAB# if dist.name in cls.depends: #LINE# #TAB# #TAB# for package in cls.depends[dist.name]: #LINE# #TAB# #TAB# #TAB# yield package
"#LINE# #TAB# x = np.mean(signal[np.isfinite(signal)]) #LINE# #TAB# y = np.mean(signal[:, (np.isfinite(signal))]) #LINE# #TAB# dx = (x - x[np.isfinite(signal)]) / 2 #LINE# #TAB# h = (y - y[np.isfinite(signal)]) / 2 #LINE# #TAB# return x, y, h"
#LINE# #TAB# out = ctx.out_object #LINE# #TAB# return out
"#LINE# #TAB# auth_user = getpass.getuser() #LINE# #TAB# auth_pass = getpass.getpass('powershell:auth_token:') #LINE# #TAB# client = keystonev2.Client(auth_user=auth_user, auth_pass=auth_pass) #LINE# #TAB# return client.root"
#LINE# #TAB# out = [] #LINE# #TAB# for d in delims: #LINE# #TAB# #TAB# if d in txt: #LINE# #TAB# #TAB# #TAB# out.append(txt[d:]) #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# break #LINE# #TAB# return out
"#LINE# #TAB# try: #LINE# #TAB# #TAB# bool_str = str_2_bool(raw_input(prompt)) #LINE# #TAB# except PipelineError: #LINE# #TAB# #TAB# print( #LINE# #TAB# #TAB# #TAB# ""'{0}' did not match a boolean expression (true/false, yes/no, t/f, y/n)"" #LINE# #TAB# #TAB# #TAB#.format(bool_str)) #LINE# #TAB# #TAB# return False #LINE# #TAB# return bool_str"
"#LINE# #TAB# opts = 'x' #LINE# #TAB# if verbosity > 1: #LINE# #TAB# #TAB# opts += 'v' #LINE# #TAB# opts += ""w=%s"" % outdir #LINE# #TAB# return [cmd, opts, archive]"
"#LINE# #TAB# with open('/dev/null', 'w') as foo_null: #LINE# #TAB# #TAB# try: #LINE# #TAB# #TAB# #TAB# ret = foo_null.read() #LINE# #TAB# #TAB# #TAB# foo_null.close() #LINE# #TAB# #TAB# #TAB# return ret #LINE# #TAB# #TAB# except: #LINE# #TAB# #TAB# #TAB# return None"
#LINE# #TAB# forest = get_spanning_ forest(graph) #LINE# #TAB# tree_list = [] #LINE# #TAB# for node in forest: #LINE# #TAB# #TAB# if graph.degree(node) == 1: #LINE# #TAB# #TAB# #TAB# tree_list.append(node) #LINE# #TAB# for i in range(len(tree_list)): #LINE# #TAB# #TAB# if graph.degree(node) == 2: #LINE# #TAB# #TAB# #TAB# graph.remove_node(tree_list[i]) #LINE# #TAB# return tree_list
#LINE# #TAB# result = [] #LINE# #TAB# for f in os.listdir(str(Path.home())): #LINE# #TAB# #TAB# if name_only: #LINE# #TAB# #TAB# #TAB# try: #LINE# #TAB# #TAB# #TAB# #TAB# obj = json.loads(f) #LINE# #TAB# #TAB# #TAB# except ValueError: #LINE# #TAB# #TAB# #TAB# #TAB# continue #LINE# #TAB# #TAB# #TAB# if obj['id']!= '__all__': #LINE# #TAB# #TAB# #TAB# #TAB# result.append(obj) #LINE# #TAB# return result
"#LINE# #TAB# if not isinstance(objects, allowed_type): #LINE# #TAB# #TAB# raise TypeError(""{} must be a {}"".format(name, type(objects))) #LINE# #TAB# if allow_none: #LINE# #TAB# #TAB# allowed_type = type(None) #LINE# #TAB# for obj in objects: #LINE# #TAB# #TAB# if obj is None: #LINE# #TAB# #TAB# #TAB# continue #LINE# #TAB# #TAB# if not issubclass(obj, allowed_type): #LINE# #TAB# #TAB# #TAB# raise TypeError(""{} must be {}"".format(name, type(obj))) #LINE# #TAB# return objects"
#LINE# #TAB# if q == 0.0: #LINE# #TAB# #TAB# return 0.0 #LINE# #TAB# elif q == 1.0: #LINE# #TAB# #TAB# return width * length * gravity #LINE# #TAB# elif q == 2.0: #LINE# #TAB# #TAB# return width * gravity / 100.0 #LINE# #TAB# elif q == 3.0: #LINE# #TAB# #TAB# return length * gravity / 100.0 #LINE# #TAB# else: #LINE# #TAB# #TAB# return 0.0
"#LINE# #TAB# apps = [] #LINE# #TAB# with open('dever_config.py', 'r') as f: #LINE# #TAB# #TAB# lines = f.readlines() #LINE# #TAB# for line in lines: #LINE# #TAB# #TAB# if not line.startswith('#'): #LINE# #TAB# #TAB# #TAB# try: #LINE# #TAB# #TAB# #TAB# #TAB# app = line.split('.')[0] #LINE# #TAB# #TAB# #TAB# #TAB# apps.append(app) #LINE# #TAB# #TAB# #TAB# except: #LINE# #TAB# #TAB# #TAB# #TAB# pass #LINE# #TAB# return apps"
"#LINE# #TAB# with open(file_path, 'r') as f: #LINE# #TAB# #TAB# data = json.load(f) #LINE# #TAB# return data"
"#LINE# #TAB# field_name = lookup_path.split('__', 1)[0] #LINE# #TAB# field = opts.get_field(field_name) #LINE# #TAB# if hasattr(field,'rel') and isinstance(field.rel, models.ManyToManyRel #LINE# #TAB# #TAB# ) or isinstance(field, models.related.RelatedObject #LINE# #TAB# #TAB# ) and not field.field.unique: #LINE# #TAB# #TAB# return True #LINE# #TAB# return False"
#LINE# #TAB# old_app = app #LINE# #TAB# while old_app is not None: #LINE# #TAB# #TAB# try: #LINE# #TAB# #TAB# #TAB# old_app = old_app.celery #LINE# #TAB# #TAB# except AttributeError: #LINE# #TAB# #TAB# #TAB# pass #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# break #LINE# #TAB# return old_app
"#LINE# #TAB# if country not in COUNTRIES: #LINE# #TAB# #TAB# raise ValueError('{} not in country {}'.format(country, COUNTRIES[country])) #LINE# #TAB# d = d.replace('-', '') #LINE# #TAB# d = d.replace(hour=4, minute=2, second=2) #LINE# #TAB# d = d.replace(minute=3, second=4) #LINE# #TAB# return d"
#LINE# #TAB# if fields == ALL: #LINE# #TAB# #TAB# fields = allowed_fields.keys() #LINE# #TAB# else: #LINE# #TAB# #TAB# fields = tuple(fields) #LINE# #TAB# #TAB# unknown_fields = set(fields) - allowed_fields.keys() #LINE# #TAB# #TAB# if unknown_fields: #LINE# #TAB# #TAB# #TAB# raise ValueError('Unknown fields: {}'.format(unknown_fields)) #LINE# #TAB# return fields
"#LINE# #TAB# if isinstance(version, str): #LINE# #TAB# #TAB# try: #LINE# #TAB# #TAB# #TAB# LooseVersion(version) #LINE# #TAB# #TAB# except ValueError: #LINE# #TAB# #TAB# #TAB# return False #LINE# #TAB# #TAB# return True #LINE# #TAB# else: #LINE# #TAB# #TAB# return False"
"#LINE# #TAB# header_record = HeaderRecord() #LINE# #TAB# header_record.name = file_name #LINE# #TAB# header_record.value = row[0] #LINE# #TAB# header_record.date = datetime.strptime(header_record.value, #LINE# #TAB# #TAB# '%Y-%m-%d %H:%M:%S') #LINE# #TAB# return header_record"
"#LINE# #TAB# #TAB# data = [] #LINE# #TAB# #TAB# for col in row: #LINE# #TAB# #TAB# #TAB# try: #LINE# #TAB# #TAB# #TAB# #TAB# if re.match(tag, col): #LINE# #TAB# #TAB# #TAB# #TAB# #TAB# data.append(col) #LINE# #TAB# #TAB# #TAB# except AttributeError: #LINE# #TAB# #TAB# #TAB# #TAB# data.append(col) #LINE# #TAB# #TAB# return data"
#LINE# #TAB# global McQuillanRotation periods #LINE# #TAB# return McQuillanRotation periods
#LINE# #TAB# N = len(observations) #LINE# #TAB# if lag < 1: #LINE# #TAB# #TAB# raise Exception('lag must be greater than 1') #LINE# #TAB# indexes = np.arange(N) #LINE# #TAB# new_observations = np.empty(observations.shape) #LINE# #TAB# for i in range(N): #LINE# #TAB# #TAB# new_observations[i - lag] = observations[i - lag] #LINE# #TAB# for i in range(N - lag): #LINE# #TAB# #TAB# new_observations[i] = observations[i - lag + stride:i + stride + 1] #LINE# #TAB# return new_observations
"#LINE# #TAB# if call == 'action': #LINE# #TAB# #TAB# raise SaltCloudSystemExit( #LINE# #TAB# #TAB# #TAB# 'The foo function must be called with'#LINE# #TAB# #TAB# #TAB# '-f or --function, or with the --list-nodes option' #LINE# #TAB# #TAB# ) #LINE# #TAB# if session is None: #LINE# #TAB# #TAB# session = get_session() #LINE# #TAB# ret = {} #LINE# #TAB# for item in session.foo(name): #LINE# #TAB# #TAB# ret[item[0]] = item[1] #LINE# #TAB# return ret"
"#LINE# #TAB# db = firestore.client() #LINE# #TAB# res = db.login(username, password) #LINE# #TAB# if res == 1: #LINE# #TAB# #TAB# return False #LINE# #TAB# else: #LINE# #TAB# #TAB# return True"
"#LINE# #TAB# if verb == 'full': #LINE# #TAB# #TAB# if time.ndim == 1: #LINE# #TAB# #TAB# #TAB# signal = signal[:, (None)] #LINE# #TAB# #TAB# if signal.ndim == 1: #LINE# #TAB# #TAB# #TAB# time = signal[:, (None)] #LINE# #TAB# #TAB# if not np.all(time): #LINE# #TAB# #TAB# #TAB# raise ValueError('Time and signal do not match.') #LINE# #TAB# elif verb!= 'both': #LINE# #TAB# #TAB# if not np.all(signal): #LINE# #TAB# #TAB# #TAB# raise ValueError('Signal and time do not match.') #LINE# #TAB# return time, signal"
"#LINE# #TAB# if encoding is None: #LINE# #TAB# #TAB# encoding = 'utf-8' #LINE# #TAB# el = etree.Element(doc, encoding=encoding) #LINE# #TAB# return el"
#LINE# #TAB# sum_ = 0 #LINE# #TAB# window = 0 #LINE# #TAB# for i in range(len(data)): #LINE# #TAB# #TAB# if i >= window_len: #LINE# #TAB# #TAB# #TAB# break #LINE# #TAB# #TAB# sum_ += data[i] #LINE# #TAB# #TAB# window += data[i] #LINE# #TAB# return sum_
#LINE# #TAB# a = (max1 - min1) / (max1 - min2) #LINE# #TAB# b = (max2 - min2) / (a + b) #LINE# #TAB# c = 0 #LINE# #TAB# try: #LINE# #TAB# #TAB# return (a - b) * 100 #LINE# #TAB# except ZeroDivisionError: #LINE# #TAB# #TAB# return 0
"#LINE# #TAB# return os.path.exists(os.path.join(directory, cache_file_path) #LINE# #TAB# #TAB# ) and os.path.getmtime(os.path.join(directory, cache_file_path)) <= cache_mtime"
#LINE# #TAB# if name is None: #LINE# #TAB# #TAB# name = operator() #LINE# #TAB# return get_operator_name(name)[0]
#LINE# #TAB# return [partition_dict['name'] for partition_dict in partition_dicts #LINE# #TAB# #TAB# ]
#LINE# #TAB# try: #LINE# #TAB# #TAB# return array[idx_col] #LINE# #TAB# except: #LINE# #TAB# #TAB# return np.nan
#LINE# #TAB# for path in paths: #LINE# #TAB# #TAB# if not os.path.exists(path): #LINE# #TAB# #TAB# #TAB# return False #LINE# #TAB# return True
"#LINE# #TAB# ret = {'name': name, #LINE# #TAB# #TAB# 'changes': {}, #LINE# #TAB# #TAB#'result': None, #LINE# #TAB# #TAB# 'comment': ''} #LINE# #TAB# if __opts__['test']: #LINE# #TAB# #TAB# ret['comment'] = 'Running traffic_manager process on all nodes in the cluster' #LINE# #TAB# #TAB# return ret #LINE# #TAB# __salt__['traffic_server.restart']() #LINE# #TAB# ret['result'] = True #LINE# #TAB# ret['comment'] = 'Failed to restart traffic_server process on all nodes in the cluster' #LINE# #TAB# return ret"
#LINE# #TAB# module_name = handler_name[3:] #LINE# #TAB# if '.' in module_name: #LINE# #TAB# #TAB# module = importlib.import_module(module_name) #LINE# #TAB# else: #LINE# #TAB# #TAB# module = importlib.import_module(module_name) #LINE# #TAB# return module
#LINE# #TAB# global _tool_registry #LINE# #TAB# if _tool_registry is None: #LINE# #TAB# #TAB# _tool_registry = get_tool_registry() #LINE# #TAB# return _tool_registry
#LINE# #TAB# if field.value() =='store': #LINE# #TAB# #TAB# return'store' #LINE# #TAB# else: #LINE# #TAB# #TAB# return'store'
"#LINE# #TAB# if boatd is None: #LINE# #TAB# #TAB# boatd = Boatd() #LINE# #TAB# content = boatd.get('/waypoints') #LINE# #TAB# return [Point(float(x), float(y)) for x, y in content.get('waypoints')]"
#LINE# #TAB# path = os.path.dirname(os.path.realpath(__file__)) #LINE# #TAB# os.mkdir(path) #LINE# #TAB# return path
"#LINE# #TAB# frag_dict = {} #LINE# #TAB# with open(fastafile) as f: #LINE# #TAB# #TAB# for line in f: #LINE# #TAB# #TAB# #TAB# if line.startswith('>'): #LINE# #TAB# #TAB# #TAB# #TAB# continue #LINE# #TAB# #TAB# #TAB# fragment_id = line.strip().split("" "")[1] #LINE# #TAB# #TAB# #TAB# frag_lengths[fragment_id] = len(line.split("" "")[0]) #LINE# #TAB# return frag_dict"
"#LINE# #TAB# with open('/sys/class/devices/counter', 'r') as f: #LINE# #TAB# #TAB# devices = int(f.read()) #LINE# #TAB# return devices"
"#LINE# #TAB# psi = 0 #LINE# #TAB# valid = T == 298.15 #LINE# #TAB# return psi, valid"
"#LINE# #TAB# result = [] #LINE# #TAB# for key in dict: #LINE# #TAB# #TAB# result.append(('namevalue', key)) #LINE# #TAB# return result"
"#LINE# #TAB# if filename.endswith('.py'): #LINE# #TAB# #TAB# return True #LINE# #TAB# try: #LINE# #TAB# #TAB# with open(filename, 'r') as f: #LINE# #TAB# #TAB# #TAB# first_line = f.readline().strip() #LINE# #TAB# #TAB# return first_line.startswith('#') #LINE# #TAB# except IOError: #LINE# #TAB# #TAB# return False"
"#LINE# #TAB# contrib_type = ""author non-byline"" #LINE# #TAB# contributors_ = contributors(soup, detail) #LINE# #TAB# non_byline_authors = [author for author in contributors_ if author.get( #LINE# #TAB# #TAB# 'type', None) == contrib_type] #LINE# #TAB# position = 1 #LINE# #TAB# for author in non_byline_authors: #LINE# #TAB# #TAB# author['position'] = position #LINE# #TAB# #TAB# position = position + 1 #LINE# #TAB# return non_byline_authors"
"#LINE# #TAB# from.modules import browserify #LINE# #TAB# if not babelify: #LINE# #TAB# #TAB# return {'dependencies_fn': browserify.browserify_deps_entry_point, 'compiler_fn': #LINE# #TAB# #TAB# #TAB# browserify.browserify_compile_script, 'input': entry_point, 'output': output_file, #LINE# #TAB# #TAB# #TAB# 'export_as': export_as} #LINE# #TAB# return {'dependencies_fn': browserify.browserify_deps_entry_point, 'compiler_fn': #LINE# #TAB# #TAB# browserify.browserify_compile_script, 'input': entry_point, 'output': output_file}"
"#LINE# #TAB# result = [] #LINE# #TAB# for c1 in barcode: #LINE# #TAB# #TAB# for c2 in barcode: #LINE# #TAB# #TAB# #TAB# if c1 == c2: #LINE# #TAB# #TAB# #TAB# #TAB# result.append(('4', barcode)) #LINE# #TAB# #TAB# #TAB# #TAB# result.append(('5', barcode)) #LINE# #TAB# #TAB# #TAB# elif c1 == c2: #LINE# #TAB# #TAB# #TAB# #TAB# result.append('6', barcode)) #LINE# #TAB# #TAB# #TAB# #TAB# result.append(('7', barcode)) #LINE# #TAB# return result"
#LINE# #TAB# result = MarkovMatrix() #LINE# #TAB# for i in range(m[0]): #LINE# #TAB# #TAB# for j in range(m[1]): #LINE# #TAB# #TAB# #TAB# result.flow[i][j] = m[2][j] #LINE# #TAB# #TAB# result.flow[i][j] = m[3][j] #LINE# #TAB# return result
"#LINE# #TAB# Operator = fields.SQL_OPERATORS[clause[1]] #LINE# #TAB# tab_sql = cls.get_sql_table() #LINE# #TAB# qu1 = tab_sql.select(tab_sql.id_line, where=Operator(tab_sql.party, #LINE# #TAB# #TAB# clause[2])) #LINE# #TAB# return [('id', 'in', qu1)]"
"#LINE# #TAB# if not file_to_align.endswith('.fa'): #LINE# #TAB# #TAB# file_to_align = '.fa' #LINE# #TAB# clustered_fn = file_to_align + '.align' #LINE# #TAB# cmd ='mafft -c {0} -o {1}'.format(clustered_fn, file_to_align) #LINE# #TAB# process = subprocess.Popen(cmd, stdout=subprocess.PIPE) #LINE# #TAB# stdout, stderr = process.communicate() #LINE# #TAB# if process.returncode!= 0: #LINE# #TAB# #TAB# logger.error(stderr) #LINE# #TAB# #TAB# return None #LINE# #TAB# return stdout"
"#LINE# #TAB# encoded = value #LINE# #TAB# if isinstance(encoded, six.string_types): #LINE# #TAB# #TAB# encoded = encoded.encode('$') #LINE# #TAB# if isinstance(encoded, tuple): #LINE# #TAB# #TAB# return encoded #LINE# #TAB# return encoded"
#LINE# #TAB# if forum.moderate_topics == 0: #LINE# #TAB# #TAB# return 1 #LINE# #TAB# elif forum.moderate_topics == 1: #LINE# #TAB# #TAB# return 0 #LINE# #TAB# else: #LINE# #TAB# #TAB# return 1
"#LINE# #TAB# if isinstance(array, list): #LINE# #TAB# #TAB# if len(array) == 1: #LINE# #TAB# #TAB# #TAB# return True #LINE# #TAB# else: #LINE# #TAB# #TAB# return False"
"#LINE# #TAB# return {'__kind__': kind_inst, 'class': fqname_for(v.__class__), 'args': #LINE# #TAB# #TAB# encode([str(v)])}"
"#LINE# #TAB# return { #LINE# #TAB# #TAB# 'id': 0, #LINE# #TAB# #TAB# 'links': [{ #LINE# #TAB# #TAB# #TAB# 'type': 'category', #LINE# #TAB# #TAB# #TAB# 'value': 1, #LINE# #TAB# #TAB# #TAB# 'title': 'hello foo' #LINE# #TAB# #TAB# }, #LINE# #TAB# #TAB# 'tags': [{ #LINE# #TAB# #TAB# #TAB# 'type': 'category', #LINE# #TAB# #TAB# #TAB# 'name': 'hello foo' #LINE# #TAB# #TAB# }, #LINE# #TAB# #TAB# 'tags': [{ #LINE# #TAB# #TAB# #TAB# 'type': 'category', #LINE# #TAB# #TAB# #TAB# 'value': 'hello foo' #LINE# #TAB# #TAB# }, #LINE# #TAB# #TAB# 'tags': [] #LINE# #TAB# }]"
#LINE# #TAB# try: #LINE# #TAB# #TAB# return repo.get_branch('.').split('/')[-1] #LINE# #TAB# except IndexError: #LINE# #TAB# #TAB# return'master'
"#LINE# #TAB# edges = {} #LINE# #TAB# for edge_identifier, node in graph_object.edges(data=True): #LINE# #TAB# #TAB# edge_type = graph_object.node[edge_identifier].graph_type #LINE# #TAB# #TAB# if edge_type == GOcats_LEAF: #LINE# #TAB# #TAB# #TAB# edges[edge_identifier] = node #LINE# #TAB# #TAB# elif edge_type == GOcats_MEAF: #LINE# #TAB# #TAB# #TAB# edges[edge_identifier] = node #LINE# #TAB# #TAB# elif edge_type == GOcats_MEAF: #LINE# #TAB# #TAB# #TAB# edges[edge_identifier] = node #LINE# #TAB# return edges"
"#LINE# #TAB# client = foo(descriptor) #LINE# #TAB# if not client: #LINE# #TAB# #TAB# return None, None #LINE# #TAB# try: #LINE# #TAB# #TAB# client.accept() #LINE# #TAB# except Exception as e: #LINE# #TAB# #TAB# raise e #LINE# #TAB# return client, descriptor.address"
"#LINE# #TAB# quat = np.array([[1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0], [0.0, -1.0, 0.0, 0.0]]) #LINE# #TAB# transform = Transform() #LINE# #TAB# transform.set_dual_quat(dual_quat) #LINE# #TAB# return transform"
"#LINE# #TAB# if hasattr(blocks, '_values'): #LINE# #TAB# #TAB# return blocks._values #LINE# #TAB# elif hasattr(blocks, '__iter__'): #LINE# #TAB# #TAB# return np.vstack([blocks._values]).T #LINE# #TAB# else: #LINE# #TAB# #TAB# return blocks"
#LINE# #TAB# new = [] #LINE# #TAB# i = 0 #LINE# #TAB# while True: #LINE# #TAB# #TAB# try: #LINE# #TAB# #TAB# #TAB# while True: #LINE# #TAB# #TAB# #TAB# #TAB# d = a.pop(i) #LINE# #TAB# #TAB# #TAB# #TAB# new.append(d) #LINE# #TAB# #TAB# #TAB# #TAB# i += 1 #LINE# #TAB# #TAB# except IndexError: #LINE# #TAB# #TAB# #TAB# break #LINE# #TAB# return new
#LINE# #TAB# #TAB# result = {} #LINE# #TAB# #TAB# if previous_object is not None: #LINE# #TAB# #TAB# #TAB# result = previous_object.foo(attributes) #LINE# #TAB# #TAB# return result
"#LINE# #TAB# settings = current_app.config.get('RESTFUL_JSON', {}) #LINE# #TAB# if current_app.debug: #LINE# #TAB# #TAB# settings.setdefault('indent', 4) #LINE# #TAB# #TAB# settings.setdefault('sort_keys', not PY3) #LINE# #TAB# dumped = dumps(data, **settings) + '\n' #LINE# #TAB# resp = make_response(dumped, code) #LINE# #TAB# resp.headers.extend(headers or {}) #LINE# #TAB# return resp"
"#LINE# #TAB# subdomain_df = subdomain_df.drop('index', axis=1) #LINE# #TAB# subdomain_df.loc[:, ('subdomain')] = subdomain_df.loc[:, ('subdomain') #LINE# #TAB# #TAB# ].astype(int) #LINE# #TAB# return subdomain_df"
"#LINE# #TAB# key = base64.b32decode(key) #LINE# #TAB# if len(key)!= 32: #LINE# #TAB# #TAB# raise ValueError('invalid key length %d' % len(key)) #LINE# #TAB# for char in key: #LINE# #TAB# #TAB# if char not in (' ', '_'): #LINE# #TAB# #TAB# #TAB# break #LINE# #TAB# else: #LINE# #TAB# #TAB# raise ValueError('invalid char %d' % char) #LINE# #TAB# return key"
"#LINE# #TAB# psi = 0.0 #LINE# #TAB# valid = T == 298.15 #LINE# #TAB# return psi, valid"
#LINE# #TAB# ret = conn.list_vms() #LINE# #TAB# for node in ret: #LINE# #TAB# #TAB# if node['name'] == name: #LINE# #TAB# #TAB# #TAB# return node #LINE# #TAB# return None
#LINE# #TAB# assert imgcol.schema == collection.schema #LINE# #TAB# assert date.year == date.year #LINE# #TAB# img = imgcol.create_image(date.strftime('%Y-%m-%d')) #LINE# #TAB# if validate: #LINE# #TAB# #TAB# img.validate() #LINE# #TAB# return img
"#LINE# #TAB# if re.search('search\\s*\\[', line): #LINE# #TAB# #TAB# return True"
#LINE# #TAB# for line in lines: #LINE# #TAB# #TAB# for sequence in color_sequences(line): #LINE# #TAB# #TAB# #TAB# if sequence[-1] == '\\': #LINE# #TAB# #TAB# #TAB# #TAB# line += reset #LINE# #TAB# #TAB# yield line
#LINE# #TAB# import pytz #LINE# #TAB# d = pytz.timezone(tz) #LINE# #TAB# d = d.localize(relPeriod) #LINE# #TAB# d = d.astimezone(pytz.UTC) #LINE# #TAB# return d
"#LINE# #TAB# with h5py.File(path, 'r') as hf5: #LINE# #TAB# #TAB# model = hf5['model'] #LINE# #TAB# return model"
"#LINE# #TAB# return os.environ.get('COCOTB_ANSI_OUTPUT', 1) == 1 if os.environ.get( #LINE# #TAB# #TAB# 'COCOTB_ANSI_OUTPUT', '1') else False"
#LINE# #TAB# try: #LINE# #TAB# #TAB# float(s) #LINE# #TAB# #TAB# return True #LINE# #TAB# except ValueError: #LINE# #TAB# #TAB# return False
"#LINE# #TAB# c = convert_color(c) #LINE# #TAB# if c[0] == '#': #LINE# #TAB# #TAB# r = 1 #LINE# #TAB# #TAB# g = 1 #LINE# #TAB# #TAB# b = 1 #LINE# #TAB# else: #LINE# #TAB# #TAB# r = c[0] #LINE# #TAB# #TAB# g = c[1] #LINE# #TAB# #TAB# b = c[2] #LINE# #TAB# return r, g, b, 1"
"#LINE# #TAB# assert len(X.shape) == 2 #LINE# #TAB# n = X.shape[1] #LINE# #TAB# res = np.zeros((n, n)) #LINE# #TAB# for i in range(1, n): #LINE# #TAB# #TAB# for j in range(1, n): #LINE# #TAB# #TAB# #TAB# res[i, j] = foo(X[i, :, (j)], w, theta) #LINE# #TAB# return res"
"#LINE# #TAB# if dd.get_coverage_interval(data) == ""genome"": #LINE# #TAB# #TAB# return [[data]] #LINE# #TAB# else: #LINE# #TAB# #TAB# return data"
#LINE# #TAB# val = analysis_fields.copy() #LINE# #TAB# val[1] = 0 #LINE# #TAB# for field in analysis_fields: #LINE# #TAB# #TAB# if field in data_frame.columns: #LINE# #TAB# #TAB# #TAB# val[1] += 1 #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# val[1] = 0 #LINE# #TAB# return val
#LINE# #TAB# if key == 'radius': #LINE# #TAB# #TAB# try: #LINE# #TAB# #TAB# #TAB# r = float(radius) / 100 #LINE# #TAB# #TAB# #TAB# return r #LINE# #TAB# #TAB# except: #LINE# #TAB# #TAB# #TAB# print('Error: %s is not a valid radius value' % key) #LINE# #TAB# #TAB# #TAB# return None #LINE# #TAB# else: #LINE# #TAB# #TAB# return None
#LINE# #TAB# if site is None: #LINE# #TAB# #TAB# site = pywikibot.Site() #LINE# #TAB# for page in site.pages(total=total): #LINE# #TAB# #TAB# yield page
"#LINE# #TAB# try: #LINE# #TAB# #TAB# with open(LOGIN_URL, 'r') as f: #LINE# #TAB# #TAB# #TAB# username = f.readline().strip() #LINE# #TAB# #TAB# #TAB# password = f.readline().strip() #LINE# #TAB# #TAB# return username, password #LINE# #TAB# except Exception: #LINE# #TAB# #TAB# return None, None"
"#LINE# #TAB# disk = os.path.dirname(os.path.abspath(__file__)) #LINE# #TAB# temp = cv2.imread(disk, cv2.IMREAD_GRAYSCALE) #LINE# #TAB# temp = cv2.cvtColor(temp, cv2.COLOR_BGR2RGB) #LINE# #TAB# return temp"
"#LINE# #TAB# if isinstance(e.op, BinaryOp): #LINE# #TAB# #TAB# return e.op #LINE# #TAB# if isinstance(e.op, BinaryOp): #LINE# #TAB# #TAB# return e.op #LINE# #TAB# return e"
"#LINE# #TAB# artist.set(**{k: kwargs[k] for k in kwargs if hasattr(artist,'set_' + k)}) #LINE# #TAB# return artist"
#LINE# #TAB# seen = set() #LINE# #TAB# seen_add = seen.add #LINE# #TAB# if iterable: #LINE# #TAB# #TAB# for element in iterable: #LINE# #TAB# #TAB# #TAB# if element not in seen: #LINE# #TAB# #TAB# #TAB# #TAB# seen_add(element) #LINE# #TAB# #TAB# #TAB# #TAB# yield element #LINE# #TAB# else: #LINE# #TAB# #TAB# for element in iterable: #LINE# #TAB# #TAB# #TAB# if filterfalse_(element): #LINE# #TAB# #TAB# #TAB# #TAB# yield element
"#LINE# #TAB# ret = [] #LINE# #TAB# for lib in libs: #LINE# #TAB# #TAB# name = lib[0].replace('.', '_') #LINE# #TAB# #TAB# val = libs[1].replace('.', '_') #LINE# #TAB# #TAB# if len(val) == 1: #LINE# #TAB# #TAB# #TAB# ret.append(name) #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# ret.append(val) #LINE# #TAB# return ret"
#LINE# #TAB# if value is True: #LINE# #TAB# #TAB# return 'TRUE' #LINE# #TAB# else: #LINE# #TAB# #TAB# return 'FALSE'
#LINE# #TAB# try: #LINE# #TAB# #TAB# if as_id == '127.0.0.1': #LINE# #TAB# #TAB# #TAB# as_id = socket.gethostbyname(socket.gethostname()) #LINE# #TAB# #TAB# return as_id #LINE# #TAB# except socket.error: #LINE# #TAB# #TAB# pass #LINE# #TAB# return as_id
"#LINE# #TAB# if opts is None: #LINE# #TAB# #TAB# opts = {} #LINE# #TAB# mode = 'r' #LINE# #TAB# if path.endswith('/'): #LINE# #TAB# #TAB# path = path[:-1] #LINE# #TAB# #TAB# mode = path[:-1] #LINE# #TAB# try: #LINE# #TAB# #TAB# f = open(path, mode) #LINE# #TAB# #TAB# result = f.read() #LINE# #TAB# finally: #LINE# #TAB# #TAB# if mode == 'r': #LINE# #TAB# #TAB# #TAB# f.close() #LINE# #TAB# else: #LINE# #TAB# #TAB# pass"
#LINE# #TAB# global _max_measurements #LINE# #TAB# _max_measurements = limit
#LINE# #TAB# api = get_api() #LINE# #TAB# _url = api +'repos/' + orgrepo + '/fork' #LINE# #TAB# try: #LINE# #TAB# #TAB# response = api.get(_url) #LINE# #TAB# #TAB# if response.status_code == 200: #LINE# #TAB# #TAB# #TAB# return True #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# return False #LINE# #TAB# except requests.exceptions.RequestException: #LINE# #TAB# #TAB# return False
#LINE# #TAB# col = get_color(colorname) #LINE# #TAB# col = list(col) #LINE# #TAB# col[3] = alpha #LINE# #TAB# return [int(x * 255) for x in col]
"#LINE# #TAB# user = default_user #LINE# #TAB# port = default_port #LINE# #TAB# if '@' in host_string: #LINE# #TAB# #TAB# user, host = host_string.split('@', 1) #LINE# #TAB# if ':' in host: #LINE# #TAB# #TAB# host, port = host.rsplit(':', 1) #LINE# #TAB# return [(host.strip(), port.strip())]"
#LINE# #TAB# r = [] #LINE# #TAB# try: #LINE# #TAB# #TAB# l = f.readline() #LINE# #TAB# #TAB# for l in l.split('\n'): #LINE# #TAB# #TAB# #TAB# if '#' in l: #LINE# #TAB# #TAB# #TAB# #TAB# pass #LINE# #TAB# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# #TAB# r.append(l) #LINE# #TAB# except IOError: #LINE# #TAB# #TAB# pass #LINE# #TAB# return r
"#LINE# #TAB# try: #LINE# #TAB# #TAB# x, y = float(f), float(f) #LINE# #TAB# except: #LINE# #TAB# #TAB# return f, 0 #LINE# #TAB# else: #LINE# #TAB# #TAB# return x, y"
"#LINE# #TAB# if not isinstance(value, list): #LINE# #TAB# #TAB# raise vol.Invalid(value) #LINE# #TAB# if len(value)!= 3: #LINE# #TAB# #TAB# raise vol.Invalid(value) #LINE# #TAB# return value"
"#LINE# #TAB# result = None #LINE# #TAB# if p_date: #LINE# #TAB# #TAB# parsed_date = re.match(r'(\d{4})-(\d{2})-(\d{2})', p_date) #LINE# #TAB# #TAB# if parsed_date: #LINE# #TAB# #TAB# #TAB# result = date( #LINE# #TAB# #TAB# #TAB# #TAB# int(parsed_date.group(1)), int(parsed_date.group(2)), int( #LINE# #TAB# #TAB# #TAB# #TAB# parsed_date.group(3)) #LINE# #TAB# #TAB# #TAB# ) #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# raise ValueError #LINE# #TAB# return result"
"#LINE# #TAB# if sql_raw_list[0] == 0: #LINE# #TAB# #TAB# return {'id': sql_raw_list[1], 'type': sql_raw_list[2], 'date': #LINE# #TAB# #TAB# #TAB# sql_raw_list[3], 'timestamp': datetime.strptime(sql_raw_list[4], #LINE# #TAB# #TAB# #TAB# '%Y-%m-%dT%H:%M:%S.%f%z')} #LINE# #TAB# else: #LINE# #TAB# #TAB# return {'id': sql_raw_list[0], 'type': sql_raw_list[1], 'date': #LINE# #TAB# #TAB# #TAB# sql_raw_list[2], 'timestamp': datetime.strptime(sql_raw_list[3], #LINE# #TAB# #TAB# #TAB# '%Y-%m-%d %H:%M:%S')}"
"#LINE# #TAB# validate_poly(poly, algorithm) #LINE# #TAB# if not bounds: #LINE# #TAB# #TAB# raise ValueError('bounds is required') #LINE# #TAB# if len(bounds)!= len(poly): #LINE# #TAB# #TAB# raise ValueError('bounds must have the same length') #LINE# #TAB# area = 0 #LINE# #TAB# for b in reversed(bounds): #LINE# #TAB# #TAB# sum_ = sum(poly[b:b + 1]) #LINE# #TAB# #TAB# if sum_ < 0: #LINE# #TAB# #TAB# #TAB# sum_ = -sum_ #LINE# #TAB# #TAB# area += sum_ #LINE# #TAB# return area"
#LINE# #TAB# with _lock: #LINE# #TAB# #TAB# if _in_progress: #LINE# #TAB# #TAB# #TAB# return True #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# return False
#LINE# #TAB# for token in _tokenize(text): #LINE# #TAB# #TAB# if token.isalpha(): #LINE# #TAB# #TAB# #TAB# yield token #LINE# #TAB# #TAB# elif token.isspace(): #LINE# #TAB# #TAB# #TAB# yield token #LINE# #TAB# #TAB# elif token.isalpha(): #LINE# #TAB# #TAB# #TAB# yield token #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# yield text
"#LINE# #TAB# return {'name': 'notebook_zip_download', 'description': #LINE# #TAB# #TAB# 'IPython Notebook bundle (.zip)','version': __version__, #LINE# #TAB# #TAB# 'created_at': str(datetime.utcnow()), 'updated_at': str( #LINE# #TAB# #TAB# datetime.utcnow()), 'deleted': False}"
"#LINE# #TAB# rB = np.zeros((B.shape[0], C.shape[0])) #LINE# #TAB# rC = np.zeros(C.shape[0]) #LINE# #TAB# for i in range(rB.shape[1]): #LINE# #TAB# #TAB# rB[i], rC[i] = projection(B[i, :], C[i, :]) #LINE# #TAB# foo = np.hstack([rB, rC]) #LINE# #TAB# return foo"
"#LINE# #TAB# n = 0 #LINE# #TAB# for i, atom in enumerate(atom_map): #LINE# #TAB# #TAB# if atom in center_data: #LINE# #TAB# #TAB# #TAB# n += 1 #LINE# #TAB# return n"
"#LINE# #TAB# res = [] #LINE# #TAB# for k in tree.keys(): #LINE# #TAB# #TAB# if isinstance(tree[k], dict): #LINE# #TAB# #TAB# #TAB# res += foo(tree[k]) #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# res.append(k) #LINE# #TAB# return res"
"#LINE# #TAB# if line.startswith('#'): #LINE# #TAB# #TAB# return None, None #LINE# #TAB# line = line[1:] #LINE# #TAB# sep ='' #LINE# #TAB# column_names = line.split(sep)[0] #LINE# #TAB# column_indices = dict() #LINE# #TAB# for i, idx in enumerate(line.split(sep)): #LINE# #TAB# #TAB# column_names[i] = int(idx) #LINE# #TAB# #TAB# column_indices[i] = i #LINE# #TAB# return column_names, column_indices"
#LINE# #TAB# for rule in rules: #LINE# #TAB# #TAB# if rule['type'] == 'comment': #LINE# #TAB# #TAB# #TAB# rules.remove(rule) #LINE# #TAB# return rules
"#LINE# #TAB# files = [] #LINE# #TAB# for dl_path in dl_paths: #LINE# #TAB# #TAB# for url in url_dict[dl_path]: #LINE# #TAB# #TAB# #TAB# if url in os.listdir(dl_path): #LINE# #TAB# #TAB# #TAB# #TAB# if os.path.isfile(os.path.join(dl_path, url)): #LINE# #TAB# #TAB# #TAB# #TAB# #TAB# files.append(os.path.join(dl_path, url)) #LINE# #TAB# return files"
"#LINE# #TAB# l = [] #LINE# #TAB# if type(df) == str: #LINE# #TAB# #TAB# df = pd.read_excel(df, sheet_name=station_name) #LINE# #TAB# else: #LINE# #TAB# #TAB# df = pd.read_csv(df, sheet_name=station_name) #LINE# #TAB# for i in range(1, len(df)): #LINE# #TAB# #TAB# l.append(df[i]) #LINE# #TAB# if as_df: #LINE# #TAB# #TAB# return l #LINE# #TAB# else: #LINE# #TAB# #TAB# return l"
"#LINE# #TAB# if isinstance(op, ops.Selection): #LINE# #TAB# #TAB# assert name is not None, 'name is None' #LINE# #TAB# #TAB# result = op.selections #LINE# #TAB# #TAB# return [result[name]] #LINE# #TAB# elif isinstance(op, ops.Aggregation): #LINE# #TAB# #TAB# assert name is not None, 'name is None' #LINE# #TAB# #TAB# return [item[name] for item in op.items()] #LINE# #TAB# elif isinstance(op, ops.AggregationSet): #LINE# #TAB# #TAB# assert name is not None, 'name is None' #LINE# #TAB# #TAB# return [item[name] for item in op.items()] #LINE# #TAB# else: #LINE# #TAB# #TAB# return op, name"
"#LINE# #TAB# try: #LINE# #TAB# #TAB# module = importlib.import_module(module_names[0]) #LINE# #TAB# except ImportError: #LINE# #TAB# #TAB# raise Exception('Module not found: {}'.format(module_names)) #LINE# #TAB# try: #LINE# #TAB# #TAB# status = getattr(module,'status') #LINE# #TAB# except AttributeError: #LINE# #TAB# #TAB# raise Exception('Module status not found: {}'.format(module_names)) #LINE# #TAB# if not status: #LINE# #TAB# #TAB# raise Exception('Module status not found: {}'.format(module_names)) #LINE# #TAB# return status"
#LINE# #TAB# if parameters['ndim'] == 1: #LINE# #TAB# #TAB# data = [] #LINE# #TAB# else: #LINE# #TAB# #TAB# data = parameters #LINE# #TAB# return data
"#LINE# #TAB# for interface_id in range(1, 256): #LINE# #TAB# #TAB# with open('/proc/%s/config' % interface_id, 'r') as f: #LINE# #TAB# #TAB# #TAB# config = json.load(f) #LINE# #TAB# #TAB# #TAB# yield {'interface_id': interface_id, 'hostname': interface_id, 'port': #LINE# #TAB# #TAB# #TAB# #TAB# interface.port, 'username': interface.username, 'password': #LINE# #TAB# #TAB# #TAB# #TAB# interface.password, 'driver': interface.driver}"
"#LINE# #TAB# line = fd.readline() #LINE# #TAB# n = int(line.split()[0]) #LINE# #TAB# t = int(line.split()[1]) #LINE# #TAB# x = None #LINE# #TAB# while True: #LINE# #TAB# #TAB# try: #LINE# #TAB# #TAB# #TAB# n, t = int(line.split()[0]) #LINE# #TAB# #TAB# except ValueError: #LINE# #TAB# #TAB# #TAB# break #LINE# #TAB# return n, t, x"
#LINE# #TAB# try: #LINE# #TAB# #TAB# return Decimal(str(value)) #LINE# #TAB# except ValueError: #LINE# #TAB# #TAB# return value
"#LINE# #TAB# backend = getattr(plt, name, None) #LINE# #TAB# if backend is None: #LINE# #TAB# #TAB# import matplotlib #LINE# #TAB# #TAB# backend = matplotlib.pyplot.Figure() #LINE# #TAB# return backend"
"#LINE# #TAB# if item.startswith('dimensions#'): #LINE# #TAB# #TAB# dim = item.replace('dimensions#', '') #LINE# #TAB# #TAB# return f""dimensions['{dim}', '{item}']"" #LINE# #TAB# elif item.startswith('meta#'): #LINE# #TAB# #TAB# dim = item.replace('meta#', '') #LINE# #TAB# #TAB# return f""meta['{dim}', '{item}']"" #LINE# #TAB# elif item.startswith('value_meta#'): #LINE# #TAB# #TAB# return f""value_meta['{item}']"" #LINE# #TAB# elif item.startswith('value_meta#'): #LINE# #TAB# #TAB# return f""value_meta['{item}']"" #LINE# #TAB# else: #LINE# #TAB# #TAB# return item"
"#LINE# #TAB# ret = dict() #LINE# #TAB# for k, v in list(_sched.items()): #LINE# #TAB# #TAB# if isinstance(_v, tuple): #LINE# #TAB# #TAB# #TAB# if k[0] == 'v': #LINE# #TAB# #TAB# #TAB# #TAB# ret[k] = v[1] #LINE# #TAB# #TAB# #TAB# elif k == 'w': #LINE# #TAB# #TAB# #TAB# #TAB# ret[k] = True #LINE# #TAB# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# #TAB# ret[k] = v #LINE# #TAB# return ret"
"#LINE# #TAB# value, length = rlp[start:start + 2], rlp[start + 2:] #LINE# #TAB# if length == 255: #LINE# #TAB# #TAB# return int(value, 1), length #LINE# #TAB# return value, length"
#LINE# #TAB# try: #LINE# #TAB# #TAB# return socket.gethostbyname(hostname) #LINE# #TAB# except socket.error: #LINE# #TAB# #TAB# return fallback
#LINE# #TAB# cfg = ConfigParser() #LINE# #TAB# if force and os.path.exists(file_path): #LINE# #TAB# #TAB# cfg.read(file_path) #LINE# #TAB# else: #LINE# #TAB# #TAB# cfg.read(file_path) #LINE# #TAB# return cfg
"#LINE# #TAB# flux_vec = flux_vec[biomass_index] #LINE# #TAB# grad = np.zeros_like(flux_vec) #LINE# #TAB# for i in range(flux_vec.shape[1]): #LINE# #TAB# #TAB# val = flux_vec[i, 0] #LINE# #TAB# #TAB# temp = flux_vec[i, 1] - flux_vec[i, 2] #LINE# #TAB# #TAB# grad[i, 0] = temp #LINE# #TAB# #TAB# grad[i, 1] = temp #LINE# #TAB# return grad"
"#LINE# #TAB# image = np.copy(image) #LINE# #TAB# image[:, :, (0)] -= color_correlation_svd_sqrt[:, :, (2)] #LINE# #TAB# image[:, :, (1)] -= color_correlation_svd_sqrt[:, :, (0)] #LINE# #TAB# return image"
"#LINE# #TAB# path = path or [] #LINE# #TAB# try: #LINE# #TAB# #TAB# for x in store: #LINE# #TAB# #TAB# #TAB# if x['path'] == path: #LINE# #TAB# #TAB# #TAB# #TAB# return True #LINE# #TAB# except (KeyError, IndexError): #LINE# #TAB# #TAB# pass #LINE# #TAB# return False"
"#LINE# #TAB# arrays = [asarray(x) for x in scalars_or_arrays] #LINE# #TAB# out_type = dtypes.result_type(*arrays) #LINE# #TAB# return [x.astype(out_type, copy=False) for x in arrays]"
"#LINE# #TAB# try: #LINE# #TAB# #TAB# status = request.db.health_check() #LINE# #TAB# except Exception as e: #LINE# #TAB# #TAB# log.error(""health check failed: %s"" % e) #LINE# #TAB# #TAB# response = jsonify({""status"": e}) #LINE# #TAB# else: #LINE# #TAB# #TAB# response.status = ""good"" #LINE# #TAB# #TAB# return response"
#LINE# #TAB# lines = [] #LINE# #TAB# for i in range(length): #LINE# #TAB# #TAB# line = string.splitlines() #LINE# #TAB# #TAB# if len(line) == 1: #LINE# #TAB# #TAB# #TAB# lines.append(line[0]) #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# lines.append(line[0]) #LINE# #TAB# return lines
"#LINE# #TAB# sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM) #LINE# #TAB# if cb: #LINE# #TAB# #TAB# sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1) #LINE# #TAB# return sock"
"#LINE# #TAB# start_response('404 NOT FOUND', [('Content-Type', 'text/plain')]) #LINE# #TAB# return ['Not Found']"
"#LINE# #TAB# with h5py.File(filename, 'r') as f: #LINE# #TAB# #TAB# try: #LINE# #TAB# #TAB# #TAB# return f['metadata'][()] #LINE# #TAB# #TAB# except KeyError: #LINE# #TAB# #TAB# #TAB# return {}"
"#LINE# #TAB# tot_actions = len(traces) #LINE# #TAB# if weight_vec is not None: #LINE# #TAB# #TAB# weights = weight_vec #LINE# #TAB# else: #LINE# #TAB# #TAB# weights = np.ones(tot_actions, dtype=np.float64) #LINE# #TAB# temp = np.random.randn(dims, weights) #LINE# #TAB# return temp"
#LINE# #TAB# if uids: #LINE# #TAB# #TAB# for pif in pifs: #LINE# #TAB# #TAB# #TAB# if 'uids' in pif: #LINE# #TAB# #TAB# #TAB# #TAB# pif['uids'] = uids.split(':') #LINE# #TAB# else: #LINE# #TAB# #TAB# pass
"#LINE# #TAB# out = {} #LINE# #TAB# for key in fields: #LINE# #TAB# #TAB# if key in layer: #LINE# #TAB# #TAB# #TAB# out[key] = layer[key][0] #LINE# #TAB# #TAB# elif isinstance(layer[key], str): #LINE# #TAB# #TAB# #TAB# try: #LINE# #TAB# #TAB# #TAB# #TAB# out[key] = getattr(layer[key], fields[key]) #LINE# #TAB# #TAB# #TAB# except AttributeError: #LINE# #TAB# #TAB# #TAB# #TAB# out[key] = str(layer[key]) #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# out[key] = layer[key] #LINE# #TAB# return out"
"#LINE# #TAB# ret = subprocess.check_output(cmd, stderr=subprocess.STDOUT, shell=True) #LINE# #TAB# ret = ret.decode() #LINE# #TAB# return ret"
"#LINE# #TAB# value = get_field_value(data, loperand) #LINE# #TAB# lt = False #LINE# #TAB# if value: #LINE# #TAB# #TAB# if extras: #LINE# #TAB# #TAB# #TAB# value = apply_extras(value, extras) #LINE# #TAB# #TAB# if type(value) == type(roperand) and value == roperand: #LINE# #TAB# #TAB# #TAB# lt = True #LINE# #TAB# if is_not: #LINE# #TAB# #TAB# return not lt #LINE# #TAB# return lt"
#LINE# #TAB# if value.isdigit(): #LINE# #TAB# #TAB# return '{0}'.format(value) #LINE# #TAB# if value.isdigit(): #LINE# #TAB# #TAB# return '{0}'.format(value) #LINE# #TAB# return value
"#LINE# #TAB# if sample_width > 0: #LINE# #TAB# #TAB# sw = sample_width - len(buf) #LINE# #TAB# #TAB# return struct.pack('BB', sw) + buf #LINE# #TAB# return buf"
"#LINE# #TAB# try: #LINE# #TAB# #TAB# abi_type = typ.type #LINE# #TAB# except AttributeError: #LINE# #TAB# #TAB# return False #LINE# #TAB# if isinstance(arg, list): #LINE# #TAB# #TAB# for i in arg: #LINE# #TAB# #TAB# #TAB# if i in abi_type.args: #LINE# #TAB# #TAB# #TAB# #TAB# return True #LINE# #TAB# #TAB# elif isinstance(arg, tuple): #LINE# #TAB# #TAB# #TAB# for item in arg: #LINE# #TAB# #TAB# #TAB# #TAB# if item.type == abi_type.args[i]: #LINE# #TAB# #TAB# #TAB# #TAB# #TAB# return True #LINE# #TAB# return False"
"#LINE# #TAB# return {k: getattr(obj, k) for k in dir(obj) if not k.startswith('_')} if isinstance( #LINE# #TAB# #TAB# obj, dict) else obj"
"#LINE# #TAB# if isinstance(band.layer, (Dataset, NetCDF4)): #LINE# #TAB# #TAB# return str(band.layer.filename) #LINE# #TAB# if isinstance(band.layer, (Dataset, NetCDF4)): #LINE# #TAB# #TAB# return f'{band.filename}:{band.layer.layer}' #LINE# #TAB# return band.filename"
"#LINE# #TAB# with h5py.File(filename, 'r') as f: #LINE# #TAB# #TAB# date = f[0][0] #LINE# #TAB# return date"
#LINE# #TAB# key = exc_type.__module__ + '.' + exc_type.__name__ #LINE# #TAB# Registry.exceptions[key] = exc_type #LINE# #TAB# return exc_type
"#LINE# #TAB# username = props.get('username', username) #LINE# #TAB# if not username: #LINE# #TAB# #TAB# return props #LINE# #TAB# for key, val in props.items(): #LINE# #TAB# #TAB# if key == 'username': #LINE# #TAB# #TAB# #TAB# continue #LINE# #TAB# #TAB# if isinstance(val, list): #LINE# #TAB# #TAB# #TAB# if val[0] == 'email': #LINE# #TAB# #TAB# #TAB# #TAB# continue #LINE# #TAB# #TAB# #TAB# elif val == 'password': #LINE# #TAB# #TAB# #TAB# #TAB# continue #LINE# #TAB# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# #TAB# props[key] = val #LINE# #TAB# return props"
"#LINE# #TAB# t = get_table(engine, table_name) #LINE# #TAB# if t.exists(): #LINE# #TAB# #TAB# return True #LINE# #TAB# index = get_index(engine, index_name) #LINE# #TAB# if index: #LINE# #TAB# #TAB# t.drop_index(inplace=True) #LINE# #TAB# #TAB# return True #LINE# #TAB# return False"
#LINE# #TAB# record = LogRecord() #LINE# #TAB# record.ip = chunk[0:2] #LINE# #TAB# record.msg = chunk[2:4] #LINE# #TAB# record.flags = chunk[4] & 255 #LINE# #TAB# record.msg_id = chunk[5] & 255 #LINE# #TAB# record.sub_type = chunk[6] & 255 #LINE# #TAB# record.msg_len = chunk[7] & 255 #LINE# #TAB# return record
#LINE# #TAB# if not installed_packages: #LINE# #TAB# #TAB# installed_packages = [] #LINE# #TAB# for installed_package in installed_packages: #LINE# #TAB# #TAB# if package in installed_package: #LINE# #TAB# #TAB# #TAB# return True #LINE# #TAB# return False
#LINE# #TAB# seconds = 0 #LINE# #TAB# try: #LINE# #TAB# #TAB# seconds = int(s) #LINE# #TAB# except ValueError: #LINE# #TAB# #TAB# raise ValueError('invalid time period') #LINE# #TAB# if seconds < 0: #LINE# #TAB# #TAB# raise ValueError('negative time period') #LINE# #TAB# return seconds
"#LINE# #TAB# handle = gl.GLuint(1) #LINE# #TAB# gl_gen_function(n, byref(handle)) #LINE# #TAB# if n > 1: #LINE# #TAB# #TAB# return [handle.value + el for el in range(n)] #LINE# #TAB# else: #LINE# #TAB# #TAB# return handle.value"
#LINE# #TAB# for token in sentence: #LINE# #TAB# #TAB# if token.type == 'bracket': #LINE# #TAB# #TAB# #TAB# return True #LINE# #TAB# return False
"#LINE# #TAB# xpath = '//*[@data-type=""resources""]//xhtml:li/xhtml:a' #LINE# #TAB# for resource in html.xpath(xpath, namespaces=HTML_DOCUMENT_NAMESPACES): #LINE# #TAB# #TAB# yield {'id': resource.get('href'), 'filename': resource.text.strip()}"
"#LINE# #TAB# spacing = np.array(spacing) #LINE# #TAB# if packed: #LINE# #TAB# #TAB# d = data.shape[2] #LINE# #TAB# #TAB# x, y = 0.5 * (y + 0.5) / spacing #LINE# #TAB# elif data.shape[2] == 1: #LINE# #TAB# #TAB# x, y = 0.5 * (y + 0.5) / spacing #LINE# #TAB# else: #LINE# #TAB# #TAB# x = 0.5 * (data.shape[2] - 1) / spacing #LINE# #TAB# #TAB# y = 0.5 * (y + 0.5) / spacing #LINE# #TAB# return x, y"
"#LINE# #TAB# try: #LINE# #TAB# #TAB# return torch.device('/dev/ttyACM1') #LINE# #TAB# except (NameError, torch.NotFoundError): #LINE# #TAB# #TAB# return 1"
"#LINE# #TAB# try: #LINE# #TAB# #TAB# conn = _get_conn(region=region, key=key, keyid=keyid, profile=profile) #LINE# #TAB# #TAB# stage = conn.get_stage(restApiId=restApiId, stageName=stageName) #LINE# #TAB# #TAB# r = {} #LINE# #TAB# #TAB# for item in stage.get('items', []): #LINE# #TAB# #TAB# #TAB# r['result'] = True #LINE# #TAB# #TAB# return r #LINE# #TAB# except ClientError as e: #LINE# #TAB# #TAB# r['error'] = __utils__['boto3.get_error'](e) #LINE# #TAB# #TAB# return r"
#LINE# #TAB# res = [] #LINE# #TAB# for i in range(len(time_series)): #LINE# #TAB# #TAB# res.append(shannon_entropy(time_series[i])) #LINE# #TAB# return res
#LINE# #TAB# children = set() #LINE# #TAB# for c in reversed(cls.__bases__): #LINE# #TAB# #TAB# children.update(foo(c)) #LINE# #TAB# return children
"#LINE# #TAB# results = {} #LINE# #TAB# for m in models: #LINE# #TAB# #TAB# results[m] = 0 #LINE# #TAB# for p in range(1, 20): #LINE# #TAB# #TAB# for u in range(1, 20): #LINE# #TAB# #TAB# #TAB# results[m][u] = np.sum((results[m][u] - results[m][u]) ** p) / ((1 - #LINE# #TAB# #TAB# #TAB# #TAB# results[m][u][u]) ** 2 for m in models) #LINE# #TAB# foo = np.mean(results) #LINE# #TAB# return foo"
#LINE# #TAB# F1 = Omega[0] #LINE# #TAB# F2 = Omega[1] #LINE# #TAB# return F1 * R + F2 * Omega
#LINE# #TAB# names = string.split(sep) #LINE# #TAB# if len(names) == 1: #LINE# #TAB# #TAB# return names[0] #LINE# #TAB# elif len(names) == 2: #LINE# #TAB# #TAB# return names[1] #LINE# #TAB# else: #LINE# #TAB# #TAB# return None
#LINE# #TAB# eq_url = equiv_url(url_parts) #LINE# #TAB# if eq_url.netloc!= '' and eq_url.path!= '': #LINE# #TAB# #TAB# eq_url = eq_url.replace(netloc=netloc) #LINE# #TAB# return eq_url
#LINE# #TAB# soup = Trimesh() #LINE# #TAB# for i in range(face_count): #LINE# #TAB# #TAB# soup.faces[i] = random.choice(range(face_count)) #LINE# #TAB# return soup
"#LINE# #TAB# with open(movie_path) as f: #LINE# #TAB# #TAB# img = f.read() #LINE# #TAB# #TAB# width, height = img.shape[:2] #LINE# #TAB# return width, height"
"#LINE# #TAB# ref_url = urlparse(cfg.get('CFG_SITE_SECURE_URL')) #LINE# #TAB# test_url = urlparse(urljoin(cfg.get('CFG_SITE_SECURE_URL'), target)) #LINE# #TAB# return test_url.netloc == ref_url.netloc"
#LINE# #TAB# try: #LINE# #TAB# #TAB# from multiprocessing import cpu_count #LINE# #TAB# #TAB# return cpu_count() #LINE# #TAB# except ImportError: #LINE# #TAB# #TAB# return 1
#LINE# #TAB# try: #LINE# #TAB# #TAB# f = open('gitignored') #LINE# #TAB# #TAB# f.readline() #LINE# #TAB# #TAB# f.close() #LINE# #TAB# #TAB# return os.path.dirname(f.readline()) #LINE# #TAB# except Exception: #LINE# #TAB# #TAB# pass #LINE# #TAB# return None
#LINE# #TAB# country_code = None #LINE# #TAB# for key in profile.keys(): #LINE# #TAB# #TAB# if 'country_code' in profile[key]: #LINE# #TAB# #TAB# #TAB# country_code = profile[key]['country_code'] #LINE# #TAB# #TAB# #TAB# break #LINE# #TAB# if country_code is not None: #LINE# #TAB# #TAB# return country_code #LINE# #TAB# else: #LINE# #TAB# #TAB# return None
#LINE# #TAB# if child.node_type == parent.node_type and child.data == parent.data: #LINE# #TAB# #TAB# return True #LINE# #TAB# for p in parent.get_children(): #LINE# #TAB# #TAB# if p.node_type == child.node_type and p.data == child.data: #LINE# #TAB# #TAB# #TAB# return True #LINE# #TAB# return False
"#LINE# #TAB# for name, field in iter_fields(node): #LINE# #TAB# #TAB# if isinstance(field, Node): #LINE# #TAB# #TAB# #TAB# yield field #LINE# #TAB# #TAB# elif isinstance(field, list): #LINE# #TAB# #TAB# #TAB# for item in field: #LINE# #TAB# #TAB# #TAB# #TAB# if isinstance(item, Node): #LINE# #TAB# #TAB# #TAB# #TAB# #TAB# yield item"
#LINE# #TAB# if vin < 200: #LINE# #TAB# #TAB# return True #LINE# #TAB# else: #LINE# #TAB# #TAB# return False
"#LINE# #TAB# for key in preferences: #LINE# #TAB# #TAB# fname = os.path.basename(file) #LINE# #TAB# #TAB# if fname.startswith('_'): #LINE# #TAB# #TAB# #TAB# continue #LINE# #TAB# #TAB# value = preferences[fname] #LINE# #TAB# #TAB# if isinstance(value, str): #LINE# #TAB# #TAB# #TAB# if value.lower() == 'true': #LINE# #TAB# #TAB# #TAB# #TAB# preferences[fname] = True #LINE# #TAB# #TAB# #TAB# elif value.lower() == 'false': #LINE# #TAB# #TAB# #TAB# #TAB# preferences[fname] = False #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# preferences[fname] = value #LINE# #TAB# return preferences"
"#LINE# #TAB# import re #LINE# #TAB# text = re.sub(r'<a [^>]+>(.+?)</a>', r'\1', text) #LINE# #TAB# text = re.sub(r'<.+?>', r'\1', text) #LINE# #TAB# return text"
"#LINE# #TAB# if request.method == 'POST': #LINE# #TAB# #TAB# return {'url': request.POST['url'], 'headers': request.GET. #LINE# #TAB# #TAB# #TAB# get('headers', {})} #LINE# #TAB# elif request.method == 'PUT': #LINE# #TAB# #TAB# return {'url': request.PUT['url'], 'headers': request.POST.get( #LINE# #TAB# #TAB# #TAB# 'headers', {})} #LINE# #TAB# else: #LINE# #TAB# #TAB# return {}"
"#LINE# #TAB# content = talker.get_issue(issue_id) #LINE# #TAB# tag = 'issue_{0}'.format(issue_id) #LINE# #TAB# content = json.dumps(content, sort_keys=True, indent=2) #LINE# #TAB# with bz2.BZ2File(filename, mode='w') as f: #LINE# #TAB# #TAB# f.write(content) #LINE# #TAB# return tag"
"#LINE# #TAB# return [ #LINE# #TAB# #TAB# f""{invariants[0].name}, {invariants[1].name}, {invariants[2].name}, {invariants[3].name}, {invariants[4].name}"" #LINE# #TAB# #TAB# for invariants in invariants #LINE# #TAB# ]"
#LINE# #TAB# for l in lines: #LINE# #TAB# #TAB# if not l.startswith('#'): #LINE# #TAB# #TAB# #TAB# yield l
"#LINE# #TAB# if value == 0 or isinstance(value, bool) and value: #LINE# #TAB# #TAB# return value #LINE# #TAB# if isinstance(value, str) and value.lower() == 'null': #LINE# #TAB# #TAB# return '0' #LINE# #TAB# return value"
"#LINE# #TAB# for k, v in d.items(): #LINE# #TAB# #TAB# if isinstance(v, dict): #LINE# #TAB# #TAB# #TAB# for i in foo(v): #LINE# #TAB# #TAB# #TAB# #TAB# yield i #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# yield k, v"
"#LINE# #TAB# original_audio_len = original_audio_bin.shape[0] #LINE# #TAB# decoded_audio_len = decoded_audio_bin.shape[0] #LINE# #TAB# foo = np.zeros((original_audio_len, decoded_audio_len)) #LINE# #TAB# for i in range(original_audio_len): #LINE# #TAB# #TAB# foo[i] = (original_audio_bin[i] - decoded_audio_bin[i]) / ( #LINE# #TAB# #TAB# #TAB# decoded_audio_bin[i] - original_audio_bin[i]) #LINE# #TAB# return foo"
#LINE# #TAB# for prefix in prefixes: #LINE# #TAB# #TAB# if orig.startswith(prefix): #LINE# #TAB# #TAB# #TAB# return prefix #LINE# #TAB# return orig
#LINE# #TAB# logging.info('Applying _foo generator:'#LINE# #TAB# #TAB# #TAB# #TAB# 'appending suffix'+ suffix) #LINE# #TAB# for record in records: #LINE# #TAB# #TAB# record.name += suffix
"#LINE# #TAB# force_clean(ws, proj) #LINE# #TAB# try: #LINE# #TAB# #TAB# yield #LINE# #TAB# finally: #LINE# #TAB# #TAB# try: #LINE# #TAB# #TAB# #TAB# for path in [x for x in os.listdir(ws) if x.endswith('.pyc')]: #LINE# #TAB# #TAB# #TAB# #TAB# os.remove(path) #LINE# #TAB# #TAB# except OSError: #LINE# #TAB# #TAB# #TAB# pass"
"#LINE# #TAB# token_lists_with_topics = [] #LINE# #TAB# for token_list in token_lists: #LINE# #TAB# #TAB# for i, tok in enumerate(token_list): #LINE# #TAB# #TAB# #TAB# if i < num_topics: #LINE# #TAB# #TAB# #TAB# #TAB# token_lists_with_topics.append(token) #LINE# #TAB# return token_lists_with_topics"
#LINE# #TAB# sig = inspect.signature(fn) #LINE# #TAB# return [p.name for p in sig.parameters.values() #LINE# #TAB# #TAB# #TAB# if p.kind is p.VAR_POSITIONAL_OR_KEYWORD]
"#LINE# #TAB# if using_cpu_only or job_name not in ('serving', 'learner'): #LINE# #TAB# #TAB# return '' #LINE# #TAB# cuda_visible_devices = os.environ.get('CUDA_VISIBLE_DEVICES', None) #LINE# #TAB# if len(cuda_visible_devices.split(',')) > gpu_id: #LINE# #TAB# #TAB# return cuda_visible_devices.split(',')[gpu_id] #LINE# #TAB# return cuda_visible_devices"
#LINE# #TAB# import distutils.spawn #LINE# #TAB# path = distutils.spawn.find_executable(executable) #LINE# #TAB# if path is None: #LINE# #TAB# #TAB# raise ValueError('{} executable not found in PATH.'.format(executable)) #LINE# #TAB# return path
#LINE# #TAB# if str(file_dir).endswith('.vcf'): #LINE# #TAB# #TAB# file_type = 'vcf' #LINE# #TAB# elif str(file_dir).endswith('.txt'): #LINE# #TAB# #TAB# file_type = 'txt' #LINE# #TAB# else: #LINE# #TAB# #TAB# raise ValueError('Invalid recording directory directory') #LINE# #TAB# return file_type
"#LINE# #TAB# if value[0] == value[-1] == '""': #LINE# #TAB# #TAB# return value[1:-1] #LINE# #TAB# else: #LINE# #TAB# #TAB# return value"
#LINE# #TAB# try: #LINE# #TAB# #TAB# if requests.get('/google-appengine').status_code == 200: #LINE# #TAB# #TAB# #TAB# return True #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# return False #LINE# #TAB# except: #LINE# #TAB# #TAB# return False #LINE# #TAB# except: #LINE# #TAB# #TAB# return False
"#LINE# #TAB# with open(filename, 'cython') as f: #LINE# #TAB# #TAB# for line in f: #LINE# #TAB# #TAB# #TAB# if line.startswith('#'): #LINE# #TAB# #TAB# #TAB# #TAB# continue #LINE# #TAB# #TAB# #TAB# name, desc = line.strip().split(':') #LINE# #TAB# #TAB# #TAB# if name in definitions: #LINE# #TAB# #TAB# #TAB# #TAB# definitions[name].append((line, desc)) #LINE# #TAB# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# #TAB# lines.append('#TAB# ') #LINE# #TAB# #TAB# f.close() #LINE# #TAB# return"
"#LINE# #TAB# options = ( #LINE# #TAB# #TAB# '--configuration jumpy --opt-strategy=usc,5 --enum-mode cautious --opt-mode=optN,' #LINE# #TAB# #TAB# + str(optimum)) #LINE# #TAB# models = clyngor.solve_from_grounded(grounding, options=options) #LINE# #TAB# best_model = None #LINE# #TAB# for model in models.discard_quotes.by_arity.with_optimization: #LINE# #TAB# #TAB# best_model = model #LINE# #TAB# return best_model"
"#LINE# #TAB# class Form(base_class): #LINE# #TAB# #TAB# pass #LINE# #TAB# text = text.strip() #LINE# #TAB# lines = text.split('\n') #LINE# #TAB# form = Form() #LINE# #TAB# for line in lines: #LINE# #TAB# #TAB# if '=' in line: #LINE# #TAB# #TAB# #TAB# name, value = line.split('=', 1) #LINE# #TAB# #TAB# #TAB# field = Field(name, value) #LINE# #TAB# #TAB# #TAB# form.add_field(field) #LINE# #TAB# return form"
#LINE# #TAB# assert size <= 1 #LINE# #TAB# assert step > 0 #LINE# #TAB# if wrap: #LINE# #TAB# #TAB# return #LINE# #TAB# if len(iterable) < size: #LINE# #TAB# #TAB# return #LINE# #TAB# for i in range(size): #LINE# #TAB# #TAB# yield iterable[i:i + size]
"#LINE# #TAB# ifupdater is None: #LINE# #TAB# #TAB# updater = RollerRegistry() #LINE# #TAB# rolled_metrics = [] #LINE# #TAB# for unit in ALL_UNITS: #LINE# #TAB# #TAB# _stop_health_checks(updater, roller_registry) #LINE# #TAB# #TAB# rolled_metrics.append(unit) #LINE# #TAB# daemon = True #LINE# #TAB# if daemon: #LINE# #TAB# #TAB# threading.Thread(target=update_barbar, args=(updater, rolled_metrics)) #LINE# #TAB# #TAB# daemon = False #LINE# #TAB# return daemon"
"#LINE# #TAB# data = np.array(data) #LINE# #TAB# if mask.ndim > 0: #LINE# #TAB# #TAB# c = np.zeros((mask.shape[0], mask.shape[1], 1)) #LINE# #TAB# #TAB# for i in range(mask.shape[0]): #LINE# #TAB# #TAB# #TAB# c[i, 0] = foo(data[i], mask) #LINE# #TAB# #TAB# return c #LINE# #TAB# else: #LINE# #TAB# #TAB# return data[mask]"
"#LINE# #TAB# if filepath is None: #LINE# #TAB# #TAB# filepath = os.path.join(os.path.dirname(os.path.realpath(__file__)), #LINE# #TAB# #TAB# #TAB# '.fydarc') #LINE# #TAB# with open(filepath, 'r') as fp: #LINE# #TAB# #TAB# data = yaml.safe_load(fp) #LINE# #TAB# return data"
#LINE# #TAB# result = string[0].upper() #LINE# #TAB# for char in string[1:]: #LINE# #TAB# #TAB# if char.isupper(): #LINE# #TAB# #TAB# #TAB# if result[0].islower(): #LINE# #TAB# #TAB# #TAB# #TAB# result += '_' + char #LINE# #TAB# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# #TAB# result += char #LINE# #TAB# return result
"#LINE# #TAB# for root, dirs, files in os.walk(dirname): #LINE# #TAB# #TAB# for f in files: #LINE# #TAB# #TAB# #TAB# if f.endswith('.card'): #LINE# #TAB# #TAB# #TAB# #TAB# yield root"
#LINE# #TAB# for b in blocks: #LINE# #TAB# #TAB# if b[0] == 0: #LINE# #TAB# #TAB# #TAB# yield b #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# yield b
"#LINE# #TAB# if isinstance(data, dict): #LINE# #TAB# #TAB# for k, v in data.items(): #LINE# #TAB# #TAB# #TAB# if isinstance(v, dict): #LINE# #TAB# #TAB# #TAB# #TAB# for item in cls.foo(v): #LINE# #TAB# #TAB# #TAB# #TAB# #TAB# yield item #LINE# #TAB# #TAB# elif isinstance(v, list): #LINE# #TAB# #TAB# #TAB# for item in cls.foo(v): #LINE# #TAB# #TAB# #TAB# #TAB# yield item #LINE# #TAB# elif isinstance(data, tuple): #LINE# #TAB# #TAB# for item in data: #LINE# #TAB# #TAB# #TAB# yield cls.foo(item) #LINE# #TAB# else: #LINE# #TAB# #TAB# yield data"
#LINE# #TAB# if not content_types: #LINE# #TAB# #TAB# return 'application/json' #LINE# #TAB# content_types = [x.lower() for x in content_types] #LINE# #TAB# return content_types[0]
"#LINE# #TAB# cls = class_ #LINE# #TAB# if hasattr(cls, '__bases__'): #LINE# #TAB# #TAB# cls = cls.__bases__ #LINE# #TAB# slots = [] #LINE# #TAB# for c in cls: #LINE# #TAB# #TAB# if hasattr(c, '__slots__'): #LINE# #TAB# #TAB# #TAB# slots += foo(c.__slots__) #LINE# #TAB# return slots"
"#LINE# #TAB# for i, j in enumerate(score): #LINE# #TAB# #TAB# if i == j: #LINE# #TAB# #TAB# #TAB# score[i] = PREA[j] #LINE# #TAB# return score"
"#LINE# #TAB# if path[-1] == '/': #LINE# #TAB# #TAB# path = path[:-1] #LINE# #TAB# if path.endswith('/'): #LINE# #TAB# #TAB# path = path[:-1] #LINE# #TAB# return {'path': path,'method': 'GET', 'params': args}"
"#LINE# #TAB# base_path = os.path.join(base_dir, ddf_id) #LINE# #TAB# df = DDF(ddf_id, base_path=base_path) #LINE# #TAB# return df"
#LINE# #TAB# if os.name == 'nt': #LINE# #TAB# #TAB# os.environ['FD_CLOEXEC'] = True #LINE# #TAB# else: #LINE# #TAB# #TAB# pass
#LINE# #TAB# try: #LINE# #TAB# #TAB# return variable in obj #LINE# #TAB# except AttributeError: #LINE# #TAB# #TAB# return False
#LINE# #TAB# if cls._foo_property: #LINE# #TAB# #TAB# return cls._foo_property.table_name #LINE# #TAB# schema = cls.get_schema() #LINE# #TAB# if schema: #LINE# #TAB# #TAB# return schema.table_name #LINE# #TAB# return cls._table_name
"#LINE# #TAB# code3 = max(code1, ord('a')) #LINE# #TAB# code4 = min(code2, ord('z') + 1) #LINE# #TAB# if code3 < code4: #LINE# #TAB# #TAB# d = ord('A') - ord('a') #LINE# #TAB# #TAB# return code3 + d, code4 + d #LINE# #TAB# else: #LINE# #TAB# #TAB# return None"
"#LINE# #TAB# list_ = [Field(k, v) for k, v in list_] #LINE# #TAB# return list_"
#LINE# #TAB# statements = statement.split('\n') #LINE# #TAB# for i in range(len(statements)): #LINE# #TAB# #TAB# statements[i] =''.join(statements[i:]) #LINE# #TAB# return statements
"#LINE# #TAB# with open('TESTING', 'r') as f: #LINE# #TAB# #TAB# f.readline() #LINE# #TAB# #TAB# f.readline() #LINE# #TAB# #TAB# i = 0 #LINE# #TAB# #TAB# while True: #LINE# #TAB# #TAB# #TAB# pass #LINE# #TAB# #TAB# #TAB# if i % 5 == 0: #LINE# #TAB# #TAB# #TAB# #TAB# i += 1 #LINE# #TAB# #TAB# #TAB# if i % 5 == 0: #LINE# #TAB# #TAB# #TAB# #TAB# print('Done!') #LINE# #TAB# #TAB# #TAB# #TAB# break #LINE# #TAB# #TAB# return i"
"#LINE# #TAB# with settings(hide('running','stdout','stderr', 'warnings'), #LINE# #TAB# #TAB# warn_only=True): #LINE# #TAB# #TAB# result = get_ips(name) #LINE# #TAB# #TAB# if result['status'] == 'ok': #LINE# #TAB# #TAB# #TAB# return True #LINE# #TAB# #TAB# elif result['name'] == name: #LINE# #TAB# #TAB# #TAB# return True #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# return False"
"#LINE# #TAB# try: #LINE# #TAB# #TAB# return socket.AF_INET #LINE# #TAB# except socket.error: #LINE# #TAB# #TAB# try: #LINE# #TAB# #TAB# #TAB# socket.inet_pton(socket.AF_INET6, address) #LINE# #TAB# #TAB# #TAB# return socket.AF_INET6 #LINE# #TAB# #TAB# except socket.error: #LINE# #TAB# #TAB# #TAB# return socket.AF_INET"
"#LINE# #TAB# if args is None: #LINE# #TAB# #TAB# args = {} #LINE# #TAB# try: #LINE# #TAB# #TAB# obj = getattr(objects, method) #LINE# #TAB# except AttributeError: #LINE# #TAB# #TAB# try: #LINE# #TAB# #TAB# #TAB# obj = getattr(objects, method) #LINE# #TAB# #TAB# except AttributeError: #LINE# #TAB# #TAB# #TAB# try: #LINE# #TAB# #TAB# #TAB# #TAB# obj = hash(obj) #LINE# #TAB# #TAB# #TAB# except TypeError: #LINE# #TAB# #TAB# #TAB# #TAB# raise TypeError() #LINE# #TAB# return obj"
"#LINE# #TAB# if infile.endswith('.docx'): #LINE# #TAB# #TAB# with open(infile, 'r') as f: #LINE# #TAB# #TAB# #TAB# docid = f.readline().strip() #LINE# #TAB# #TAB# #TAB# title = f.readline().strip() #LINE# #TAB# #TAB# #TAB# odf = f.readline().strip() #LINE# #TAB# #TAB# #TAB# title = title.replace('.docx', '') #LINE# #TAB# #TAB# #TAB# odf = odf.replace('.docx', '') #LINE# #TAB# #TAB# return {'title': title, 'odf': odf}"
"#LINE# #TAB# try: #LINE# #TAB# #TAB# f = open('{}/etc/feh-data.zip'.format(os.getcwd()), 'r') #LINE# #TAB# #TAB# data = json.load(f) #LINE# #TAB# #TAB# f.close() #LINE# #TAB# #TAB# return data['url'] #LINE# #TAB# except FileNotFoundError: #LINE# #TAB# #TAB# return None"
#LINE# #TAB# t.value = float(t.value) #LINE# #TAB# return t
"#LINE# #TAB# if six.PY2 and isinstance(s, str): #LINE# #TAB# #TAB# return s.decode('utf-8') #LINE# #TAB# return s"
"#LINE# #TAB# try: #LINE# #TAB# #TAB# num = int(num) #LINE# #TAB# except (TypeError, ValueError): #LINE# #TAB# #TAB# return default #LINE# #TAB# else: #LINE# #TAB# #TAB# return num"
#LINE# #TAB# res = int(float(val)) #LINE# #TAB# if res == 0: #LINE# #TAB# #TAB# return 0 #LINE# #TAB# else: #LINE# #TAB# #TAB# return res
"#LINE# #TAB# print('Generate with the SVG file {:s}'.format(ai_filename)) #LINE# #TAB# r_outline = [] #LINE# #TAB# for i_ol in ai_figure: #LINE# #TAB# #TAB# r_outline.append(outline_arcpy(i_ol, 'B')) #LINE# #TAB# with open(ai_filename, 'w') as f: #LINE# #TAB# #TAB# for one_line_or_arc in r_outline: #LINE# #TAB# #TAB# #TAB# f.write(one_line_or_arc) #LINE# #TAB# #TAB# f.close() #LINE# #TAB# return"
#LINE# #TAB# if template.startswith('#'): #LINE# #TAB# #TAB# return False #LINE# #TAB# if template.startswith('__'): #LINE# #TAB# #TAB# return False #LINE# #TAB# return True
"#LINE# #TAB# for filename in filenames: #LINE# #TAB# #TAB# _, src = os.path.split(filename) #LINE# #TAB# #TAB# _, dst = os.path.split(dst) #LINE# #TAB# #TAB# os.symlink(src, dst) #LINE# #TAB# return"
"#LINE# #TAB# x = r * np.cos(0.5) #LINE# #TAB# y = r * np.sin(0.5) #LINE# #TAB# return np.zeros_like(x)[:, :, (r)]"
"#LINE# #TAB# global _bcml_cwd #LINE# #TAB# if _bcml_cwd is None: #LINE# #TAB# #TAB# _bcml_cwd = Path(os.getenv('BCML_ROOT', Path.home())) / 'bcml' #LINE# #TAB# return _bcml_cwd"
"#LINE# #TAB# foo = FrequencySeries( #LINE# #TAB# #TAB# length, #LINE# #TAB# #TAB# delta_f, #LINE# #TAB# #TAB# freq=low_freq_cutoff, #LINE# #TAB# #TAB# name='foo_{}'.format(length) #LINE# #TAB# ) #LINE# #TAB# return foo"
#LINE# #TAB# rate = ET.Element('rate') #LINE# #TAB# rate.text = fps #LINE# #TAB# return rate
"#LINE# #TAB# field_id = 1 #LINE# #TAB# with db_connect() as db_conn: #LINE# #TAB# #TAB# with db_conn.cursor() as cursor: #LINE# #TAB# #TAB# #TAB# set_field(field_id, group_name) #LINE# #TAB# #TAB# #TAB# result = cursor.execute( #LINE# #TAB# #TAB# #TAB# #TAB# 'SELECT * FROM fields WHERE group_id =?', (group_name,)) #LINE# #TAB# #TAB# #TAB# db_conn.commit() #LINE# #TAB# return field_id"
"#LINE# #TAB# if string.startswith('_'): #LINE# #TAB# #TAB# string = string[1:] #LINE# #TAB# string = string.replace('_', '') #LINE# #TAB# string = string.lower() #LINE# #TAB# for char in string: #LINE# #TAB# #TAB# if char == '_' and char!='': #LINE# #TAB# #TAB# #TAB# string = string.replace(char, '') #LINE# #TAB# return string"
"#LINE# #TAB# shape = maya.cmds.ls(maya.cmds.listRelatives(geometry, s=True, pa= #LINE# #TAB# #TAB# True) or [], geometry=True) #LINE# #TAB# if not shape: #LINE# #TAB# #TAB# return None #LINE# #TAB# return shape[0]"
#LINE# #TAB# for batch in range(num_epochs): #LINE# #TAB# #TAB# print('Loading batch %d' % batch) #LINE# #TAB# #TAB# if len(data) > batch_size: #LINE# #TAB# #TAB# #TAB# yield data[batch:batch_size]
"#LINE# #TAB# res = [] #LINE# #TAB# for i in range(0, len(s), n): #LINE# #TAB# #TAB# res.append(s[i:i + n]) #LINE# #TAB# return res"
"#LINE# #TAB# config = configparser.ConfigParser() #LINE# #TAB# config.read(file_name) #LINE# #TAB# return config, {'configs': config.get('pig', {}), 'args': [], 'params': {}}"
#LINE# #TAB# if len(letter)!= 1: #LINE# #TAB# #TAB# raise ValueError('The target string must be one letter.') #LINE# #TAB# if letter[0] not in list(ascii_letters): #LINE# #TAB# #TAB# raise ValueError('The target string must be one letter.') #LINE# #TAB# return True
#LINE# #TAB# if session is None: #LINE# #TAB# #TAB# session = db.session #LINE# #TAB# obj = session.query(obj).filter_by(pk=obj.pk).first() #LINE# #TAB# if skip!= {}: #LINE# #TAB# #TAB# obj.pk = skip #LINE# #TAB# return obj
"#LINE# #TAB# V, E = G #LINE# #TAB# n = len(V) #LINE# #TAB# E1 = lists(n) #LINE# #TAB# E2 = lists(n) #LINE# #TAB# for i, e in enumerate(E1): #LINE# #TAB# #TAB# E2[e[0]].append(i) #LINE# #TAB# #TAB# E3 = lists(n) #LINE# #TAB# #TAB# for j, e in enumerate(E2): #LINE# #TAB# #TAB# #TAB# E1[e[0]].append(i) #LINE# #TAB# #TAB# #TAB# E2[e[1]].append(j) #LINE# #TAB# return E1, E2"
"#LINE# #TAB# results = [] #LINE# #TAB# for start, quantity in d.items(): #LINE# #TAB# #TAB# results.append((start, start + width, quantity)) #LINE# #TAB# return results"
"#LINE# #TAB# if reponame == reposave and path: #LINE# #TAB# #TAB# return os.path.join(path, 'issuetemplate') #LINE# #TAB# elif reponame == path: #LINE# #TAB# #TAB# return os.path.join(path, 'issue') #LINE# #TAB# elif reponame == os.getcwd(): #LINE# #TAB# #TAB# return os.path.abspath(os.path.join(path, 'issue_template')) #LINE# #TAB# else: #LINE# #TAB# #TAB# return None"
"#LINE# #TAB# value = value.strip('#') #LINE# #TAB# r = int(value, 16) #LINE# #TAB# g = int(value, 16) #LINE# #TAB# b = int(value, 16) #LINE# #TAB# return {'color': r, 'g': g, 'b': b}"
#LINE# #TAB# if not'milestone_properties' in holder: #LINE# #TAB# #TAB# holder['milestone_properties'] = MilestoneProperties() #LINE# #TAB# return holder['milestone_properties']
"#LINE# #TAB# for field in node._fields: #LINE# #TAB# #TAB# try: #LINE# #TAB# #TAB# #TAB# yield field, getattr(node, field) #LINE# #TAB# #TAB# except AttributeError: #LINE# #TAB# #TAB# #TAB# pass"
"#LINE# #TAB# if os.environ.get('ConEmuANSI', '') == 'ON': #LINE# #TAB# #TAB# return True #LINE# #TAB# for key in colors.COLORTERM: #LINE# #TAB# #TAB# if os.environ.get(key, '') == 'truecolor': #LINE# #TAB# #TAB# #TAB# return True #LINE# #TAB# return False"
"#LINE# #TAB# _module_name = 'ds_connectors.handlers.aws_s3_handlers' #LINE# #TAB# _handler = 'AwsS3PersistHandler' #LINE# #TAB# return _module_name, _handler"
#LINE# #TAB# import importlib #LINE# #TAB# spec = importlib.util.spec_from_file_location(filepath) #LINE# #TAB# mod = importlib.util.module_from_spec(spec) #LINE# #TAB# if mod_name: #LINE# #TAB# #TAB# spec.loader.mod_name = mod_name #LINE# #TAB# module = importlib.util.module_from_spec(spec) #LINE# #TAB# spec.loader.exec_module(module) #LINE# #TAB# return module
"#LINE# #TAB# if isinstance(src, dict): #LINE# #TAB# #TAB# for k, v in src.items(): #LINE# #TAB# #TAB# #TAB# if isinstance(v, bytes): #LINE# #TAB# #TAB# #TAB# #TAB# try: #LINE# #TAB# #TAB# #TAB# #TAB# #TAB# src[k] = v.decode('utf-8') #LINE# #TAB# #TAB# #TAB# #TAB# except AttributeError: #LINE# #TAB# #TAB# #TAB# #TAB# #TAB# src[k] = str(v) #LINE# #TAB# return src"
"#LINE# #TAB# subparser.add_argument( #LINE# #TAB# #TAB# ""--download"", help=""Download your YouTube video."", #LINE# #TAB# #TAB# default=None, type=str, required=False) #LINE# #TAB# return foo"
"#LINE# #TAB# article_ids = [] #LINE# #TAB# for a in soup.find_all('a', href=True): #LINE# #TAB# #TAB# id = a.get('href') #LINE# #TAB# #TAB# if id: #LINE# #TAB# #TAB# #TAB# article_ids.append(id) #LINE# #TAB# return article_ids"
#LINE# #TAB# l10n = locale.getdefaultlocale() #LINE# #TAB# if not l10n: #LINE# #TAB# #TAB# return 'en' #LINE# #TAB# else: #LINE# #TAB# #TAB# return l10n
"#LINE# #TAB# try: #LINE# #TAB# #TAB# r = winreg.QueryValueEx(winreg.HKEY_LOCAL_MACHINE, key) #LINE# #TAB# #TAB# print(r) #LINE# #TAB# except WindowsError: #LINE# #TAB# #TAB# pass"
#LINE# #TAB# try: #LINE# #TAB# #TAB# return request.query_params['access_token'] #LINE# #TAB# except KeyError: #LINE# #TAB# #TAB# return None
"#LINE# #TAB# for k, v in json.items(): #LINE# #TAB# #TAB# if isinstance(v, dict): #LINE# #TAB# #TAB# #TAB# if k == 'links': #LINE# #TAB# #TAB# #TAB# #TAB# json[k] = Link(json[k]) #LINE# #TAB# #TAB# #TAB# #TAB# continue #LINE# #TAB# #TAB# if isinstance(v, list): #LINE# #TAB# #TAB# #TAB# json[k] = Link(json[k], json[k]) #LINE# #TAB# return json"
#LINE# #TAB# if header in IGNORE_HEADERS: #LINE# #TAB# #TAB# return False #LINE# #TAB# if header.startswith('HTTP_') or header == 'CONTENT_TYPE': #LINE# #TAB# #TAB# return True #LINE# #TAB# return False
"#LINE# #TAB# if not isinstance(inp, numbers.Number): #LINE# #TAB# #TAB# check_value(inp) #LINE# #TAB# #TAB# raise error.BASICError(err) #LINE# #TAB# return inp"
#LINE# #TAB# if cid: #LINE# #TAB# #TAB# try: #LINE# #TAB# #TAB# #TAB# return g.gcp_label(cid) #LINE# #TAB# #TAB# except gcp.errors.ClientError as e: #LINE# #TAB# #TAB# #TAB# if e.response.status_code == 404: #LINE# #TAB# #TAB# #TAB# #TAB# return '' #LINE# #TAB# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# #TAB# raise e #LINE# #TAB# else: #LINE# #TAB# #TAB# return ''
"#LINE# #TAB# bigdataset = os.getenv(envkey) #LINE# #TAB# if bigdataset: #LINE# #TAB# #TAB# return bigdataset #LINE# #TAB# artifactory_folder = os.path.abspath(os.path.join(os.path.dirname(bigdataset), #LINE# #TAB# #TAB# 'Artifactory')) #LINE# #TAB# blob_paths = [] #LINE# #TAB# for filename in os.listdir(artifactory_folder): #LINE# #TAB# #TAB# filepath = os.path.join(artifactory_folder, filename) #LINE# #TAB# #TAB# if os.path.isfile(filepath): #LINE# #TAB# #TAB# #TAB# blob_paths.append(filepath) #LINE# #TAB# bigdataset_path = os.path.join(artifactory_folder, blob_paths) #LINE# #TAB# return bigdataset_path"
"#LINE# #TAB# if cfg.name == 'ner' and cfg.sequence_label_config =='seq': #LINE# #TAB# #TAB# return cfg #LINE# #TAB# return {'ner': cfg.ner,'sequence_label_config': cfg.sequence_label_config}"
"#LINE# #TAB# try: #LINE# #TAB# #TAB# c = compile(source, name, 'eval') #LINE# #TAB# except SyntaxError: #LINE# #TAB# #TAB# c = compile(source, name, 'exec') #LINE# #TAB# return c"
#LINE# #TAB# import spellcheck #LINE# #TAB# try: #LINE# #TAB# #TAB# return spellcheck.foo(build_dir) #LINE# #TAB# except spellcheck.SpellcheckError: #LINE# #TAB# #TAB# return 1
"#LINE# #TAB# if isinstance(s, str): #LINE# #TAB# #TAB# s = s.replace('&', '&amp;') #LINE# #TAB# #TAB# s = s.replace('<', '&lt;') #LINE# #TAB# #TAB# s = s.replace('>', '&gt;') #LINE# #TAB# return s"
"#LINE# #TAB# return ((iso_8601(year=yw[0], month=yw[1], day=1), (iso_8601(year=yw[2], #LINE# #TAB# #TAB# month=1), day=1))[:2]"
"#LINE# #TAB# if registry is None: #LINE# #TAB# #TAB# return None #LINE# #TAB# key = registry.CreateKey(registry.HKEY_CURRENT_USER, #LINE# #TAB# #TAB# 'Software\\Valve\\Steam') #LINE# #TAB# return registry.QueryValueEx(key, 'SteamPath')[0]"
"#LINE# #TAB# #TAB# if isinstance(value, six.string_types): #LINE# #TAB# #TAB# #TAB# el.text = value #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# try: #LINE# #TAB# #TAB# #TAB# #TAB# el.text = el.text.strip() #LINE# #TAB# #TAB# #TAB# except AttributeError: #LINE# #TAB# #TAB# #TAB# #TAB# pass #LINE# #TAB# #TAB# return value"
"#LINE# #TAB# for node in program_ast.nodes: #LINE# #TAB# #TAB# if type(node) is ast.Name: #LINE# #TAB# #TAB# #TAB# foo = getattr(node, 'arg', None) #LINE# #TAB# #TAB# #TAB# if foo is not None: #LINE# #TAB# #TAB# #TAB# #TAB# return foo #LINE# #TAB# return None"
#LINE# #TAB# consensus_snapshot = cls.generate_consensus_snapshot_from_ops_hash( record_root_hash ) #LINE# #TAB# for prev_hash in prev_consensus_hashes: #LINE# #TAB# #TAB# consensus_snapshot = cls.generate_consensus_snapshot_from_ops_hash( #LINE# #TAB# #TAB# #TAB# prev_hash ) #LINE# #TAB# return consensus_snapshot
#LINE# #TAB# a_names = set(a.args) #LINE# #TAB# b_names = set(b.args) #LINE# #TAB# if a_names!= b_names: #LINE# #TAB# #TAB# return False #LINE# #TAB# return True
"#LINE# #TAB# with open(""{}.json"".format(ROOT_DIR), ""r"") as f: #LINE# #TAB# #TAB# data = json.load(f) #LINE# #TAB# return data"
"#LINE# #TAB# return {'data': {'action_button': button.data, 'action_button_text': #LINE# #TAB# #TAB# button.action_text}}"
#LINE# #TAB# if name not in _local: #LINE# #TAB# #TAB# _local[name] = app #LINE# #TAB# return _local[name]
"#LINE# #TAB# sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM) #LINE# #TAB# sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1) #LINE# #TAB# sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1) #LINE# #TAB# return sock"
"#LINE# #TAB# data = tz.get_in([""config"", ""algorithm"", ""samtools"", ""variant_regions""], data) #LINE# #TAB# out = {} #LINE# #TAB# for chrom in data: #LINE# #TAB# #TAB# start = tz.get_in([chrom, ""start""], data) #LINE# #TAB# #TAB# end = tz.get_in([chrom, ""end""], data) #LINE# #TAB# #TAB# if start and end: #LINE# #TAB# #TAB# #TAB# out[chrom] = ""%s-%s"" % (start, end) #LINE# #TAB# return out"
#LINE# #TAB# try: #LINE# #TAB# #TAB# if sys.version_info[0] >= 3: #LINE# #TAB# #TAB# #TAB# return 1 #LINE# #TAB# #TAB# elif sys.version_info[0] == 2 and sys.version_info[1] >= 4: #LINE# #TAB# #TAB# #TAB# return 2 #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# return 0 #LINE# #TAB# except ValueError: #LINE# #TAB# #TAB# return 1
"#LINE# #TAB# with open(os.devnull, 'w') as devnull: #LINE# #TAB# #TAB# try: #LINE# #TAB# #TAB# #TAB# r = subprocess.getoutput(['git','rev-parse', '--show-toplevel'], #LINE# #TAB# #TAB# #TAB# #TAB# #TAB# #TAB# #TAB# #TAB# cwd=git_folder) #LINE# #TAB# #TAB# except subprocess.CalledProcessError: #LINE# #TAB# #TAB# #TAB# return 'unknown' #LINE# #TAB# #TAB# if r.returncode == 0: #LINE# #TAB# #TAB# #TAB# return r.stdout.decode('utf-8') #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# return r.stderr.decode('utf-8') #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# return 'unknown'"
#LINE# #TAB# try: #LINE# #TAB# #TAB# return int(x) #LINE# #TAB# except ValueError: #LINE# #TAB# #TAB# return x
"#LINE# #TAB# nbytes = len(fileContent) #LINE# #TAB# data = [] #LINE# #TAB# for i in range(nbytes): #LINE# #TAB# #TAB# temp = bytearray(fileContent[i:i + nbytes]) #LINE# #TAB# #TAB# temp[i:i + nbytes] = int.from_bytes(temp[i:i + nbytes], 'big') #LINE# #TAB# #TAB# data.append(temp) #LINE# #TAB# return data"
"#LINE# #TAB# import json #LINE# #TAB# with open(""demo.json"", ""r"") as f: #LINE# #TAB# #TAB# t = json.load(f) #LINE# #TAB# #TAB# return t"
"#LINE# #TAB# found_class = None #LINE# #TAB# for name in dir(module): #LINE# #TAB# #TAB# if name.isupper(): #LINE# #TAB# #TAB# #TAB# if getattr(module, name) == class_string: #LINE# #TAB# #TAB# #TAB# #TAB# found_class = name #LINE# #TAB# #TAB# #TAB# #TAB# break #LINE# #TAB# return found_class"
"#LINE# #TAB# if grayscale: #LINE# #TAB# #TAB# img = cv2.imread(path, cv2.IMREAD_GRAYSCALE) #LINE# #TAB# elif target_size: #LINE# #TAB# #TAB# img = cv2.imread(path, target_size) #LINE# #TAB# else: #LINE# #TAB# #TAB# img = cv2.imread(path, cv2.IMREAD_UNCHANGED) #LINE# #TAB# if target_size: #LINE# #TAB# #TAB# img = cv2.resize(img, target_size) #LINE# #TAB# return img"
"#LINE# #TAB# with open(input_file, 'r') as f: #LINE# #TAB# #TAB# config = yaml.load(f) #LINE# #TAB# return config"
#LINE# #TAB# locale_list = [] #LINE# #TAB# for lang in Language.objects.all(): #LINE# #TAB# #TAB# if lang.name not in locale_list: #LINE# #TAB# #TAB# #TAB# locale_list.append(lang) #LINE# #TAB# return {'language_code': locale_list[0].language}
"#LINE# #TAB# try: #LINE# #TAB# #TAB# acl_url = urljoin(_acl_url(), 'users/{}'.format(uid)) #LINE# #TAB# #TAB# r = http.get(acl_url) #LINE# #TAB# #TAB# return r.json() #LINE# #TAB# except DCOSHTTPException as e: #LINE# #TAB# #TAB# if e.response.status_code!= 400: #LINE# #TAB# #TAB# #TAB# raise"
#LINE# #TAB# if word.islower(): #LINE# #TAB# #TAB# return correction.lower() #LINE# #TAB# if word.isupper(): #LINE# #TAB# #TAB# return correction.upper() #LINE# #TAB# if word.islower(): #LINE# #TAB# #TAB# return correction.lower() #LINE# #TAB# if word == '0' and correction.isupper(): #LINE# #TAB# #TAB# return correction.upper() #LINE# #TAB# if word.islower(): #LINE# #TAB# #TAB# return correction.lower() #LINE# #TAB# if word.isupper(): #LINE# #TAB# #TAB# return correction.upper() #LINE# #TAB# return correction
#LINE# #TAB# for name in names: #LINE# #TAB# #TAB# if name.endswith('.py'): #LINE# #TAB# #TAB# #TAB# names.remove(name) #LINE# #TAB# return names
#LINE# #TAB# try: #LINE# #TAB# #TAB# foo_dict = dict_of_dict.copy() #LINE# #TAB# #TAB# return foo_dict #LINE# #TAB# except: #LINE# #TAB# #TAB# return {}
"#LINE# #TAB# radar = radar[:] #LINE# #TAB# for i in range(len(radar)-1): #LINE# #TAB# #TAB# for j in range(i+1, len(radar)): #LINE# #TAB# #TAB# #TAB# if abs(radar[j] - radar[i]) > 1e-06: #LINE# #TAB# #TAB# #TAB# #TAB# return False #LINE# #TAB# return True"
"#LINE# #TAB# result = None #LINE# #TAB# if isinstance(mylist, float): #LINE# #TAB# #TAB# with warnings.catch_warnings(): #LINE# #TAB# #TAB# #TAB# warnings.simplefilter('ignore') #LINE# #TAB# #TAB# #TAB# result = float(mylist) #LINE# #TAB# elif isinstance(mylist, list): #LINE# #TAB# #TAB# for i in range(len(mylist)): #LINE# #TAB# #TAB# #TAB# result[i] = mylist[i] #LINE# #TAB# else: #LINE# #TAB# #TAB# for i in range(len(mylist)): #LINE# #TAB# #TAB# #TAB# result[i] = float(mylist[i]) #LINE# #TAB# return result"
#LINE# #TAB# if not os.path.isfile(folder): #LINE# #TAB# #TAB# return False #LINE# #TAB# if folder.endswith('.pyc'): #LINE# #TAB# #TAB# return True #LINE# #TAB# return False
"#LINE# #TAB# if sys.version_info[0] >= 3: #LINE# #TAB# #TAB# return ""You can't use GET /2 or GET /3"" #LINE# #TAB# elif sys.version_info[0] == 2: #LINE# #TAB# #TAB# return ""You can use GET /2 or GET /3"" #LINE# #TAB# elif sys.version_info[0] == 3: #LINE# #TAB# #TAB# return ""You can use GET /3 or GET /3"" #LINE# #TAB# else: #LINE# #TAB# #TAB# return ""You don't have the correct version number."""
#LINE# #TAB# if s.size == 1: #LINE# #TAB# #TAB# return s[0] #LINE# #TAB# elif s.size == 2: #LINE# #TAB# #TAB# return s[0] ** 2 #LINE# #TAB# elif s.size == 3: #LINE# #TAB# #TAB# return s[0] ** 2 #LINE# #TAB# else: #LINE# #TAB# #TAB# return s[0] ** 2
"#LINE# #TAB# h = sha256() #LINE# #TAB# with open(file, 'rb') as f: #LINE# #TAB# #TAB# for chunk in iter(lambda: f.read(4096), b''): #LINE# #TAB# #TAB# #TAB# h.update(chunk) #LINE# #TAB# return h.hexdigest()[0:7]"
#LINE# #TAB# #TAB# obj = cls(name) #LINE# #TAB# #TAB# obj.exporter = 'get_output_table_name' #LINE# #TAB# #TAB# obj.output_name = output_name #LINE# #TAB# #TAB# return obj
"#LINE# #TAB# with open(fasta_name, 'r') as f: #LINE# #TAB# #TAB# name = f.readline().strip() #LINE# #TAB# #TAB# num = f.count('\n') #LINE# #TAB# #TAB# while 1: #LINE# #TAB# #TAB# #TAB# yield name #LINE# #TAB# #TAB# #TAB# name = f.readline().strip() #LINE# #TAB# #TAB# #TAB# num += 1"
"#LINE# #TAB# if not isinstance(identifier, URIRef): #LINE# #TAB# #TAB# identifier = URIRef(identifier) #LINE# #TAB# store = DjangoStore(store_id) #LINE# #TAB# graph = Graph(store, identifier=identifier) #LINE# #TAB# if graph.open(None, create=create)!= VALID_STORE: #LINE# #TAB# #TAB# raise ValueError(""The store identified by {0} is not a valid store"".format(store_id)) #LINE# #TAB# return graph"
"#LINE# #TAB# g1_variables = set([g1.variable, g2.variable]) #LINE# #TAB# g1_arrays = set([g1.variable, g2.variable]) #LINE# #TAB# g2_variables = set([g1.variable, g2.variable]) #LINE# #TAB# return g1_variables, g2_variables"
#LINE# #TAB# result = {} #LINE# #TAB# if previous_props: #LINE# #TAB# #TAB# for key in list(previous_props.keys()): #LINE# #TAB# #TAB# #TAB# if key in next_props: #LINE# #TAB# #TAB# #TAB# #TAB# result[key] = next_props[key] #LINE# #TAB# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# #TAB# result[key] = previous_props[key] #LINE# #TAB# if next_props: #LINE# #TAB# #TAB# for key in list(next_props.keys()): #LINE# #TAB# #TAB# #TAB# if key in previous_props: #LINE# #TAB# #TAB# #TAB# #TAB# result[key] = previous_props[key] #LINE# #TAB# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# #TAB# result[key] = next_props[key] #LINE# #TAB# return result
#LINE# #TAB# if message[0] == 'commit': #LINE# #TAB# #TAB# return message[1] #LINE# #TAB# else: #LINE# #TAB# #TAB# return message[0]
#LINE# #TAB# for supported_language in SUPPORTED_LANGUAGES: #LINE# #TAB# #TAB# if search_text in supported_language: #LINE# #TAB# #TAB# #TAB# yield supported_language
"#LINE# #TAB# for char in [""'"", '""']: #LINE# #TAB# #TAB# value = value.replace(char, '\\' + char) #LINE# #TAB# if value.count('.') == 1: #LINE# #TAB# #TAB# return value[:-1] #LINE# #TAB# else: #LINE# #TAB# #TAB# return value"
"#LINE# #TAB# for part in SUGGESTIONS: #LINE# #TAB# #TAB# text = text.replace(part, SUGGESTIONS[part]) #LINE# #TAB# return text"
"#LINE# #TAB# try: #LINE# #TAB# #TAB# return m.__class__() #LINE# #TAB# except AttributeError: #LINE# #TAB# #TAB# if isinstance(m, types.ModuleType): #LINE# #TAB# #TAB# #TAB# m.__class__ = type(m) #LINE# #TAB# #TAB# return m"
#LINE# #TAB# try: #LINE# #TAB# #TAB# import matplotlib #LINE# #TAB# #TAB# yield #LINE# #TAB# except ImportError: #LINE# #TAB# #TAB# raise #LINE# #TAB# except Exception: #LINE# #TAB# #TAB# pass
"#LINE# #TAB# if igs is None: #LINE# #TAB# #TAB# igs = range(len(conns)) #LINE# #TAB# mesh = Mesh(name) #LINE# #TAB# mesh._set_data(coors=coors, ngroups=ngroups, conns=[conns[ig] for ig in #LINE# #TAB# #TAB# igs], mat_ids=[mat_ids[ig] for ig in igs], descs=[descs[ig] for ig in #LINE# #TAB# #TAB# igs]) #LINE# #TAB# mesh._set_shape_info() #LINE# #TAB# return mesh"
"#LINE# #TAB# for obj in builder.get_objects(): #LINE# #TAB# #TAB# if isinstance(obj, gtk.Window): #LINE# #TAB# #TAB# #TAB# return obj"
"#LINE# #TAB# global CACHE #LINE# #TAB# obj_id = str(object) #LINE# #TAB# if obj_id not in CACHE: #LINE# #TAB# #TAB# CACHE[obj_id] = {} #LINE# #TAB# #TAB# results = [] #LINE# #TAB# #TAB# for item in objects: #LINE# #TAB# #TAB# #TAB# key, value = item.split(':', 1) #LINE# #TAB# #TAB# #TAB# summary['cache'][key] = value #LINE# #TAB# #TAB# #TAB# results.append((key, summary)) #LINE# #TAB# return results"
"#LINE# #TAB# data = {} #LINE# #TAB# with open(""data/time_machine_train.csv"", ""r"") as f: #LINE# #TAB# #TAB# for line in f: #LINE# #TAB# #TAB# #TAB# data[line[0]] = int(line[1:]) #LINE# #TAB# with open(""data/time_machine_val.csv"", ""r"") as f: #LINE# #TAB# #TAB# for line in f: #LINE# #TAB# #TAB# #TAB# data[line[0]] = float(line[1:]) #LINE# #TAB# print(""Time machine data is: "") #LINE# #TAB# return data"
"#LINE# #TAB# if isinstance(bgcolor, str): #LINE# #TAB# #TAB# bgcolor = (bgcolor, bgcolor) #LINE# #TAB# if not img.mode == 'RGBA': #LINE# #TAB# #TAB# img = Image.new('RGB', (img.width, img.height), bgcolor) #LINE# #TAB# else: #LINE# #TAB# #TAB# img = Image.new('RGB', img.width, img.height, bgcolor) #LINE# #TAB# return img"
#LINE# #TAB# vals = df[groupby].set_index(fld) #LINE# #TAB# return vals.most_common(1)[0][0]
#LINE# #TAB# logging.basicConfig(format='%(message)s') #LINE# #TAB# handler = logging.StreamHandler(sys.stderr) #LINE# #TAB# handler.setFormatter(logging.Formatter( #LINE# #TAB# #TAB# '%(asctime)s %(levelname)s: %(message)s')) #LINE# #TAB# logging.getLogger().addHandler(handler) #LINE# #TAB# logging.getLogger().setLevel(logging.DEBUG) #LINE# #TAB# return handler
#LINE# #TAB# if name.startswith('http'): #LINE# #TAB# #TAB# return '/etc/init/{0}.py'.format(name) #LINE# #TAB# elif name.startswith('https'): #LINE# #TAB# #TAB# return '/etc/init/{0}.py'.format(name) #LINE# #TAB# else: #LINE# #TAB# #TAB# return '/etc/init/{0}.py'.format(name)
"#LINE# #TAB# pop_no_diff_fields(latest_config, current_config) #LINE# #TAB# diff = abs(latest_config - current_config) #LINE# #TAB# if len(diff)!= len(pop_no_diff_fields(latest_config, current_config)): #LINE# #TAB# #TAB# return False #LINE# #TAB# return True"
"#LINE# #TAB# warnings.warn( #LINE# #TAB# #TAB# 'In requests 3.0, get_foo() will be removed. For more information, please see the discussion on issue #2266. (This warning should only appear once.)' #LINE# #TAB# #TAB#, DeprecationWarning) #LINE# #TAB# tried_encodings = [] #LINE# #TAB# encoding = get_encoding(r) #LINE# #TAB# if encoding: #LINE# #TAB# #TAB# try: #LINE# #TAB# #TAB# #TAB# return str(r.content, encoding) #LINE# #TAB# #TAB# except UnicodeError: #LINE# #TAB# #TAB# #TAB# tried_encodings.append(encoding) #LINE# #TAB# try: #LINE# #TAB# #TAB# return str(r.content, encoding, errors='replace') #LINE# #TAB# except TypeError: #LINE# #TAB# #TAB# return r.content"
#LINE# #TAB# amount = item.amount #LINE# #TAB# if amount > max_amount: #LINE# #TAB# #TAB# return amount - max_amount #LINE# #TAB# return amount
#LINE# #TAB# try: #LINE# #TAB# #TAB# fid = pysam.AlignmentFile(bam_file) #LINE# #TAB# except IOError: #LINE# #TAB# #TAB# raise ValueError('Cannot open {0}'.format(bam_file)) #LINE# #TAB# try: #LINE# #TAB# #TAB# fid.fetch() #LINE# #TAB# except ValueError: #LINE# #TAB# #TAB# raise ValueError('Cannot open {0}'.format(bam_file)) #LINE# #TAB# return fid
#LINE# #TAB# if name is None: #LINE# #TAB# #TAB# return None #LINE# #TAB# if name.lower() == 'true': #LINE# #TAB# #TAB# return True #LINE# #TAB# elif name.lower() == 'false': #LINE# #TAB# #TAB# return False #LINE# #TAB# else: #LINE# #TAB# #TAB# try: #LINE# #TAB# #TAB# #TAB# return int(name) #LINE# #TAB# #TAB# except ValueError: #LINE# #TAB# #TAB# #TAB# return name
"#LINE# #TAB# del value, frame #LINE# #TAB# if isinstance(groups[0], tuple): #LINE# #TAB# #TAB# for func_name in groups[0]: #LINE# #TAB# #TAB# #TAB# func = groups[0][func_name] #LINE# #TAB# #TAB# #TAB# yield NO_FUNC_MSG.format(func_name) #LINE# #TAB# if isinstance(value, str): #LINE# #TAB# #TAB# for line in value.splitlines(): #LINE# #TAB# #TAB# #TAB# yield NO_FUNC_MSG.format(line) #LINE# #TAB# elif isinstance(value, tuple): #LINE# #TAB# #TAB# for line in value: #LINE# #TAB# #TAB# #TAB# yield NO_FUNC_MSG.format(line) #LINE# #TAB# else: #LINE# #TAB# #TAB# yield NO_FUNC_MSG"
#LINE# #TAB# val = 0 #LINE# #TAB# if 'incrementalMFD' in taglist[node.tag]: #LINE# #TAB# #TAB# val -= 1 #LINE# #TAB# if 'truncGutenbergRichterMFD' in taglist[node.tag]: #LINE# #TAB# #TAB# val += 1 #LINE# #TAB# if 'truncGutenbergRichterMFD' in taglist[node.tag]: #LINE# #TAB# #TAB# val += 1 #LINE# #TAB# return val
#LINE# #TAB# s = str(string) #LINE# #TAB# if not s.startswith('0.'): #LINE# #TAB# #TAB# return [] #LINE# #TAB# result = [] #LINE# #TAB# for i in range(len(s)): #LINE# #TAB# #TAB# if s[i] == '0': #LINE# #TAB# #TAB# #TAB# digit = s[i:] #LINE# #TAB# #TAB# #TAB# result.append(digit) #LINE# #TAB# return result
"#LINE# #TAB# headers = [] #LINE# #TAB# for name in fnames: #LINE# #TAB# #TAB# name = name.replace('.', '_') #LINE# #TAB# #TAB# header = _foo(name, blend) #LINE# #TAB# #TAB# if header is None: #LINE# #TAB# #TAB# #TAB# continue #LINE# #TAB# #TAB# if header not in headers: #LINE# #TAB# #TAB# #TAB# headers.append(header) #LINE# #TAB# return headers"
#LINE# #TAB# ecc_names = [] #LINE# #TAB# for line in open('data/ecc.json').readlines(): #LINE# #TAB# #TAB# for ecc in line.split(): #LINE# #TAB# #TAB# #TAB# if ecc.isdigit(): #LINE# #TAB# #TAB# #TAB# #TAB# ecc_names.append(ecc) #LINE# #TAB# return ecc_names
#LINE# #TAB# if model_mae == naive_mae: #LINE# #TAB# #TAB# return 0.0 #LINE# #TAB# else: #LINE# #TAB# #TAB# return 1.0 - model_mae / naive_mae
#LINE# #TAB# return [name for name in os.listdir(directory) if name.endswith('.xml') #LINE# #TAB# #TAB# ]
"#LINE# #TAB# if 'width' in entity.attributes: #LINE# #TAB# #TAB# x = xy[0] #LINE# #TAB# #TAB# y = xy[1] #LINE# #TAB# elif 'height' in entity.attributes: #LINE# #TAB# #TAB# y = xy[1] #LINE# #TAB# #TAB# x = xy[0] - entity.attributes['width'] #LINE# #TAB# else: #LINE# #TAB# #TAB# x = entity.attributes['width'] #LINE# #TAB# #TAB# y = entity.attributes['height'] #LINE# #TAB# return x, y"
#LINE# #TAB# try: #LINE# #TAB# #TAB# return eval(obj) #LINE# #TAB# except: #LINE# #TAB# #TAB# return obj
#LINE# #TAB# contract = get_contract(netid) #LINE# #TAB# if contract is not None: #LINE# #TAB# #TAB# return contract.forward() #LINE# #TAB# return None
#LINE# #TAB# _list = [] #LINE# #TAB# for item in series: #LINE# #TAB# #TAB# _list.append(item) #LINE# #TAB# col = df[series.columns[0]] #LINE# #TAB# df.loc[col] = _list #LINE# #TAB# return df
#LINE# #TAB# tree = eTree() #LINE# #TAB# tree.parse(string) #LINE# #TAB# root = tree.getroot() #LINE# #TAB# return root
"#LINE# #TAB# result = [] #LINE# #TAB# for i in range(len(polygon)): #LINE# #TAB# #TAB# for j in range(i + 1, len(polygon)): #LINE# #TAB# #TAB# #TAB# result.append(polygon[j] * scale + polygon[i + j]) #LINE# #TAB# return result"
"#LINE# #TAB# if isinstance(data, h5py.highlevel.Dataset): #LINE# #TAB# #TAB# data = data.value #LINE# #TAB# if isinstance(data, np.ndarray): #LINE# #TAB# #TAB# try: #LINE# #TAB# #TAB# #TAB# return np.asarray(data) #LINE# #TAB# #TAB# except: #LINE# #TAB# #TAB# #TAB# return np.array(data) #LINE# #TAB# return data"
#LINE# #TAB# out = {} #LINE# #TAB# for record in records: #LINE# #TAB# #TAB# aaobj = AAIndexObject() #LINE# #TAB# #TAB# aaobj.id = record.id #LINE# #TAB# #TAB# out[record.id] = aaobj #LINE# #TAB# return out
"#LINE# #TAB# s = str(u) #LINE# #TAB# for c in string.ascii_letters: #LINE# #TAB# #TAB# if c in s: #LINE# #TAB# #TAB# #TAB# u = u.replace(c, foo(c)) #LINE# #TAB# return u"
"#LINE# #TAB# if object is True: #LINE# #TAB# #TAB# result = {'id': object.id, 'name': object.name} #LINE# #TAB# else: #LINE# #TAB# #TAB# result = {'id': object.id, 'name': 'bar'} #LINE# #TAB# return result"
"#LINE# #TAB# m = matrix[0] #LINE# #TAB# m = min(m, axis=0) #LINE# #TAB# m = max(m, axis=0) #LINE# #TAB# for i in range(0, scale): #LINE# #TAB# #TAB# m = min(m, axis=0) #LINE# #TAB# #TAB# matrix[i] = m #LINE# #TAB# return matrix"
#LINE# #TAB# if mimetype not in _mimetype_map: #LINE# #TAB# #TAB# return False #LINE# #TAB# if mimetype.startswith('image'): #LINE# #TAB# #TAB# return False #LINE# #TAB# return True
#LINE# #TAB# import os #LINE# #TAB# try: #LINE# #TAB# #TAB# s = os.stat(mypath) #LINE# #TAB# except OSError: #LINE# #TAB# #TAB# return 'unknown' #LINE# #TAB# else: #LINE# #TAB# #TAB# return 'file'
"#LINE# #TAB# ""Handle a response from the newton API"" #LINE# #TAB# if response.status_code == 200: #LINE# #TAB# #TAB# data = response.json() #LINE# #TAB# #TAB# return data['id']"
"#LINE# #TAB# result = {} #LINE# #TAB# for k, v in data.items(): #LINE# #TAB# #TAB# result[k] = v #LINE# #TAB# return result"
#LINE# #TAB# print('ignoring exception') #LINE# #TAB# raise exn
#LINE# #TAB# curve = cls(name) #LINE# #TAB# curve.generate() #LINE# #TAB# return curve
"#LINE# #TAB# import sys #LINE# #TAB# if not hasattr(stream, 'buffer'): #LINE# #TAB# #TAB# stream.seek(0) #LINE# #TAB# #TAB# try: #LINE# #TAB# #TAB# #TAB# data = stream.read(8192) #LINE# #TAB# #TAB# except: #LINE# #TAB# #TAB# #TAB# return False #LINE# #TAB# #TAB# stream.seek(0) #LINE# #TAB# #TAB# return data"
"#LINE# #TAB# assert isinstance(model, Model) #LINE# #TAB# pred = predicate #LINE# #TAB# for binding in model.binding_set: #LINE# #TAB# #TAB# present = False #LINE# #TAB# #TAB# for x in binding.operands: #LINE# #TAB# #TAB# #TAB# if x not in pred: #LINE# #TAB# #TAB# #TAB# #TAB# present = True #LINE# #TAB# #TAB# #TAB# #TAB# break #LINE# #TAB# #TAB# if present: #LINE# #TAB# #TAB# #TAB# yield binding #LINE# #TAB# if pred: #LINE# #TAB# #TAB# yield binding"
"#LINE# #TAB# alpha = 0 #LINE# #TAB# beta = 0 #LINE# #TAB# for i in range(A.shape[0]): #LINE# #TAB# #TAB# for j in range(A.shape[1]): #LINE# #TAB# #TAB# #TAB# alpha += ((A[i, j] - B[i, j]) ** 2 + (A[i, j] - B[i, j]) ** 2) / (alpha + #LINE# #TAB# #TAB# #TAB# #TAB# beta * beta) #LINE# #TAB# return alpha"
"#LINE# #TAB# if hasattr(structure, 'iteritems'): #LINE# #TAB# #TAB# return structure.iteritems() #LINE# #TAB# else: #LINE# #TAB# #TAB# return structure"
"#LINE# #TAB# return {'id': obj.id,'sectie': obj.sectie, 'capakey': obj.capakey, #LINE# #TAB# #TAB# 'percid': obj.percid}"
"#LINE# #TAB# if not os.path.isfile(path): #LINE# #TAB# #TAB# return None #LINE# #TAB# try: #LINE# #TAB# #TAB# with open(path, 'r') as f: #LINE# #TAB# #TAB# #TAB# return float(f.readline().strip()) #LINE# #TAB# except IOError: #LINE# #TAB# #TAB# pass"
"#LINE# #TAB# n_days = int(duration_in_seconds / 86400) #LINE# #TAB# minutes, seconds = divmod(n_days, 60) #LINE# #TAB# hours, minutes = divmod(minutes, 60) #LINE# #TAB# if hours == 0: #LINE# #TAB# #TAB# return f'{0:d}:{1:02d}:{2:02d}' #LINE# #TAB# elif minutes == 0: #LINE# #TAB# #TAB# return f'{0:d}:{1:02d}' #LINE# #TAB# else: #LINE# #TAB# #TAB# return f'{0:d}:{1:02d}:{2:02d}'"
#LINE# #TAB# cfg = VersioneerConfig() #LINE# #TAB# cfg.VCS = 'git' #LINE# #TAB# cfg.style = '%(STYLE)s' #LINE# #TAB# cfg.tag_prefix = '%(TAG_PREFIX)s' #LINE# #TAB# cfg.parentdir_prefix = '%(PARENTDIR_PREFIX)s' #LINE# #TAB# cfg.versionfile_source = '%(VERSIONFILE_SOURCE)s' #LINE# #TAB# cfg.verbose = False #LINE# #TAB# return cfg
#LINE# #TAB# for item in searchList: #LINE# #TAB# #TAB# yield item[0] #LINE# #TAB# for item in searchList: #LINE# #TAB# #TAB# yield item[1]
"#LINE# #TAB# cmd = ['tag', '-a', tag_name] #LINE# #TAB# if push: #LINE# #TAB# #TAB# cmd.append('-s') #LINE# #TAB# #TAB# cmd.append('--push') #LINE# #TAB# else: #LINE# #TAB# #TAB# cmd.append('--tag') #LINE# #TAB# cmd.append(tag_name) #LINE# #TAB# result = __salt__['cmd.run'](cmd, python_shell=False) #LINE# #TAB# if result.get('retcode')!= 0: #LINE# #TAB# #TAB# return result['stdout'] #LINE# #TAB# else: #LINE# #TAB# #TAB# return False"
"#LINE# #TAB# keymaps = Keymap() #LINE# #TAB# for raw_keymap in raw_keymaps: #LINE# #TAB# #TAB# x = Keymap.from_raw(raw_keymap) #LINE# #TAB# #TAB# y = Keymap.from_raw(raw_keymap) #LINE# #TAB# #TAB# keymaps.add(x, y) #LINE# #TAB# return keymaps"
"#LINE# #TAB# with open(fp, 'r') as f: #LINE# #TAB# #TAB# line = f.readline().strip() #LINE# #TAB# if not line: #LINE# #TAB# #TAB# return False #LINE# #TAB# if fp.endswith('.json'): #LINE# #TAB# #TAB# return json.loads(line) #LINE# #TAB# return True"
#LINE# #TAB# return node_cache.introspection_active( #LINE# #TAB# #TAB# ) or introspection.node_not_found_hook is not None
#LINE# #TAB# if string[0] == '@': #LINE# #TAB# #TAB# parts = string.split('@') #LINE# #TAB# #TAB# return parts[1] #LINE# #TAB# else: #LINE# #TAB# #TAB# return string
"#LINE# #TAB# for regex, replace in regexps: #LINE# #TAB# #TAB# content = re.sub(regex, replace, content) #LINE# #TAB# return content"
"#LINE# #TAB# if id_cols == None: #LINE# #TAB# #TAB# id_cols = df.columns #LINE# #TAB# invalid_ids = [] #LINE# #TAB# for col in id_cols: #LINE# #TAB# #TAB# if df[col].isnull().sum() > 0: #LINE# #TAB# #TAB# #TAB# invalid_ids.append(col) #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# df.dropna(inplace=True, axis=1, inplace=True) #LINE# #TAB# df = df.dropna(inplace=True, axis=1, inplace=True) #LINE# #TAB# return df"
"#LINE# #TAB# func = getattr(ofxget, 'foo') #LINE# #TAB# if func is not None: #LINE# #TAB# #TAB# return func(**args) #LINE# #TAB# return None"
"#LINE# #TAB# files = [f for f in os.listdir(directory) if os.path.isfile(os.path.join( #LINE# #TAB# #TAB# directory, f))] #LINE# #TAB# return files"
#LINE# #TAB# df = pd.DataFrame({field: pd.Timestamp(datetime.utcnow()).strftime( #LINE# #TAB# #TAB# '%Y-%m-%d %H:%M:%S')}) #LINE# #TAB# if expiration_ms is not None: #LINE# #TAB# #TAB# df['expiration_ms'] = expiration_ms #LINE# #TAB# else: #LINE# #TAB# #TAB# df[field] = pd.Timestamp(datetime.utcnow()).strftime( #LINE# #TAB# #TAB# #TAB# '%Y-%m-%d %H:%M:%S') #LINE# #TAB# return df
"#LINE# #TAB# for href, calendar in calendars: #LINE# #TAB# #TAB# if href == calendar: #LINE# #TAB# #TAB# #TAB# continue #LINE# #TAB# #TAB# yield href, calendar"
"#LINE# #TAB# if start > end: #LINE# #TAB# #TAB# begidx = get_begidx(text, start) #LINE# #TAB# #TAB# endidx = get_endidx(text, end) #LINE# #TAB# #TAB# return [(begidx, endidx)] #LINE# #TAB# return []"
#LINE# #TAB# print('Please enter your API key ( from'+ read_webapp_url() +'):') #LINE# #TAB# key = input('API key: ') #LINE# #TAB# if len(key)!= 32: #LINE# #TAB# #TAB# print('Please provide your API key: ') #LINE# #TAB# #TAB# return key #LINE# #TAB# else: #LINE# #TAB# #TAB# return None
"#LINE# #TAB# assert theta_units in ['radians', 'degrees'],\ #LINE# #TAB# #TAB# ""kwarg theta_units must specified in radians or degrees"" #LINE# #TAB# if theta_units == ""degrees"": #LINE# #TAB# #TAB# theta = np.degrees(np.arctan2(y, x)) #LINE# #TAB# elif theta_units == ""degrees"": #LINE# #TAB# #TAB# theta = np.arctan2(y, x) #LINE# #TAB# return theta"
"#LINE# #TAB# method = request.method.lower() #LINE# #TAB# method = request.method.lower() #LINE# #TAB# if method == 'GET': #LINE# #TAB# #TAB# result = resource.get(parent_resource=parent_resource) #LINE# #TAB# #TAB# if result is not None and isinstance(result, dict): #LINE# #TAB# #TAB# #TAB# return result #LINE# #TAB# #TAB# elif method == 'POST': #LINE# #TAB# #TAB# #TAB# return {'path': request.path, 'query_string': request.GET} #LINE# #TAB# #TAB# elif method == 'PUT': #LINE# #TAB# #TAB# #TAB# return {'path': request.path, 'query_string': request.GET} #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# return {'resource': resource, 'query_string': request.GET} #LINE# #TAB# else: #LINE# #TAB# #TAB# return {}"
"#LINE# #TAB# if renderer is None: #LINE# #TAB# #TAB# renderer = 'agg' #LINE# #TAB# try: #LINE# #TAB# #TAB# import matplotlib #LINE# #TAB# #TAB# renderer_module = import_module(renderer) #LINE# #TAB# except ImportError: #LINE# #TAB# #TAB# raise ImportError('renderer {} not found'.format(renderer)) #LINE# #TAB# renderer_module = getattr(matplotlib, renderer) #LINE# #TAB# renderer_func = getattr(matplotlib, renderer_module) #LINE# #TAB# return renderer_module, renderer_func"
"#LINE# #TAB# x = x[(...), ::-1] #LINE# #TAB# x[..., 0] -= 103.939 #LINE# #TAB# x[..., 1] -= 116.779 #LINE# #TAB# return x"
#LINE# #TAB# for e1 in G.es: #LINE# #TAB# #TAB# for e2 in G.es[e1]: #LINE# #TAB# #TAB# #TAB# if e1 == e2: #LINE# #TAB# #TAB# #TAB# #TAB# continue #LINE# #TAB# #TAB# #TAB# if e2 not in G.es[e1]: #LINE# #TAB# #TAB# #TAB# #TAB# G.es[e1][e2] = e1
#LINE# #TAB# with open(fn) as f: #LINE# #TAB# #TAB# return float(f.readline().split()[0]) / 1000.0
"#LINE# #TAB# out = [] #LINE# #TAB# default = defaults[0] #LINE# #TAB# for i, arg in enumerate(args): #LINE# #TAB# #TAB# if arg in defaults: #LINE# #TAB# #TAB# #TAB# out.append((arg, default)) #LINE# #TAB# #TAB# elif arg == '-': #LINE# #TAB# #TAB# #TAB# out.append((arg, default)) #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# out.append((arg, default)) #LINE# #TAB# return out"
#LINE# #TAB# value = data.extracted if data.extracted else False #LINE# #TAB# if value: #LINE# #TAB# #TAB# try: #LINE# #TAB# #TAB# #TAB# compound = Compound.objects.get(slug=value) #LINE# #TAB# #TAB# except Compound.DoesNotExist: #LINE# #TAB# #TAB# #TAB# return '' #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# return compound
"#LINE# #TAB# #TAB# if not pretty: #LINE# #TAB# #TAB# #TAB# s = repr(obj) #LINE# #TAB# #TAB# #TAB# if isinstance(obj, string_types): #LINE# #TAB# #TAB# #TAB# #TAB# s = s.replace('\n','' * indent) #LINE# #TAB# #TAB# #TAB# return s #LINE# #TAB# #TAB# elif isinstance(obj, tuple): #LINE# #TAB# #TAB# #TAB# s = ', '.join([ #LINE# #TAB# #TAB# #TAB# #TAB# get_repr(item, pretty=pretty, indent=indent) #LINE# #TAB# #TAB# #TAB# #TAB# for item in obj #LINE# #TAB# #TAB# #TAB# ]) #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# s = repr(obj) #LINE# #TAB# #TAB# return s"
#LINE# #TAB# open_index_failures = [] #LINE# #TAB# for index in indices: #LINE# #TAB# #TAB# try: #LINE# #TAB# #TAB# #TAB# open_index_failures.append(elastic_client.indices.open(index)) #LINE# #TAB# #TAB# except: #LINE# #TAB# #TAB# #TAB# open_index_failures.append(index) #LINE# #TAB# return open_index_failures
"#LINE# #TAB# mod = type(name, (types.ModuleType,), {}) #LINE# #TAB# mod.__dict__.update(code or {}) #LINE# #TAB# mod.__name__ = name #LINE# #TAB# return mod"
#LINE# #TAB# results = [] #LINE# #TAB# for obj in object_list: #LINE# #TAB# #TAB# results.append(foo(obj)) #LINE# #TAB# return results
"#LINE# #TAB# angles = np.asarray(angles, dtype=np.float64) #LINE# #TAB# if angles.ndim == 2: #LINE# #TAB# #TAB# return angles.reshape((-1, 3)).T #LINE# #TAB# elif angles.ndim == 3: #LINE# #TAB# #TAB# return angles.reshape((-1, 2)).T #LINE# #TAB# else: #LINE# #TAB# #TAB# return angles"
#LINE# #TAB# params['order_id'] = 0 #LINE# #TAB# return params
#LINE# #TAB# ret = [] #LINE# #TAB# for col in columns: #LINE# #TAB# #TAB# if col not in ret: #LINE# #TAB# #TAB# #TAB# ret.append(col) #LINE# #TAB# return ret
#LINE# #TAB# if epoch <= 0: #LINE# #TAB# #TAB# return lr * factor #LINE# #TAB# else: #LINE# #TAB# #TAB# return lr * factor
"#LINE# #TAB# cm = np.zeros_like(tpm) #LINE# #TAB# for i in range(tpm.shape[0]): #LINE# #TAB# #TAB# for j in range(tpm.shape[1]): #LINE# #TAB# #TAB# #TAB# cm[i, j] = 1 #LINE# #TAB# foo = np.zeros_like(tpm) #LINE# #TAB# for i in range(tpm.shape[1]): #LINE# #TAB# #TAB# for j in range(tpm.shape[1]): #LINE# #TAB# #TAB# #TAB# foo[i, j] = 1.0 / float(tpm[i, j]) #LINE# #TAB# return foo"
"#LINE# #TAB# for key in dir(network): #LINE# #TAB# #TAB# if key.startswith('_'): #LINE# #TAB# #TAB# #TAB# continue #LINE# #TAB# #TAB# if isinstance(network[key], dict): #LINE# #TAB# #TAB# #TAB# if key in network and isinstance(network[key], dict): #LINE# #TAB# #TAB# #TAB# #TAB# foo(network[key]) #LINE# #TAB# #TAB# #TAB# elif isinstance(network[key], (list, tuple)): #LINE# #TAB# #TAB# #TAB# #TAB# for item in network[key]: #LINE# #TAB# #TAB# #TAB# #TAB# #TAB# foo(item) #LINE# #TAB# return network"
"#LINE# #TAB# d = {} #LINE# #TAB# for f in file_dict: #LINE# #TAB# #TAB# with open(f, 'r') as f: #LINE# #TAB# #TAB# #TAB# data = f.read() #LINE# #TAB# #TAB# d[f] = data #LINE# #TAB# return d"
"#LINE# #TAB# if isinstance(sql, six.string_types): #LINE# #TAB# #TAB# args = sql, #LINE# #TAB# else: #LINE# #TAB# #TAB# args = sql, #LINE# #TAB# metrics = Metrics() #LINE# #TAB# for line in args: #LINE# #TAB# #TAB# values = line.split() #LINE# #TAB# #TAB# if len(values) == 2: #LINE# #TAB# #TAB# #TAB# metrics.add_metric(values[0], values[1]) #LINE# #TAB# #TAB# elif len(values) == 4: #LINE# #TAB# #TAB# #TAB# metrics.add_metric(values[0], values[1]) #LINE# #TAB# return metrics"
#LINE# #TAB# try: #LINE# #TAB# #TAB# ct = ContentType.objects.get(slug=ct_name) #LINE# #TAB# except ContentType.DoesNotExist: #LINE# #TAB# #TAB# return None #LINE# #TAB# else: #LINE# #TAB# #TAB# return ct
#LINE# #TAB# if transform == 'a': #LINE# #TAB# #TAB# return 'c' #LINE# #TAB# elif transform == 'b': #LINE# #TAB# #TAB# return 'd' #LINE# #TAB# elif transform == 'c': #LINE# #TAB# #TAB# return 'a' #LINE# #TAB# else: #LINE# #TAB# #TAB# return 'e'
#LINE# #TAB# try: #LINE# #TAB# #TAB# return obj.__cause__ #LINE# #TAB# except AttributeError: #LINE# #TAB# #TAB# return obj
"#LINE# #TAB# if module_name not in sys.modules: #LINE# #TAB# #TAB# return [] #LINE# #TAB# module_dir = os.path.dirname(os.path.abspath(sys.modules[module_name])) #LINE# #TAB# paths = [os.path.join(module_dir, f) for f in os.listdir(module_dir) if #LINE# #TAB# #TAB# f.endswith('.py')] #LINE# #TAB# return paths"
"#LINE# #TAB# return ['val1', 'val2', 'val3', 'val4', 'val5', 'val6', 'val7', #LINE# #TAB# #TAB# 'val10', 'val11', 'val12', 'val13', 'val14', 'val15', 'val16', #LINE# #TAB# #TAB# 'val15']"
"#LINE# #TAB# s = get_cgi_field(form, key) #LINE# #TAB# return s is not None"
"#LINE# #TAB# if not element: #LINE# #TAB# #TAB# return {} #LINE# #TAB# out = {} #LINE# #TAB# for child in element: #LINE# #TAB# #TAB# if child.tag == 'k': #LINE# #TAB# #TAB# #TAB# foo = foo(child) #LINE# #TAB# #TAB# elif child.tag == 'v': #LINE# #TAB# #TAB# #TAB# foo = foo(child) #LINE# #TAB# #TAB# elif child.tag == 'date': #LINE# #TAB# #TAB# #TAB# foo = foo(child) #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# out[child.tag] = {'tag': child.tag, 'value': str(child.text)} #LINE# #TAB# return out"
"#LINE# #TAB# with open(in_file) as in_handle: #LINE# #TAB# #TAB# in_handle.readline() #LINE# #TAB# #TAB# for line in in_handle: #LINE# #TAB# #TAB# #TAB# if line.startswith(""#""): #LINE# #TAB# #TAB# #TAB# #TAB# parts = line.split("" "") #LINE# #TAB# #TAB# #TAB# #TAB# if len(parts) == 3: #LINE# #TAB# #TAB# #TAB# #TAB# #TAB# chrom, start, end = parts #LINE# #TAB# #TAB# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# #TAB# #TAB# chrom = parts[0] #LINE# #TAB# #TAB# #TAB# #TAB# #TAB# start = int(start) #LINE# #TAB# #TAB# #TAB# #TAB# end = int(end) #LINE# #TAB# return chrom, start, end"
#LINE# #TAB# l = [] #LINE# #TAB# try: #LINE# #TAB# #TAB# with open('/etc/machine-id') as f: #LINE# #TAB# #TAB# #TAB# for line in f: #LINE# #TAB# #TAB# #TAB# #TAB# l.append(line.rstrip()) #LINE# #TAB# except IOError: #LINE# #TAB# #TAB# return 'unknown' #LINE# #TAB# if sys.platform.startswith('win'): #LINE# #TAB# #TAB# return str(os.getpid()) #LINE# #TAB# else: #LINE# #TAB# #TAB# return l[0]
#LINE# #TAB# if not context: #LINE# #TAB# #TAB# return False #LINE# #TAB# if context.is_admin: #LINE# #TAB# #TAB# return False #LINE# #TAB# if not context.user or not context.project: #LINE# #TAB# #TAB# return False #LINE# #TAB# return True
#LINE# #TAB# try: #LINE# #TAB# #TAB# profile_obj = boto3.Session(profile_name=profile) #LINE# #TAB# #TAB# return profile_obj.get_account_number() #LINE# #TAB# except ClientError as e: #LINE# #TAB# #TAB# print(e.response['Error']['Message']) #LINE# #TAB# #TAB# return 'fail'
"#LINE# #TAB# d = data.copy() #LINE# #TAB# d.loc[d['peak_value'] < 3, 'peak_value'] = 0 #LINE# #TAB# d = d.drop(['peak_value', 'peak_value'], axis=1) #LINE# #TAB# d = d.loc[d['peak_value'] > 3, 'peak_value'] #LINE# #TAB# e = d.loc[d['peak_value'] < 3, 'value'] #LINE# #TAB# f = d.loc[d['peak_value'] > 3, 'value'] #LINE# #TAB# d = f.drop(['peak_value', 'value'], axis=1) #LINE# #TAB# out = data.loc[f].copy() #LINE# #TAB# return out"
"#LINE# #TAB# if operand_name_list is None: #LINE# #TAB# #TAB# operand_name_list = [] #LINE# #TAB# res = [] #LINE# #TAB# for operand in operand_list: #LINE# #TAB# #TAB# if isinstance(operand, ArrayLike): #LINE# #TAB# #TAB# #TAB# res.extend(foo(operand, operand_name_list)) #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# res.append(operand) #LINE# #TAB# return res"
"#LINE# #TAB# try: #LINE# #TAB# #TAB# s = socket.socket(socket.AF_INET, socket.SOCK_STREAM) #LINE# #TAB# #TAB# s.connect(('localhost', 80)) #LINE# #TAB# #TAB# s.close() #LINE# #TAB# #TAB# return'rest_host' #LINE# #TAB# except: #LINE# #TAB# #TAB# return 'localhost'"
"#LINE# #TAB# with open(filename, 'r') as f: #LINE# #TAB# #TAB# lc_input_data = pickle.load(f) #LINE# #TAB# return lc_input_data"
"#LINE# #TAB# if signature[0:4]!= '----': #LINE# #TAB# #TAB# return f'<{signature}>' #LINE# #TAB# result = f'<{signature}>' #LINE# #TAB# for i in range(1, len(signature)): #LINE# #TAB# #TAB# if 'type' in signature[i]: #LINE# #TAB# #TAB# #TAB# result += f'Typedef {signature[i - 1]}' #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# result += f'<{signature[i]}>' #LINE# #TAB# return result"
#LINE# #TAB# for bp in blueprints: #LINE# #TAB# #TAB# if bp.has_static_folder: #LINE# #TAB# #TAB# #TAB# del bp.static_folder
"#LINE# #TAB# client = _create_client() #LINE# #TAB# client.table(table_name) #LINE# #TAB# with client.begin(): #LINE# #TAB# #TAB# duration = int(round(now() - utc_hour, 2)) #LINE# #TAB# #TAB# while True: #LINE# #TAB# #TAB# #TAB# data = client.get(table_name) #LINE# #TAB# #TAB# #TAB# if data['startTime'] is None: #LINE# #TAB# #TAB# #TAB# #TAB# break #LINE# #TAB# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# #TAB# data['startTime'] = data['startTime'] - timedelta(seconds= #LINE# #TAB# #TAB# #TAB# #TAB# #TAB# duration) #LINE# #TAB# #TAB# #TAB# #TAB# yield data"
#LINE# #TAB# for key in keys: #LINE# #TAB# #TAB# if key in fromDic and fromDic[key]!= toDic[key]: #LINE# #TAB# #TAB# #TAB# del fromDic[key]
"#LINE# #TAB# sources = [] #LINE# #TAB# for item in sourcelist: #LINE# #TAB# #TAB# if len(item) == 4: #LINE# #TAB# #TAB# #TAB# source = Source(url=item[0], title=item[3], url=item[1]) #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# source = Source(url=item, title=item[0], title=item[1], url= #LINE# #TAB# #TAB# #TAB# #TAB# item[2], url=item[3]) #LINE# #TAB# #TAB# sources.append(source) #LINE# #TAB# return sources"
"#LINE# #TAB# dirs = [] #LINE# #TAB# files = os.listdir(package) #LINE# #TAB# for name in files: #LINE# #TAB# #TAB# full_name = package + '.' + name #LINE# #TAB# #TAB# if os.path.isdir(full_name): #LINE# #TAB# #TAB# #TAB# dirs.append(full_name) #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# files.append(full_name) #LINE# #TAB# #TAB# yield full_name, dirs, files #LINE# #TAB# try: #LINE# #TAB# #TAB# yield package, top, dirs #LINE# #TAB# except OSError: #LINE# #TAB# #TAB# pass"
#LINE# #TAB# p = BiopaxProcessor() #LINE# #TAB# p.add_model(model) #LINE# #TAB# return p
#LINE# #TAB# opener = urllib.request.build_opener(*get_handlers()) #LINE# #TAB# urllib.request.install_opener(opener) #LINE# #TAB# return opener
"#LINE# #TAB# scores = {} #LINE# #TAB# exemplar_followers = set() #LINE# #TAB# for followers in exemplars.values(): #LINE# #TAB# #TAB# exemplar_followers |= followers #LINE# #TAB# for brand, followers in brands: #LINE# #TAB# #TAB# scores[brand] = _foo(followers, exemplar_followers) #LINE# #TAB# return scores"
"#LINE# #TAB# gy = year - 1 + EPOCH_GREGORIAN_YEAR #LINE# #TAB# if month!= 20: #LINE# #TAB# #TAB# m = 0 #LINE# #TAB# elif gregorian.leap(gy + 1): #LINE# #TAB# #TAB# m = -14 #LINE# #TAB# elif gregorian.leap(gy + 1): #LINE# #TAB# #TAB# m = -15 #LINE# #TAB# else: #LINE# #TAB# #TAB# m = 0 #LINE# #TAB# return gregorian.to_jd(gy, 3, 20) + 19 * (month - 1) + m + day"
"#LINE# #TAB# try: #LINE# #TAB# #TAB# data = response.json() #LINE# #TAB# #TAB# if ""error_description"" in data: #LINE# #TAB# #TAB# #TAB# return data['error_description'] #LINE# #TAB# #TAB# if ""error"" in data: #LINE# #TAB# #TAB# #TAB# return data['error'] #LINE# #TAB# except Exception: #LINE# #TAB# #TAB# pass #LINE# #TAB# return ""Unknown error"""
"#LINE# #TAB# lexer, ext = os.path.splitext(file_name) #LINE# #TAB# if ext == '.py': #LINE# #TAB# #TAB# lexer = pygments.lex.PygmentsLexer() #LINE# #TAB# elif ext == '.txt': #LINE# #TAB# #TAB# lexer = pygments.lex.TextLexer() #LINE# #TAB# elif ext == '.txt': #LINE# #TAB# #TAB# lexer = pygments.lex.TextLexer() #LINE# #TAB# return lexer, text"
#LINE# #TAB# try: #LINE# #TAB# #TAB# module = __import__(module) #LINE# #TAB# #TAB# return module #LINE# #TAB# except: #LINE# #TAB# #TAB# return None
"#LINE# #TAB# if index is None: #LINE# #TAB# #TAB# return f'0{count}' #LINE# #TAB# if isinstance(index, int): #LINE# #TAB# #TAB# return f'0{index}' #LINE# #TAB# if isinstance(index, str): #LINE# #TAB# #TAB# return index #LINE# #TAB# index = int(index) #LINE# #TAB# if count < 1: #LINE# #TAB# #TAB# return f'0{index}' #LINE# #TAB# return f'{index}{count}'"
"#LINE# #TAB# key = rsa.load_private_key(b64decode(privkeystring), backend=default_backend()) #LINE# #TAB# inp = base64.b64decode(inp) #LINE# #TAB# outp = b'' #LINE# #TAB# if len(outp)!= 64: #LINE# #TAB# #TAB# raise DecryptionFailed('invalid private key length: {0}'.format(len(outp))) #LINE# #TAB# out = outp.decrypt(b64decode(privkey)) #LINE# #TAB# inp = inp.decode('utf-8') #LINE# #TAB# return out"
"#LINE# #TAB# version_string = version_string.strip() #LINE# #TAB# if version_string.startswith(""0.""): #LINE# #TAB# #TAB# release, major, minor = version_string.split(""."") #LINE# #TAB# else: #LINE# #TAB# #TAB# release, major, minor = version_string.split(""."") #LINE# #TAB# return release, major, minor"
#LINE# #TAB# cores = 1 #LINE# #TAB# try: #LINE# #TAB# #TAB# queue_size = pprocess.QueueSize(limit=cores) #LINE# #TAB# except: #LINE# #TAB# #TAB# pass #LINE# #TAB# else: #LINE# #TAB# #TAB# try: #LINE# #TAB# #TAB# #TAB# queue_size = pprocess.QueueSize(limit=cores) #LINE# #TAB# #TAB# except: #LINE# #TAB# #TAB# #TAB# pass #LINE# #TAB# #TAB# if queue_size == 1: #LINE# #TAB# #TAB# #TAB# cores = 1 #LINE# #TAB# return cores
#LINE# #TAB# login = args['login'] #LINE# #TAB# password = args['password'] #LINE# #TAB# if login == '': #LINE# #TAB# #TAB# print('Invalid username or password. Use --login instead.') #LINE# #TAB# #TAB# sys.exit(1) #LINE# #TAB# if password == '': #LINE# #TAB# #TAB# print('Invalid password. Use --password again.') #LINE# #TAB# #TAB# sys.exit(2) #LINE# #TAB# return 0
"#LINE# #TAB# update_clause = '' #LINE# #TAB# for key, value in dictionary.items(): #LINE# #TAB# #TAB# if value is not None: #LINE# #TAB# #TAB# #TAB# update_clause +='{0} = {1}'.format(key, value) #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# update_clause +='{0} = {1}'.format(key, value) #LINE# #TAB# return update_clause"
#LINE# #TAB# if ';' not in line: #LINE# #TAB# #TAB# return line #LINE# #TAB# cmd = line.split(';') #LINE# #TAB# if len(cmd) > 1: #LINE# #TAB# #TAB# return cmd[0] #LINE# #TAB# else: #LINE# #TAB# #TAB# return cmd
#LINE# #TAB# nmea_degrees = str(nmea_degrees) #LINE# #TAB# if nmea_degrees[0] == '-': #LINE# #TAB# #TAB# return nmea_degrees #LINE# #TAB# elif nmea_degrees[0] == '+': #LINE# #TAB# #TAB# return nmea_degrees #LINE# #TAB# else: #LINE# #TAB# #TAB# return '-' + nmea_degrees
"#LINE# #TAB# _data = get_info(game_id, gameweek) #LINE# #TAB# picks = _data['picks'] #LINE# #TAB# for i in range(0, len(picks)): #LINE# #TAB# #TAB# if i == team_id: #LINE# #TAB# #TAB# #TAB# return picks[i] #LINE# #TAB# return None"
#LINE# #TAB# if event.in_place: #LINE# #TAB# #TAB# obj.signupsheet = False #LINE# #TAB# else: #LINE# #TAB# #TAB# obj.signupsheet = True
"#LINE# #TAB# if 'Authorization' not in request.headers: #LINE# #TAB# #TAB# return None #LINE# #TAB# auth = request.headers['Authorization'] #LINE# #TAB# if not auth: #LINE# #TAB# #TAB# return None #LINE# #TAB# if auth.startswith('Basic '): #LINE# #TAB# #TAB# username, password = auth.split(':') #LINE# #TAB# #TAB# return f'{username}:{password}' #LINE# #TAB# else: #LINE# #TAB# #TAB# return None"
#LINE# #TAB# weekday_string = vehicle_journey_element.get('weekday') #LINE# #TAB# if weekday_string is None: #LINE# #TAB# #TAB# return None #LINE# #TAB# if len(weekday_string) == 1: #LINE# #TAB# #TAB# return weekday_string[0] #LINE# #TAB# elif len(weekday_string) == 2: #LINE# #TAB# #TAB# return weekday_string[1] #LINE# #TAB# else: #LINE# #TAB# #TAB# return None
"#LINE# #TAB# errorCode = c_uint() #LINE# #TAB# try: #LINE# #TAB# #TAB# cdb = conf.lib.clang_CompilationDatabase_get(buildDir, #LINE# #TAB# #TAB# #TAB# byref(errorCode)) #LINE# #TAB# except CompilationDatabaseError as e: #LINE# #TAB# #TAB# raise CompilationDatabaseError(int(errorCode.value), #LINE# #TAB# #TAB# #TAB# 'CompilationDatabase loading failed') #LINE# #TAB# return cdb"
"#LINE# #TAB# dir_list = [] #LINE# #TAB# while True: #LINE# #TAB# #TAB# try: #LINE# #TAB# #TAB# #TAB# dir_list.append(os.path.dirname(os.path.realpath(__file__))) #LINE# #TAB# #TAB# except OSError: #LINE# #TAB# #TAB# #TAB# pass #LINE# #TAB# #TAB# try: #LINE# #TAB# #TAB# #TAB# dir_list.append(os.path.join(os.path.dirname(os.path.realpath(__file__)), #LINE# #TAB# #TAB# #TAB# #TAB# 'Steam')) #LINE# #TAB# #TAB# except OSError: #LINE# #TAB# #TAB# #TAB# pass #LINE# #TAB# return dir_list"
"#LINE# #TAB# res = [] #LINE# #TAB# for part in tag.split(','): #LINE# #TAB# #TAB# parts = part.split(':') #LINE# #TAB# #TAB# if len(parts) == 2: #LINE# #TAB# #TAB# #TAB# res.append(parts[0]) #LINE# #TAB# return res"
#LINE# #TAB# global _namespaces #LINE# #TAB# _namespaces[prefix] = namespace
#LINE# #TAB# if 'coldstart' in os.environ: #LINE# #TAB# #TAB# return 'true' #LINE# #TAB# return 'false'
"#LINE# #TAB# red = gl[0] #LINE# #TAB# green = gl[1] #LINE# #TAB# blue = gl[2] #LINE# #TAB# r = gl[3] #LINE# #TAB# v = gl[4] #LINE# #TAB# return red, green, blue, v"
#LINE# #TAB# old = logger.getLevel() #LINE# #TAB# logger.setLevel(level) #LINE# #TAB# yield #LINE# #TAB# logger.setLevel(old) #LINE# #TAB# del logger
#LINE# #TAB# start_activities = set() #LINE# #TAB# for node in dfg: #LINE# #TAB# #TAB# if node[0] == 'S': #LINE# #TAB# #TAB# #TAB# start_activities.add(node[1]) #LINE# #TAB# #TAB# elif node[0] == 'C': #LINE# #TAB# #TAB# #TAB# start_activities.add(node[1]) #LINE# #TAB# for node in dfg: #LINE# #TAB# #TAB# if node[0] == 'E': #LINE# #TAB# #TAB# #TAB# start_activities.add(node[1]) #LINE# #TAB# return start_activities
"#LINE# #TAB# result = None #LINE# #TAB# if os.path.exists(file_path): #LINE# #TAB# #TAB# with open(file_path, 'r') as f: #LINE# #TAB# #TAB# #TAB# result = f.read().split('.')[-1] #LINE# #TAB# return result"
"#LINE# #TAB# ret = [] #LINE# #TAB# for k, v in inspect.signature(func).parameters.items(): #LINE# #TAB# #TAB# if isinstance(v, param.Param): #LINE# #TAB# #TAB# #TAB# ret.append({'name': k, 'annotation': v}) #LINE# #TAB# #TAB# elif isinstance(v, list): #LINE# #TAB# #TAB# #TAB# ret.extend(foo(v)) #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# ret.append({'name': k, 'annotation': v}) #LINE# #TAB# return ret"
"#LINE# #TAB# resp = request.response #LINE# #TAB# resp.status = '200 OK' #LINE# #TAB# resp.content_type = 'text/html' #LINE# #TAB# resp.headers['X-Accel-Expires'] = 'Sat, 01 Dec 2001 00:00:00 GMT' #LINE# #TAB# return resp"
#LINE# #TAB# if is_forward_reference(typ): #LINE# #TAB# #TAB# typ = resolve_forward_reference(typ) #LINE# #TAB# #TAB# if typ is not None: #LINE# #TAB# #TAB# #TAB# return typ #LINE# #TAB# return 'is'
#LINE# #TAB# try: #LINE# #TAB# #TAB# return value.split('/')[-1].split('.')[0] #LINE# #TAB# except IndexError: #LINE# #TAB# #TAB# return value
"#LINE# #TAB# try: #LINE# #TAB# #TAB# if t.value.count('.') == 0: #LINE# #TAB# #TAB# #TAB# try: #LINE# #TAB# #TAB# #TAB# #TAB# t.value = int(t.value) #LINE# #TAB# #TAB# #TAB# except: #LINE# #TAB# #TAB# #TAB# #TAB# t.value = float(t.value) #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# t.value = float(t.value) #LINE# #TAB# except: #LINE# #TAB# #TAB# print('[%d]: Number %s is not valid!' % (t.lineno, t.value)) #LINE# #TAB# #TAB# t.value = 0 #LINE# #TAB# return t"
"#LINE# #TAB# ret = [] #LINE# #TAB# for i in _bytes: #LINE# #TAB# #TAB# ret.append(int(i, 16)) #LINE# #TAB# return ret"
#LINE# #TAB# Tr = 298.15 #LINE# #TAB# return abc[0] + abc[1] * (T - Tr) + abc[2] * (T - Tr) ** 2
"#LINE# #TAB# code = str(code) #LINE# #TAB# proj4 = utils.crscode_to_string(""esri"", code, ""proj4"") #LINE# #TAB# crs = from_proj4(proj4) #LINE# #TAB# return crs"
"#LINE# #TAB# norm = np.linalg.norm #LINE# #TAB# cosine = np.dot(v1, v2) / norm #LINE# #TAB# angle = np.arccos(cosine) #LINE# #TAB# return angle"
#LINE# #TAB# try: #LINE# #TAB# #TAB# module = import_module(module) #LINE# #TAB# #TAB# return module #LINE# #TAB# except ImportError: #LINE# #TAB# #TAB# return None
"#LINE# #TAB# from bs4 import BeautifulSoup #LINE# #TAB# from mezzanine.core.request import current_request #LINE# #TAB# request = current_request() #LINE# #TAB# if request is not None: #LINE# #TAB# #TAB# dom = BeautifulSoup(html, ""html.parser"") #LINE# #TAB# #TAB# for tag, attr in ABSOLUTE_URL_TAGS.items(): #LINE# #TAB# #TAB# #TAB# for node in dom.findAll(tag): #LINE# #TAB# #TAB# #TAB# #TAB# url = node.get(attr, """") #LINE# #TAB# #TAB# #TAB# #TAB# if url: #LINE# #TAB# #TAB# #TAB# #TAB# #TAB# node[attr] = request.build_absolute_uri(url) #LINE# #TAB# #TAB# html = str(dom) #LINE# #TAB# return html"
#LINE# #TAB# print('!') #LINE# #TAB# i = 0 #LINE# #TAB# while i < len(classes): #LINE# #TAB# #TAB# if classes[i] == 1: #LINE# #TAB# #TAB# #TAB# t = TP[i] #LINE# #TAB# #TAB# #TAB# n = TN[i] #LINE# #TAB# #TAB# elif classes[i] == 2: #LINE# #TAB# #TAB# #TAB# t = FP[i] #LINE# #TAB# #TAB# elif classes[i] == 3: #LINE# #TAB# #TAB# #TAB# f = FP[i] #LINE# #TAB# #TAB# elif classes[i] == 4: #LINE# #TAB# #TAB# #TAB# fn = FN[i] #LINE# #TAB# #TAB# #TAB# print('!') #LINE# #TAB# #TAB# i += 1
"#LINE# #TAB# if keys is None: #LINE# #TAB# #TAB# return orig_dict #LINE# #TAB# return {k: v for k, v in orig_dict.items() if k in keys}"
"#LINE# #TAB# try: #LINE# #TAB# #TAB# spike_idx = int(min_c * winlen) #LINE# #TAB# except ValueError: #LINE# #TAB# #TAB# return concept #LINE# #TAB# res = [concept[winlen == i] for i in range(min_c + 1, max_c + 1, winlen)] #LINE# #TAB# if min_neu and spike_idx >= min_z: #LINE# #TAB# #TAB# res.append(concept[min_c][spike_idx]) #LINE# #TAB# if min_c and spike_idx == max_c: #LINE# #TAB# #TAB# res.append(concept[min_z][spike_idx]) #LINE# #TAB# if max_neu and spike_idx == max_neu: #LINE# #TAB# #TAB# res.append(concept[max_z][spike_idx]) #LINE# #TAB# return res"
"#LINE# #TAB# bins = Bins() #LINE# #TAB# for i in range(num_bins): #LINE# #TAB# #TAB# p =probs[i] #LINE# #TAB# #TAB# c = np.exp(-p * p) #LINE# #TAB# #TAB# bins.fit(c, p) #LINE# #TAB# return bins"
"#LINE# #TAB# files = sorted(files, key=os.path.getmtime) #LINE# #TAB# return { #LINE# #TAB# #TAB#'size': psize, #LINE# #TAB# #TAB# 'hashes': [ #LINE# #TAB# #TAB# #TAB# hashlib.sha1(f.read()).hexdigest(), #LINE# #TAB# #TAB# #TAB# f.read() #LINE# #TAB# #TAB# #TAB# for f in files #LINE# #TAB# #TAB# ] #LINE# #TAB# }"
#LINE# #TAB# if string is True: #LINE# #TAB# #TAB# return True #LINE# #TAB# if string == 'False': #LINE# #TAB# #TAB# return False #LINE# #TAB# if string == 'None': #LINE# #TAB# #TAB# return False #LINE# #TAB# return string
#LINE# #TAB# if request.accept_language: #LINE# #TAB# #TAB# lang = request.accept_language.best_match(LANGUAGES) #LINE# #TAB# #TAB# if lang: #LINE# #TAB# #TAB# #TAB# return lang #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# return 'en' #LINE# #TAB# else: #LINE# #TAB# #TAB# return 'en'
"#LINE# #TAB# if len(array_one)!= len(array_two): #LINE# #TAB# #TAB# raise ValueError('arrays must be of same length') #LINE# #TAB# exp_diff = 0 #LINE# #TAB# for i in range(len(array_one)): #LINE# #TAB# #TAB# exp_diff += foo(array_one[i], array_two[i]) #LINE# #TAB# return exp_diff"
"#LINE# #TAB# y0, x0, y1, x1 = rectangle #LINE# #TAB# res = np.zeros(grid.shape, dtype=np.float64) #LINE# #TAB# res[:, (0)] = y0 #LINE# #TAB# res[:, (1)] = x0 #LINE# #TAB# res[:, (2)] = y0 #LINE# #TAB# res[:, (3)] = x1 #LINE# #TAB# res[:, (4)] = y1 #LINE# #TAB# res[:, (5)] = x1 #LINE# #TAB# res[:, (6)] = y1 #LINE# #TAB# return res"
"#LINE# #TAB# rst = '' #LINE# #TAB# if format: #LINE# #TAB# #TAB# format = format.lower() #LINE# #TAB# #TAB# rst += '-f'+ format + '\n' #LINE# #TAB# with open(filename, 'r') as f: #LINE# #TAB# #TAB# data = f.read() #LINE# #TAB# rst += data #LINE# #TAB# return rst"
"#LINE# #TAB# return get_origin(annotation) is dict and getattr(annotation, '_name', None #LINE# #TAB# #TAB# ) == 'Dict'"
#LINE# #TAB# event_msg = event.copy() #LINE# #TAB# event_msg['Date'] = arrow.utcnow().strftime('%Y-%m-%d %H:%M:%S') #LINE# #TAB# event_msg['Message'] = base64.b64encode(event_msg.get('Message')) #LINE# #TAB# event_msg['Date'] = arrow.utcnow().strftime('%Y-%m-%d') #LINE# #TAB# event_msg['Date'] = arrow.utcnow().strftime('%H:%M:%S') #LINE# #TAB# event_msg['MessageSecret'] = secret #LINE# #TAB# return event_msg
#LINE# #TAB# if skipUserInput: #LINE# #TAB# #TAB# return getpass('Enter password: ') #LINE# #TAB# else: #LINE# #TAB# #TAB# password = getpass('Enter password: ') #LINE# #TAB# #TAB# return password
#LINE# #TAB# if error_message is None: #LINE# #TAB# #TAB# error_message = 'No value given' #LINE# #TAB# val = row.get(name) #LINE# #TAB# if val is not None: #LINE# #TAB# #TAB# if len(val) > 0: #LINE# #TAB# #TAB# #TAB# return val #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# errors.append(error_message) #LINE# #TAB# return ''
"#LINE# #TAB# split = split_if_needed(args) #LINE# #TAB# commands = [] #LINE# #TAB# if not split: #LINE# #TAB# #TAB# return commands #LINE# #TAB# for i in range(1, len(args) + 1): #LINE# #TAB# #TAB# commands.append(args[i]) #LINE# #TAB# return commands"
"#LINE# #TAB# import socket #LINE# #TAB# s = socket.socket(socket.AF_INET, socket.SOCK_STREAM) #LINE# #TAB# s.connect(('8.8.8.8', 80)) #LINE# #TAB# s.getsockname() #LINE# #TAB# return s.getsockname()[0]"
"#LINE# #TAB# try: #LINE# #TAB# #TAB# with open('/proc/cpuinfo', 'r') as f: #LINE# #TAB# #TAB# #TAB# data = f.read() #LINE# #TAB# #TAB# #TAB# return data.split()[1] #LINE# #TAB# except Exception: #LINE# #TAB# #TAB# return 'error'"
"#LINE# #TAB# shapes = maya.cmds.ls(maya.cmds.listRelatives(geo, type='shape')) #LINE# #TAB# if not shapes: #LINE# #TAB# #TAB# return [] #LINE# #TAB# return [shape for shape in shapes if shape.type!='shape']"
"#LINE# #TAB# if isinstance(input, str): #LINE# #TAB# #TAB# return input #LINE# #TAB# try: #LINE# #TAB# #TAB# content_type = magic.from_bytes(input) #LINE# #TAB# except magic.UnknownMagicError: #LINE# #TAB# #TAB# return input #LINE# #TAB# else: #LINE# #TAB# #TAB# return content_type"
#LINE# #TAB# try: #LINE# #TAB# #TAB# return DateTime(text) #LINE# #TAB# except TypeError: #LINE# #TAB# #TAB# return None
"#LINE# #TAB# blueprint = Blueprint('', __name__, url_prefix='/', template_dir=os.path. #LINE# #TAB# #TAB# join(os.path.dirname(__file__), 'templates')) #LINE# #TAB# add_blueprint(blueprint, url_prefix='/', template_dir=os.path.join( #LINE# #TAB# #TAB# os.path.dirname(__file__), 'templates')) #LINE# #TAB# return blueprint"
#LINE# #TAB# if url.startswith('http') and url.endswith('/'): #LINE# #TAB# #TAB# url = url[len('http') + 1:] #LINE# #TAB# if url.endswith('/'): #LINE# #TAB# #TAB# url = url[:-1] #LINE# #TAB# return url
#LINE# #TAB# if 'break' in chromosome_plot_info: #LINE# #TAB# #TAB# columns = store.break_column(chromosome_plot_info['break']) #LINE# #TAB# elif 'number' in chromosome_plot_info: #LINE# #TAB# #TAB# columns = store.number_column(chromosome_plot_info['number']) #LINE# #TAB# else: #LINE# #TAB# #TAB# columns = store.column(chromosome_plot_info['break']) #LINE# #TAB# return columns
#LINE# #TAB# if prameter_type == 'quadrature': #LINE# #TAB# #TAB# kwargs['quadrature'] = True #LINE# #TAB# #TAB# if param in kwargs: #LINE# #TAB# #TAB# #TAB# kwargs[param] = kwargs[param] #LINE# #TAB# #TAB# elif param in path: #LINE# #TAB# #TAB# #TAB# kwargs[path] = kwargs[path] #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# kwargs[param] = path #LINE# #TAB# return kwargs
"#LINE# #TAB# import urlparse #LINE# #TAB# import os #LINE# #TAB# path = urlparse.urljoin( #LINE# #TAB# #TAB# urlparse.urlparse(url).netloc, #LINE# #TAB# #TAB# str(postfix)).path #LINE# #TAB# if not os.path.exists(path): #LINE# #TAB# #TAB# os.makedirs(path) #LINE# #TAB# return path"
#LINE# #TAB# entry = dict(entry) if entry else {} #LINE# #TAB# if not username: #LINE# #TAB# #TAB# username = getpass.getuser() #LINE# #TAB# if not prompt: #LINE# #TAB# #TAB# prompt = '%s:'% (username) #LINE# #TAB# if always_ask: #LINE# #TAB# #TAB# return getpass.getpass(prompt) #LINE# #TAB# try: #LINE# #TAB# #TAB# return getpass.getpass(prompt) #LINE# #TAB# except EOFError: #LINE# #TAB# #TAB# return None
#LINE# #TAB# fid1 = real_fid #LINE# #TAB# ret = complex(0) #LINE# #TAB# ret[0] = fid1 #LINE# #TAB# ret[1] = fid2str(fid1) #LINE# #TAB# return ret
"#LINE# #TAB# if PY2: #LINE# #TAB# #TAB# if isinstance(value, str): #LINE# #TAB# #TAB# #TAB# value = value.decode('utf-8') #LINE# #TAB# else: #LINE# #TAB# #TAB# value = str(value) #LINE# #TAB# return value"
"#LINE# #TAB# packet = p.Packet(MsgType.Base) #LINE# #TAB# packet.add_subpacket(p.Ack(BaseMsgCode.GetTimeSetRevB, AckCode.OK)) #LINE# #TAB# return packet"
"#LINE# #TAB# with settings(hide('stdout')): #LINE# #TAB# #TAB# res = subprocess.run(['git','rev-parse', '--show-toplevel'], stdin= #LINE# #TAB# #TAB# #TAB# subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.PIPE) #LINE# #TAB# if res.returncode == 0: #LINE# #TAB# #TAB# return res.stdout.strip() #LINE# #TAB# return None"
"#LINE# #TAB# text = re.sub(r'<(.*?)>', r'\1', text) #LINE# #TAB# text = re.sub(r'<(.*?)>', r'\1', text) #LINE# #TAB# if remove_url: #LINE# #TAB# #TAB# text = re.sub(r'<(.*?)>', r'\1', text) #LINE# #TAB# return text"
"#LINE# #TAB# if isinstance(x, str) and re.match(EMAIL_PATTERN, x): #LINE# #TAB# #TAB# return True #LINE# #TAB# else: #LINE# #TAB# #TAB# return False"
#LINE# #TAB# ret = salt.utils.mac_utils.execute_return_result( #LINE# #TAB# #TAB#'systemsetup -f foo') #LINE# #TAB# return salt.utils.mac_utils.validate_enabled( #LINE# #TAB# #TAB# #TAB# salt.utils.mac_utils.parse_return(ret)) == 'on'
#LINE# #TAB# try: #LINE# #TAB# #TAB# return socket.gethostbyname(hostname) #LINE# #TAB# except socket.error: #LINE# #TAB# #TAB# return None
"#LINE# #TAB# a, b, c, d, e, f = m #LINE# #TAB# if n & 1: #LINE# #TAB# #TAB# if g & 1!= 0: #LINE# #TAB# #TAB# #TAB# g >>= 1 #LINE# #TAB# #TAB# b = b + c #LINE# #TAB# elif n & 2: #LINE# #TAB# #TAB# if g & 3!= 0: #LINE# #TAB# #TAB# #TAB# b = b + d #LINE# #TAB# #TAB# f = f + g #LINE# #TAB# else: #LINE# #TAB# #TAB# return b #LINE# #TAB# try: #LINE# #TAB# #TAB# y = gf(a, b, c, d, e, f, g, s) #LINE# #TAB# except Exception: #LINE# #TAB# #TAB# return b #LINE# #TAB# else: #LINE# #TAB# #TAB# return b"
#LINE# #TAB# if T > 0: #LINE# #TAB# #TAB# return 1 / (T - 1) #LINE# #TAB# else: #LINE# #TAB# #TAB# return 0
"#LINE# #TAB# x2ys = np.asarray(x2ys) #LINE# #TAB# scores = np.zeros((x2ys.shape[0], n_trans)) #LINE# #TAB# for i in range(n_trans): #LINE# #TAB# #TAB# tmp = 0.0 #LINE# #TAB# #TAB# for j in range(x2ys.shape[0]): #LINE# #TAB# #TAB# #TAB# x2ys[i, j] = x2ys[i, j] / (2 * n_trans - 1) #LINE# #TAB# #TAB# #TAB# tmp += np.sum(np.log(x2ys[i, j]) - np.log(x2ys[j, i])) #LINE# #TAB# #TAB# scores[i, j] = tmp #LINE# #TAB# return scores"
"#LINE# #TAB# y_pos = np.sum(y == 1) #LINE# #TAB# y_neg = np.sum(y == -1) #LINE# #TAB# intercept = np.mean(y_pos) #LINE# #TAB# d_beta = safe_sparse_dot(X.T, intercept - y_pos) / X.shape[0] #LINE# #TAB# p = 1 / np.max([np.linalg.norm(d_beta[np.where(group_index == g)[0]], #LINE# #TAB# #TAB# 2) for g in range(0, len(group_index))]) #LINE# #TAB# return intercept, d_beta, p"
#LINE# #TAB# try: #LINE# #TAB# #TAB# if not peer.is_online(): #LINE# #TAB# #TAB# #TAB# return 'online' #LINE# #TAB# #TAB# if not peer.is_standby(): #LINE# #TAB# #TAB# #TAB# return'standby' #LINE# #TAB# #TAB# return 'online' #LINE# #TAB# except: #LINE# #TAB# #TAB# return'standby'
"#LINE# #TAB# return {'red': colour.red, 'green': colour.green, 'blue': colour.blue, #LINE# #TAB# #TAB# 'orange': colour.orange}"
#LINE# #TAB# if item_pid in cache.keys(): #LINE# #TAB# #TAB# return cache.get(item_pid) is not None #LINE# #TAB# return False
#LINE# #TAB# if filename.endswith('.pyc'): #LINE# #TAB# #TAB# return os.path.getmtime(filename) #LINE# #TAB# elif filename.endswith('.pyo'): #LINE# #TAB# #TAB# return os.path.getmtime(filename) #LINE# #TAB# return None
"#LINE# #TAB# root_path = os.path.abspath(os.curdir) #LINE# #TAB# while True: #LINE# #TAB# #TAB# if os.path.exists(os.path.join(root_path, nested_path)): #LINE# #TAB# #TAB# #TAB# return nested_path #LINE# #TAB# #TAB# next_path = os.path.abspath(os.path.join(root_path, os.pardir)) #LINE# #TAB# #TAB# if os.path.exists(next_path): #LINE# #TAB# #TAB# #TAB# return next_path"
#LINE# #TAB# if entry.path == '/': #LINE# #TAB# #TAB# return remote.file(entry.path) #LINE# #TAB# if entry.path == '': #LINE# #TAB# #TAB# return remote.directory(entry.path) #LINE# #TAB# return entry
"#LINE# #TAB# masking_rows = [] #LINE# #TAB# for i, row in enumerate(m): #LINE# #TAB# #TAB# if row.mask == masking_value: #LINE# #TAB# #TAB# #TAB# masking_rows.append(i) #LINE# #TAB# return masking_rows"
#LINE# #TAB# return p[0] >= rect[0] and p[1] <= rect[1] and p[2] >= rect[2 #LINE# #TAB# #TAB# ] and p[3] <= rect[3]
"#LINE# #TAB# return [np.dot(v, pole[:, (0)]) for v in vertices] if np.abs(np.dot( #LINE# #TAB# #TAB# v, pole[:, (0)]) > np.abs(np.dot(v, pole[:, (1)])) > #LINE# #TAB# #TAB# np.abs(np.dot(pole[:, (0)], pole[:, (1)])) > 0]"
"#LINE# #TAB# if is_module: #LINE# #TAB# #TAB# pattern = r'[\p{Ll}\p{Lu}\p{Nd}]+$' #LINE# #TAB# #TAB# word = re.sub(pattern, r'\1', word) #LINE# #TAB# else: #LINE# #TAB# #TAB# word = re.sub(pattern, r'\1', word) #LINE# #TAB# return word"
#LINE# #TAB# undeclared = set() #LINE# #TAB# for node in nodes: #LINE# #TAB# #TAB# if node.name not in names: #LINE# #TAB# #TAB# #TAB# undeclared.add(node.name) #LINE# #TAB# return undeclared
"#LINE# #TAB# with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s: #LINE# #TAB# #TAB# s.bind(('localhost', port)) #LINE# #TAB# #TAB# s.accept() #LINE# #TAB# #TAB# del s"
"#LINE# #TAB# try: #LINE# #TAB# #TAB# return resolver.query(dns_name, netaddr.IPNetwork(str(dns_name))) #LINE# #TAB# except dns.resolver.NXDOMAIN: #LINE# #TAB# #TAB# return set() #LINE# #TAB# except socket.error: #LINE# #TAB# #TAB# return set() #LINE# #TAB# except socket.error: #LINE# #TAB# #TAB# return set() #LINE# #TAB# return"
#LINE# #TAB# if options.cwd is not None: #LINE# #TAB# #TAB# cwd = options.cwd #LINE# #TAB# else: #LINE# #TAB# #TAB# cwd = os.getcwd() #LINE# #TAB# if not os.path.isdir(cwd): #LINE# #TAB# #TAB# sys.stderr.write( #LINE# #TAB# #TAB# #TAB# ) #LINE# #TAB# #TAB# sys.exit(1) #LINE# #TAB# return cwd
"#LINE# #TAB# records = [] #LINE# #TAB# for s in seeds: #LINE# #TAB# #TAB# if '@' in s: #LINE# #TAB# #TAB# #TAB# user, url = s.split('@') #LINE# #TAB# #TAB# #TAB# records.append((user, url)) #LINE# #TAB# #TAB# elif '|' in s: #LINE# #TAB# #TAB# #TAB# user, url = s.split('|') #LINE# #TAB# #TAB# #TAB# records.append((user, url)) #LINE# #TAB# return records"
"#LINE# #TAB# sha256_map: dict = {} #LINE# #TAB# if os.path.exists(directory) and os.path.isfile(directory): #LINE# #TAB# #TAB# files = [os.path.join(directory, path) for path in os.listdir( #LINE# #TAB# #TAB# #TAB# directory) if os.path.isfile(os.path.join(directory, path))] #LINE# #TAB# #TAB# for filepath in files: #LINE# #TAB# #TAB# #TAB# sha256_map.update({filepath: hashlib.sha256(filepath).hexdigest()}) #LINE# #TAB# return sha256_map"
#LINE# #TAB# if image.pixeltype!= 'unsigned char': #LINE# #TAB# #TAB# image = image.clone('unsigned char') #LINE# #TAB# idim = image.dimension #LINE# #TAB# vec = iio.ANTsVector() #LINE# #TAB# vec.data = image.data #LINE# #TAB# vec.ydim = image.dimension #LINE# #TAB# vec.width = image.width #LINE# #TAB# vec.height = image.height #LINE# #TAB# vec.transpose = 0 #LINE# #TAB# return vec
"#LINE# #TAB# try: #LINE# #TAB# #TAB# credential = context.client.get_credential(name) #LINE# #TAB# except Exception: #LINE# #TAB# #TAB# LOG.error(_('Unable to find a credential with name: %s'), name) #LINE# #TAB# #TAB# return False #LINE# #TAB# return credential"
#LINE# #TAB# if base_dict is None: #LINE# #TAB# #TAB# return extra_dict #LINE# #TAB# if extra_dict is None: #LINE# #TAB# #TAB# return base_dict #LINE# #TAB# result = base_dict.copy() #LINE# #TAB# result.update(extra_dict) #LINE# #TAB# return result
"#LINE# #TAB# tmp_dir = tempfile.mkdtemp() #LINE# #TAB# vault_client.thaw(path=tmp_dir, opt=opt) #LINE# #TAB# return tmp_dir"
"#LINE# #TAB# id, version = get_id_n_version(ident_hash) #LINE# #TAB# if id == None: #LINE# #TAB# #TAB# return None #LINE# #TAB# conn = cnx.connect() #LINE# #TAB# cursor = conn.cursor() #LINE# #TAB# query = 'SELECT * FROM cnx_epub WHERE id=%s' % id #LINE# #TAB# cursor.execute(query, (id, version)) #LINE# #TAB# result = {} #LINE# #TAB# for row in cursor: #LINE# #TAB# #TAB# result[row[0]] = row[1] #LINE# #TAB# conn.commit() #LINE# #TAB# return result"
"#LINE# #TAB# raw = get_raw_blast(pdb_id, chain_id, output_form) #LINE# #TAB# raw_blast = parse_blast(raw, output_form) #LINE# #TAB# return raw_blast"
#LINE# #TAB# global _foo #LINE# #TAB# _foo = guess
"#LINE# #TAB# data_stream.seek(start) #LINE# #TAB# for i in range(start, len(data_stream)): #LINE# #TAB# #TAB# byte = data_stream.read(1) #LINE# #TAB# #TAB# if not byte: #LINE# #TAB# #TAB# #TAB# return i #LINE# #TAB# return 0"
"#LINE# #TAB# fields = {'from': batch.sender, 'to': sorted(batch.recipients)} #LINE# #TAB# if batch.delivery_report: #LINE# #TAB# #TAB# fields['delivery_report'] = batch.delivery_report #LINE# #TAB# if batch.send_at: #LINE# #TAB# #TAB# fields['send_at'] = _mk_datetime(batch.send_at) #LINE# #TAB# if batch.expire_at: #LINE# #TAB# #TAB# fields['expire_at'] = _mk_datetime(batch.expire_at) #LINE# #TAB# if batch.tags: #LINE# #TAB# #TAB# fields['tags'] = sorted(batch.tags) #LINE# #TAB# if batch.callback_url: #LINE# #TAB# #TAB# fields['callback_url'] = batch.callback_url #LINE# #TAB# return fields"
"#LINE# #TAB# if power not in wg: #LINE# #TAB# #TAB# p1, p2 = power #LINE# #TAB# #TAB# if p1 == 0: #LINE# #TAB# #TAB# #TAB# return wg[0, p2] #LINE# #TAB# #TAB# if p2 == 1: #LINE# #TAB# #TAB# #TAB# return wg[1, p1] #LINE# #TAB# #TAB# return wg[0, p2] #LINE# #TAB# return wg[0, 0]"
#LINE# #TAB# if url not in settings.cache: #LINE# #TAB# #TAB# return None #LINE# #TAB# try: #LINE# #TAB# #TAB# response = requests.get(url) #LINE# #TAB# #TAB# if response.status_code == 200: #LINE# #TAB# #TAB# #TAB# response_json = response.json() #LINE# #TAB# except: #LINE# #TAB# #TAB# response_json = None #LINE# #TAB# #TAB# if response.status_code == 404: #LINE# #TAB# #TAB# #TAB# response_json = None #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# response_json = response.json() #LINE# #TAB# #TAB# settings.cache[url] = response_json #LINE# #TAB# return response_json
"#LINE# #TAB# params = '' #LINE# #TAB# for k in dic: #LINE# #TAB# #TAB# if isinstance(dic[k], str): #LINE# #TAB# #TAB# #TAB# params += str(dic[k]) +'' #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# params += str(dic[k]) +'' #LINE# #TAB# return params"
#LINE# #TAB# slots = loadConfig() #LINE# #TAB# if module is not None: #LINE# #TAB# #TAB# if name == module: #LINE# #TAB# #TAB# #TAB# return slots.get(name) #LINE# #TAB# for slot in slots: #LINE# #TAB# #TAB# if slot.name == name: #LINE# #TAB# #TAB# #TAB# return slot #LINE# #TAB# return None
"#LINE# #TAB# body_backbone_names = [f.name for f in body_backbone_CNN] #LINE# #TAB# image_backbone_names = [f.name for f in image_backbone_CNN] #LINE# #TAB# weights_filenames = ['{}-weights.csv'.format(body_backbone_names[0]) for #LINE# #TAB# #TAB# body_backbone_name in body_backbone_names] #LINE# #TAB# csvlogger_filenames = ['{}-image-backbone-{}'.format(body_backbone_names[1], #LINE# #TAB# #TAB# image_backbone_names[0]) for image_backbone_name in image_backbone_names] #LINE# #TAB# return weights_filenames, csvlogger_filenames"
"#LINE# #TAB# sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1) #LINE# #TAB# try: #LINE# #TAB# #TAB# data = sock.recv(struct.unpack('>i', data)) #LINE# #TAB# except socket.error: #LINE# #TAB# #TAB# return 0 #LINE# #TAB# out = int(data[0]) #LINE# #TAB# sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1) #LINE# #TAB# return out"
"#LINE# #TAB# n, m = covmatrix.shape #LINE# #TAB# nv = np.shape(covmatrix)[0] #LINE# #TAB# corrmatrix = np.zeros((n, n)) #LINE# #TAB# for i in range(m): #LINE# #TAB# #TAB# for j in range(n): #LINE# #TAB# #TAB# #TAB# corrmatrix[(i), (j), :] = np.corrcoef(covmatrix[(i), (j), :], #LINE# #TAB# #TAB# #TAB# #TAB# covmatrix[(i), (j), :]) #LINE# #TAB# return corrmatrix"
#LINE# #TAB# try: #LINE# #TAB# #TAB# x = str(pr_list[0]) #LINE# #TAB# #TAB# if len(pr_list) == 1: #LINE# #TAB# #TAB# #TAB# return x #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# return '(%s)' % x #LINE# #TAB# except: #LINE# #TAB# #TAB# return pr_list[0]
#LINE# #TAB# val = entry.get(prop) #LINE# #TAB# if not val: #LINE# #TAB# #TAB# return default #LINE# #TAB# if raw and val: #LINE# #TAB# #TAB# return val #LINE# #TAB# return val[0]
"#LINE# #TAB# if datatype == 'int8': #LINE# #TAB# #TAB# dbrcode = 1 #LINE# #TAB# elif datatype == 'uint8': #LINE# #TAB# #TAB# dbrcode = 2 #LINE# #TAB# elif datatype == 'uint16': #LINE# #TAB# #TAB# dbrcode = 3 #LINE# #TAB# elif datatype == 'uint32': #LINE# #TAB# #TAB# dbrcode = 4 #LINE# #TAB# else: #LINE# #TAB# #TAB# raise ValueError('Invalid data type: {}'.format(datatype)) #LINE# #TAB# return dbrcode, dtype"
"#LINE# #TAB# if mono: #LINE# #TAB# #TAB# window = np.hanning(n) + 1e-05 #LINE# #TAB# else: #LINE# #TAB# #TAB# window = np.array([np.hanning(n) + 1e-05, np.hanning(n) + 1e-05]) #LINE# #TAB# return window"
#LINE# #TAB# if cls.config == {}: #LINE# #TAB# #TAB# return True #LINE# #TAB# return False
"#LINE# #TAB# parser = BackendCommandArgumentParser(cls.BACKEND, from_date=True, #LINE# #TAB# #TAB# token_auth=True, archive=True) #LINE# #TAB# parser.add_argument('--host', default='localhost') #LINE# #TAB# parser.add_argument('--port', default=6379, type=int) #LINE# #TAB# return parser"
#LINE# #TAB# for index in indices: #LINE# #TAB# #TAB# yield sequence[index]
#LINE# #TAB# global _molgenis_version #LINE# #TAB# if _molgenis_version is None: #LINE# #TAB# #TAB# _molgenis_version = get_version() #LINE# #TAB# return _molgenis_version
"#LINE# #TAB# array = np.zeros((len(events), len(slots))) #LINE# #TAB# for row, event in enumerate(events): #LINE# #TAB# #TAB# for col, slot in enumerate(slots): #LINE# #TAB# #TAB# #TAB# if slot in event: #LINE# #TAB# #TAB# #TAB# #TAB# array[row, col] = 1 #LINE# #TAB# return array"
"#LINE# #TAB# for part in name.split('.'): #LINE# #TAB# #TAB# if part == import_: #LINE# #TAB# #TAB# #TAB# mod = sys.modules[part] #LINE# #TAB# #TAB# #TAB# return mod #LINE# #TAB# #TAB# parts = part.split('.') #LINE# #TAB# #TAB# if len(parts) == 2: #LINE# #TAB# #TAB# #TAB# submod = importlib.import_module('.'.join(parts[0:-1]), parts[-1]) #LINE# #TAB# #TAB# #TAB# try: #LINE# #TAB# #TAB# #TAB# #TAB# mod = getattr(submod, parts[-1]) #LINE# #TAB# #TAB# #TAB# #TAB# return mod #LINE# #TAB# #TAB# #TAB# except AttributeError: #LINE# #TAB# #TAB# #TAB# #TAB# pass #LINE# #TAB# raise ImportError"
#LINE# #TAB# if msg.get('type') == 'user': #LINE# #TAB# #TAB# key = msg['auth'] #LINE# #TAB# #TAB# if key in cfg.profile.auth: #LINE# #TAB# #TAB# #TAB# cfg.profile.auth[key] = msg['auth'] #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# cfg.profile.auth[key] = msg['auth'] #LINE# #TAB# #TAB# return 0 #LINE# #TAB# return 1
"#LINE# #TAB# path = os.path.join(_ROOT, 'items.json') #LINE# #TAB# items = read_json_file(path) #LINE# #TAB# for item_id in items: #LINE# #TAB# #TAB# if item_name == item_id: #LINE# #TAB# #TAB# #TAB# return item_id #LINE# #TAB# return False"
#LINE# #TAB# if value is None: #LINE# #TAB# #TAB# raise argparse.ArgumentTypeError(f'Value is required') #LINE# #TAB# if value <= lower: #LINE# #TAB# #TAB# return True #LINE# #TAB# return False
"#LINE# #TAB# try: #LINE# #TAB# #TAB# ret = (used / total) * 100 #LINE# #TAB# except ZeroDivisionError: #LINE# #TAB# #TAB# ret = 0 #LINE# #TAB# if round_ is not None: #LINE# #TAB# #TAB# ret = round(ret, round_) #LINE# #TAB# return ret"
#LINE# #TAB# if enabled: #LINE# #TAB# #TAB# return enabled #LINE# #TAB# if enabled == True: #LINE# #TAB# #TAB# return __repr__ == '__index__': #LINE# #TAB# #TAB# return 0 #LINE# #TAB# else: #LINE# #TAB# #TAB# return 1
#LINE# #TAB# for module in modules: #LINE# #TAB# #TAB# try: #LINE# #TAB# #TAB# #TAB# return importlib.import_module(module) #LINE# #TAB# #TAB# except ImportError: #LINE# #TAB# #TAB# #TAB# print('Failed to import {}'.format(module)) #LINE# #TAB# #TAB# #TAB# raise
"#LINE# #TAB# result = [] #LINE# #TAB# for k, v in d.items(): #LINE# #TAB# #TAB# if isinstance(v, dict): #LINE# #TAB# #TAB# #TAB# if which_key in v: #LINE# #TAB# #TAB# #TAB# #TAB# result.append((k, foo(v, which_key))) #LINE# #TAB# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# #TAB# result.append((k, v)) #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# result.append((k, v)) #LINE# #TAB# return result"
"#LINE# #TAB# with open(f, 'r') as f: #LINE# #TAB# #TAB# obj = cls.load(f) #LINE# #TAB# return obj"
"#LINE# #TAB# try: #LINE# #TAB# #TAB# if g.user: #LINE# #TAB# #TAB# #TAB# return g.user #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# return ""Couldn't get the logged in user"" #LINE# #TAB# except Exception: #LINE# #TAB# #TAB# return ""Couldn't get the logged in user"""
#LINE# #TAB# res = [] #LINE# #TAB# for w in waves: #LINE# #TAB# #TAB# if w in gaps: #LINE# #TAB# #TAB# #TAB# res.append(w) #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# break #LINE# #TAB# return res
#LINE# #TAB# if not depends: #LINE# #TAB# #TAB# return data #LINE# #TAB# res = [] #LINE# #TAB# for item in data: #LINE# #TAB# #TAB# req = depends.get(item) #LINE# #TAB# #TAB# if req: #LINE# #TAB# #TAB# #TAB# if req in res: #LINE# #TAB# #TAB# #TAB# #TAB# res.remove(req) #LINE# #TAB# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# #TAB# res.append(item) #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# res.append(item) #LINE# #TAB# return res
"#LINE# #TAB# req = requests.get(search) #LINE# #TAB# if ot is None: #LINE# #TAB# #TAB# ot = datetime.datetime.now() #LINE# #TAB# text = req.text #LINE# #TAB# if resultformat == 'brief': #LINE# #TAB# #TAB# text = clean_text(text) #LINE# #TAB# elif resultformat == 'list': #LINE# #TAB# #TAB# text = extract_list(text, ot) #LINE# #TAB# elif resultformat == 'dict': #LINE# #TAB# #TAB# text = extract_dict(text, ot) #LINE# #TAB# else: #LINE# #TAB# #TAB# raise ValueError('Unknown result format: {}'.format(resultformat)) #LINE# #TAB# return text"
"#LINE# #TAB# #TAB# return [goea.enrichment, #LINE# #TAB# #TAB# #TAB# #TAB# goea.namespace, #LINE# #TAB# #TAB# #TAB# #TAB# goea.depth, #LINE# #TAB# #TAB# #TAB# #TAB# goea.namespace_name, #LINE# #TAB# #TAB# #TAB# #TAB# goea.GO]"
#LINE# #TAB# try: #LINE# #TAB# #TAB# client.list_buckets() #LINE# #TAB# #TAB# return True #LINE# #TAB# except ClientError as e: #LINE# #TAB# #TAB# print(e.response['Error']['Message']) #LINE# #TAB# #TAB# return False
#LINE# #TAB# for col in columns: #LINE# #TAB# #TAB# df['_' + col] = df[col] * (1 / 3) #LINE# #TAB# return df
"#LINE# #TAB# sdm = getsdm(sdmname) #LINE# #TAB# sourcedict = {} #LINE# #TAB# for row in sdm['Field']: #LINE# #TAB# #TAB# src = str(row.fieldName) #LINE# #TAB# #TAB# sourcenum = int(row.sourceId) #LINE# #TAB# #TAB# direction = str(row.referenceDir) #LINE# #TAB# #TAB# (ra,dec) = [float(val) for val in direction.split(' ')[3:]] #LINE# #TAB# #TAB# sourcedict[sourcenum] = {} #LINE# #TAB# #TAB# sourcedict[sourcenum]['source'] = src #LINE# #TAB# #TAB# sourcedict[sourcenum]['ra'] = ra #LINE# #TAB# #TAB# sourcedict[sourcenum]['dec'] = dec #LINE# #TAB# return sourcedict"
"#LINE# #TAB# if's' in duration: #LINE# #TAB# #TAB# return '{0} s'.format(duration['s']) #LINE# #TAB# if'm' in duration: #LINE# #TAB# #TAB# return '{0} m {1}'.format(duration['m'], duration['s']) #LINE# #TAB# if 'h' in duration: #LINE# #TAB# #TAB# return '{0} h {1}'.format(duration['h'], duration['m']) #LINE# #TAB# return '{0} s'.format(duration['s'])"
"#LINE# #TAB# try: #LINE# #TAB# #TAB# with open('/etc/dwilib', 'r') as f: #LINE# #TAB# #TAB# #TAB# data = f.read() #LINE# #TAB# #TAB# #TAB# f.close() #LINE# #TAB# #TAB# #TAB# return True #LINE# #TAB# except Exception: #LINE# #TAB# #TAB# return False"
"#LINE# #TAB# m = re.match('(\\d+)-(\\d+)', s) #LINE# #TAB# if m: #LINE# #TAB# #TAB# return int(m.group(1)) #LINE# #TAB# else: #LINE# #TAB# #TAB# return s"
"#LINE# #TAB# if not tea_slug: #LINE# #TAB# #TAB# tea_slug = config.SITE.slug #LINE# #TAB# for request_addition in requested_additions: #LINE# #TAB# #TAB# if request_addition.addition == tea_slug: #LINE# #TAB# #TAB# #TAB# return ForbiddenCombinations( #LINE# #TAB# #TAB# #TAB# #TAB# request_addition, tea_slug=tea_slug) #LINE# #TAB# return None"
#LINE# #TAB# if is_runtime(): #LINE# #TAB# #TAB# return 'runtime' #LINE# #TAB# elif is_original(): #LINE# #TAB# #TAB# return 'original' #LINE# #TAB# elif is_frozen(): #LINE# #TAB# #TAB# return 'frozen' #LINE# #TAB# else: #LINE# #TAB# #TAB# return 'original'
#LINE# #TAB# t0 = time.time() #LINE# #TAB# resp = {} #LINE# #TAB# for ws in nb.worksheets: #LINE# #TAB# #TAB# for cell in ws.cells: #LINE# #TAB# #TAB# #TAB# if cell.cell_type == 'code': #LINE# #TAB# #TAB# #TAB# #TAB# cell.outputs = [''] #LINE# #TAB# #TAB# #TAB# #TAB# time.sleep(timeout) #LINE# #TAB# #TAB# #TAB# #TAB# resp['outputs'].append(cell) #LINE# #TAB# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# #TAB# resp['outputs'].append(cell) #LINE# #TAB# #TAB# time.sleep(timeout) #LINE# #TAB# return resp
#LINE# #TAB# if not os.path.isdir(dir_name): #LINE# #TAB# #TAB# raise ValueError('Not a directory') #LINE# #TAB# return dir_name
"#LINE# #TAB# from..forms.converter import convert_form_field #LINE# #TAB# args = {} #LINE# #TAB# for name, filter_field in six.iteritems(filterset_class.base_filters): #LINE# #TAB# #TAB# field_type = convert_form_field(filter_field.field).Argument() #LINE# #TAB# #TAB# field_type.description = filter_field.label #LINE# #TAB# #TAB# args[name] = field_type #LINE# #TAB# return args"
#LINE# #TAB# default_value = [] #LINE# #TAB# for i in range(len(initialparameters)): #LINE# #TAB# #TAB# default_value.append(initialparameters[i]) #LINE# #TAB# return default_value
#LINE# #TAB# if tree.tag == 'Document': #LINE# #TAB# #TAB# root = ElementTree.fromstring(tree.text) #LINE# #TAB# #TAB# return root #LINE# #TAB# elif tree.tag == 'Document': #LINE# #TAB# #TAB# root = ElementTree.fromstring(tree.find('Document')) #LINE# #TAB# #TAB# return foo(root) #LINE# #TAB# else: #LINE# #TAB# #TAB# return tree
#LINE# #TAB# oLine.comment = True #LINE# #TAB# oLine.sLine = ''
#LINE# #TAB# sym_set = set() #LINE# #TAB# for paradigm in paradigms: #LINE# #TAB# #TAB# for p in paradigm.pargs: #LINE# #TAB# #TAB# #TAB# if p.name in sym_set: #LINE# #TAB# #TAB# #TAB# #TAB# sym_set.add(p.name) #LINE# #TAB# return sym_set
#LINE# #TAB# import socket #LINE# #TAB# sock.close() #LINE# #TAB# thread.kill() #LINE# #TAB# return 0
"#LINE# #TAB# epoch = int(current_step / steps_per_epoch) #LINE# #TAB# loop = int(current_step % steps_per_loop) #LINE# #TAB# return epoch, loop, steps_per_epoch, steps_per_loop"
"#LINE# #TAB# if not reserved_tokens: #LINE# #TAB# #TAB# return [] #LINE# #TAB# parts = [t for t in reserved_tokens if t] #LINE# #TAB# pattern = '|'.join(parts) #LINE# #TAB# return [token for token in parts if re.match(pattern, token)]"
"#LINE# #TAB# for item in os.listdir(path): #LINE# #TAB# #TAB# fullpath = os.path.join(path, item) #LINE# #TAB# #TAB# if os.path.isdir(fullpath): #LINE# #TAB# #TAB# #TAB# for i in foo(fullpath): #LINE# #TAB# #TAB# #TAB# #TAB# os.remove(i) #LINE# #TAB# #TAB# return"
#LINE# #TAB# try: #LINE# #TAB# #TAB# return cls._response_queue.get(timeout=0) #LINE# #TAB# except Empty: #LINE# #TAB# #TAB# return None
"#LINE# #TAB# normvectpart = np.sqrt(quat[0] ** 2 + quat[1] ** 2 + quat[2] ** 2 + #LINE# #TAB# #TAB# quat[3] ** 2) #LINE# #TAB# angle = np.arccos(quat[3] / normvectpart) * 2.0 #LINE# #TAB# unitvec = np.array(quat[:3]) / np.sin(angle / 2) / normvectpart #LINE# #TAB# return unitvec, angle"
"#LINE# #TAB# data = pd.read_table(filepath, names=['OTU', 'Taxonomy']) #LINE# #TAB# data = data.drop(['OTU', 'Taxonomy']) #LINE# #TAB# data.index = data.index.rename(None) #LINE# #TAB# data = data.sort_index() #LINE# #TAB# return data"
#LINE# #TAB# tags = [] #LINE# #TAB# for tag in ds.tags: #LINE# #TAB# #TAB# if tag!= 'PRIVATE': #LINE# #TAB# #TAB# #TAB# tags.append(tag) #LINE# #TAB# return tags
"#LINE# #TAB# oligo_id = oligo_dict[contents[0]] #LINE# #TAB# for i in range(1, nchains): #LINE# #TAB# #TAB# s = oligo_dict[contents[i]] #LINE# #TAB# #TAB# if s in oligo_id: #LINE# #TAB# #TAB# #TAB# return oligo_id"
"#LINE# #TAB# outer_dict = {} #LINE# #TAB# inner_dict = {} #LINE# #TAB# for k1, v in nested_dict.items(): #LINE# #TAB# #TAB# try: #LINE# #TAB# #TAB# #TAB# outer_dict[k1] = foo(v) #LINE# #TAB# #TAB# except (KeyError, ValueError): #LINE# #TAB# #TAB# #TAB# inner_dict[k1] = foo(v) #LINE# #TAB# return outer_dict, inner_dict"
#LINE# #TAB# data = {'event_id': game_id} #LINE# #TAB# r = requests.get(BASE_URL.format(**data)) #LINE# #TAB# r.raise_for_status() #LINE# #TAB# if r.status_code == 200: #LINE# #TAB# #TAB# return json.loads(r.text) #LINE# #TAB# return {}
#LINE# #TAB# status = data['headers']['status'] #LINE# #TAB# if status == Status.SUCCESS.value: #LINE# #TAB# #TAB# Memory.leave_room = data['room']
"#LINE# #TAB# parser.add_argument('--os-data-protection-api-version', metavar= #LINE# #TAB# #TAB# '<data-protection-api-version>', default=utils.env( #LINE# #TAB# #TAB# 'OS_DATA_PROTECTION_API_VERSION', default= #LINE# #TAB# #TAB# DEFAULT_DATA_PROTECTION_API_VERSION), help= #LINE# #TAB# #TAB# 'Data protection API version, default=' + #LINE# #TAB# #TAB# DEFAULT_DATA_PROTECTION_API_VERSION + #LINE# #TAB# #TAB#'(Env: OS_DATA_PROTECTION_API_VERSION)') #LINE# #TAB# return parser"
"#LINE# #TAB# with open(path, 'r') as f: #LINE# #TAB# #TAB# box_list = f.read().split('\n') #LINE# #TAB# #TAB# x = int(box_list[0]) #LINE# #TAB# #TAB# y = int(box_list[1]) #LINE# #TAB# #TAB# width = float(box_list[2]) #LINE# #TAB# #TAB# height = float(box_list[3]) #LINE# #TAB# #TAB# bbox = [('x' + str(x), 'y' + str(y), 'width' + str(width)), ( #LINE# #TAB# #TAB# #TAB# 'height' + str(height), 'height')] #LINE# #TAB# return bbox"
#LINE# #TAB# if value is not None: #LINE# #TAB# #TAB# return value.strip() #LINE# #TAB# return None
"#LINE# #TAB# with open(model_path, 'rb') as f: #LINE# #TAB# #TAB# image = f.read() #LINE# #TAB# image_shape = image.shape #LINE# #TAB# x = np.arange(image_shape[0]).reshape((image_shape[1], image_shape[2])) #LINE# #TAB# y = np.arange(image_shape[1]).reshape((image_shape[2], image_shape[3])) #LINE# #TAB# return x, y"
"#LINE# #TAB# assert isinstance(archive_table, Table) #LINE# #TAB# assert archive_table.version_column =='version' #LINE# #TAB# order_clause = sa.asc(archive_table.version_constraint) + sa.asc(archive_table #LINE# #TAB# #TAB#.version_column) #LINE# #TAB# return order_clause"
"#LINE# #TAB# return cls.objects.filter(category__in=cls.categories.values_list( #LINE# #TAB# #TAB#'model_name', flat=True))[:2]"
"#LINE# results = {} #LINE# fname = pkg_resources.resource_filename(__name__,'resources/Latitudes-Longitudes.csv') #LINE# with open(fname, 'rU') as csvfile: #LINE# #TAB# reader = csv.reader(csvfile, delimiter = ',') #LINE# #TAB# for row in reader: #LINE# #TAB# results[row[0]] = row[1] #LINE# return results"
"#LINE# #TAB# keys = p[0] #LINE# #TAB# for i in range(1, len(keys)): #LINE# #TAB# #TAB# p[keys[i]] = p[1] #LINE# #TAB# return p"
"#LINE# #TAB# r = requests.get(url='{}scenarios/{}'.format(LIZARD_URL, scenario_uuid), #LINE# #TAB# #TAB# headers=get_headers()) #LINE# #TAB# r.raise_for_status() #LINE# #TAB# return r.text"
"#LINE# #TAB# if params: #LINE# #TAB# #TAB# s = '? params:' #LINE# #TAB# #TAB# for k, v in params.items(): #LINE# #TAB# #TAB# #TAB# s += '%s = %s\n' % (k, v) #LINE# #TAB# else: #LINE# #TAB# #TAB# s = '? params:' #LINE# #TAB# return s"
"#LINE# #TAB# return [('flagged', random.randint(1, 999999999), ('flagged', random.randint( #LINE# #TAB# #TAB# 1, 999999999)), ('flagged', random.randint(1, 999999999)), ('flagged', #LINE# #TAB# #TAB# random.randint(1, 999999999)), ('flagged', random.randint(1, 999999999)), #LINE# #TAB# #TAB# ('flagged', random.randint(1, 999999999)), ('flagged', random.randint( #LINE# #TAB# #TAB# 1, 999999999)), ('flagged', random.randint(1, 999999999)), ('flagged', #LINE# #TAB# #TAB# random.randint(1, 999999999)), ('flagged', random.randint(1, 999999999)), ( #LINE# #TAB# #TAB# 'flagged', random.randint(1, 999999999)), ('flagged', random. #LINE# #TAB# #TAB# randint(1, 999999999))]"
"#LINE# #TAB# status = subprocess.call((git_path, 'log', '-1', '--pretty=format:%h'), #LINE# #TAB# #TAB# #TAB# #TAB# #TAB# #TAB# #TAB# stdout=subprocess.PIPE, stderr=subprocess.PIPE) #LINE# #TAB# if status == 0: #LINE# #TAB# #TAB# return None #LINE# #TAB# else: #LINE# #TAB# #TAB# return status"
"#LINE# #TAB# _, bone_name = os.path.splitext(name) #LINE# #TAB# if topping == 0: #LINE# #TAB# #TAB# return bone_name + '.tsh' #LINE# #TAB# elif topping == 1: #LINE# #TAB# #TAB# return bone_name + '.txt' #LINE# #TAB# else: #LINE# #TAB# #TAB# return bone_name + '.txt'"
#LINE# #TAB# msg_parsers[cls.__name__] = cls #LINE# #TAB# return cls
"#LINE# #TAB# if attribute_set is not None: #LINE# #TAB# #TAB# data = attribute_set.to_str() #LINE# #TAB# #TAB# if isinstance(data, dict): #LINE# #TAB# #TAB# #TAB# data = json.dumps(data) #LINE# #TAB# #TAB# return data #LINE# #TAB# return ''"
#LINE# #TAB# resource = request.matchdict['resource'] #LINE# #TAB# return resource
#LINE# #TAB# p = request.json['action']['detailParameters'] #LINE# #TAB# return p
"#LINE# #TAB# psi = 0 #LINE# #TAB# valid = T == 298.15 #LINE# #TAB# return psi, valid"
"#LINE# #TAB# if use: #LINE# #TAB# #TAB# use = ""%s%s"" % (use, kid) #LINE# #TAB# k = Key(key, kid=kid) #LINE# #TAB# return k"
"#LINE# #TAB# size = len(list1) #LINE# #TAB# sum1 = sum(list1) #LINE# #TAB# sum2 = sum(list2) #LINE# #TAB# sum_sq1 = sum([pow(l, 2) for l in list1]) #LINE# #TAB# sum_sq2 = sum([pow(l, 2) for l in list2]) #LINE# #TAB# prod_sum = sum([list1[i] * list2[i] for i in range(size)]) #LINE# #TAB# num = prod_sum - (sum1 * sum2 / float(size)) #LINE# #TAB# den = sqrt((sum_sq1 - pow(sum1, 2.0) / size) * #LINE# #TAB# #TAB# (sum_sq2 - pow(sum2, 2.0) / size)) #LINE# #TAB# return num / den"
#LINE# #TAB# try: #LINE# #TAB# #TAB# for key in allHeadersContent: #LINE# #TAB# #TAB# #TAB# del allHeadersContent[key] #LINE# #TAB# except Exception: #LINE# #TAB# #TAB# pass
"#LINE# #TAB# if cause_string: #LINE# #TAB# #TAB# cause_list = ','.join(cause_string.split(',')) #LINE# #TAB# #TAB# queryset = queryset.filter(**{'%s__icontains' % cause_list: True}) #LINE# #TAB# return queryset"
"#LINE# #TAB# if row_content == []: #LINE# #TAB# #TAB# return 1 #LINE# #TAB# if isinstance(row_content, str): #LINE# #TAB# #TAB# return len(row_content) #LINE# #TAB# if isinstance(row_content, list): #LINE# #TAB# #TAB# for item in row_content: #LINE# #TAB# #TAB# #TAB# foo(item) #LINE# #TAB# #TAB# return 0 #LINE# #TAB# else: #LINE# #TAB# #TAB# return [len(row_content)]"
"#LINE# #TAB# import os #LINE# #TAB# path = os.path.join(os.getcwd(), 'foo') #LINE# #TAB# with open(path, 'w') as f: #LINE# #TAB# #TAB# f.write('') #LINE# #TAB# #TAB# try: #LINE# #TAB# #TAB# #TAB# os.unlink(path) #LINE# #TAB# #TAB# except OSError: #LINE# #TAB# #TAB# #TAB# pass"
#LINE# #TAB# with cls._batcher_lock: #LINE# #TAB# #TAB# if cls._batcher is None: #LINE# #TAB# #TAB# #TAB# cls._batcher = cls() #LINE# #TAB# return cls._batcher
"#LINE# #TAB# b0 = 0.0641 * 3 / 4 #LINE# #TAB# b1 = 2.255 * 3 / 4 #LINE# #TAB# b2 = 0 #LINE# #TAB# Cphi = 0.0 * 3 / 2 ** (5 / 2) #LINE# #TAB# C0 = Cphi / (2 * sqrt(np_abs(i2c['Na'] * i2c['S2O3']))) #LINE# #TAB# C1 = 0 #LINE# #TAB# alph1 = 2 #LINE# #TAB# alph2 = -9 #LINE# #TAB# omega = -9 #LINE# #TAB# valid = T == 298.15 #LINE# #TAB# return b0, b1, b2, C0, C1, alph1, alph2, omega, valid"
#LINE# #TAB# if len(intfspec) == 1: #LINE# #TAB# #TAB# cmdline = intfspec[0] +'1' #LINE# #TAB# elif len(intfspec) == 2: #LINE# #TAB# #TAB# cmdline = intfspec[0] +'2' #LINE# #TAB# else: #LINE# #TAB# #TAB# cmdline = intfspec[0] +'3' #LINE# #TAB# return cmdline
#LINE# #TAB# try: #LINE# #TAB# #TAB# return Model.objects.get(pk=model_id).name #LINE# #TAB# except Model.DoesNotExist: #LINE# #TAB# #TAB# return 'unknown_model'
"#LINE# #TAB# name = field_type.name #LINE# #TAB# value = buffer.get(name, _byte_order) #LINE# #TAB# if is_string: #LINE# #TAB# #TAB# return str(value) #LINE# #TAB# else: #LINE# #TAB# #TAB# return value"
"#LINE# #TAB# parser = argparse.ArgumentParser() #LINE# #TAB# parser.add_argument('bar', type=int, help='bar', default=1) #LINE# #TAB# args = parser.parse_args() #LINE# #TAB# return args"
"#LINE# #TAB# #TAB# checkpoint = os.path.join(checkpointDir,'model.checkpoint') #LINE# #TAB# #TAB# model = cls.readFromCheckpoint(checkpoint) #LINE# #TAB# #TAB# model.checkpoint = checkpoint #LINE# #TAB# #TAB# return model"
"#LINE# #TAB# try: #LINE# #TAB# #TAB# return os.kill(pid, 0) #LINE# #TAB# except OSError: #LINE# #TAB# #TAB# return 'Unknown Process ID: %s' % pid"
#LINE# #TAB# while data[0]!= 255: #LINE# #TAB# #TAB# ord1 = ord(data[0]) #LINE# #TAB# #TAB# ord2 = ord(data[1]) #LINE# #TAB# #TAB# if ord2 < 32 or ord2 > 126: #LINE# #TAB# #TAB# #TAB# raise ValueError('invalid byte order') #LINE# #TAB# #TAB# cmd = chr(ord1) + ord2 #LINE# #TAB# #TAB# if data[0] == 255: #LINE# #TAB# #TAB# #TAB# cmd = chr(ord2) + cmd #LINE# #TAB# #TAB# data = data[1:] #LINE# #TAB# return cmd
"#LINE# #TAB# indent = None #LINE# #TAB# for c in code: #LINE# #TAB# #TAB# if c == '\n': #LINE# #TAB# #TAB# #TAB# if include_start: #LINE# #TAB# #TAB# #TAB# #TAB# indent = _foo(c) #LINE# #TAB# #TAB# #TAB# #TAB# break #LINE# #TAB# #TAB# elif isinstance(c, str): #LINE# #TAB# #TAB# #TAB# indent = _foo(c) #LINE# #TAB# return indent"
#LINE# #TAB# if repo is None: #LINE# #TAB# #TAB# return False #LINE# #TAB# if repo == 'fe.buildtimetrend': #LINE# #TAB# #TAB# return True #LINE# #TAB# return False
"#LINE# #TAB# sig = inspect.signature(func) #LINE# #TAB# num_inputs = getattr(input_type, '_n_inputs', None) #LINE# #TAB# if num_inputs is None: #LINE# #TAB# #TAB# num_inputs = 1 #LINE# #TAB# if len(num_inputs)!= len(sig.inputs): #LINE# #TAB# #TAB# raise ValueError( #LINE# #TAB# #TAB# #TAB# f'Input {input_type} must have the same number of inputs to {func}' #LINE# #TAB# #TAB# #TAB# ) #LINE# #TAB# return sig"
#LINE# #TAB# feed = [] #LINE# #TAB# for tag in html: #LINE# #TAB# #TAB# try: #LINE# #TAB# #TAB# #TAB# f = feed['items'][0] #LINE# #TAB# #TAB# #TAB# if f.lower().startswith('url'): #LINE# #TAB# #TAB# #TAB# #TAB# url = f.split('/')[1] #LINE# #TAB# #TAB# #TAB# feed.append(f) #LINE# #TAB# #TAB# except IndexError: #LINE# #TAB# #TAB# #TAB# pass #LINE# #TAB# return feed
"#LINE# #TAB# global frozen_pool #LINE# #TAB# frozen_pool = True #LINE# #TAB# _kwargs = {} #LINE# #TAB# for k, v in six.iteritems(kwargs): #LINE# #TAB# #TAB# if k in _kwargs: #LINE# #TAB# #TAB# #TAB# frozen_pool[k] = v #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# _kwargs[k] = v #LINE# #TAB# return frozen_pool"
"#LINE# #TAB# expr = expression.Expression('v{} {}'.format(vid, expr)) #LINE# #TAB# cols = dtable.columns(vid) #LINE# #TAB# for col in cols: #LINE# #TAB# #TAB# col = col.name #LINE# #TAB# #TAB# mask = expr.evaluate(dtable, {vid: col}) #LINE# #TAB# #TAB# dtable[mask, col] = np.nan"
#LINE# #TAB# y = np.zeros_like(x) #LINE# #TAB# for i in range(a): #LINE# #TAB# #TAB# y[i] = a / (k1 * (x - x1) + k2 * (x - x2)) #LINE# #TAB# return y
"#LINE# #TAB# s = _socket.socket(socket.AF_INET, socket.SOCK_DGRAM) #LINE# #TAB# s.connect((addr, addr)) #LINE# #TAB# s.shutdown(socket.SHUT_RDWR) #LINE# #TAB# return s"
"#LINE# #TAB# new_row = { #LINE# #TAB# #TAB# 'id': row['id'], #LINE# #TAB# #TAB# 'collection': collection, #LINE# #TAB# } #LINE# #TAB# return new_row"
#LINE# #TAB# try: #LINE# #TAB# #TAB# imp.find_module(module) #LINE# #TAB# #TAB# return True #LINE# #TAB# except ImportError: #LINE# #TAB# #TAB# return False
"#LINE# #TAB# template_dir = os.path.dirname(os.path.realpath(__file__)) #LINE# #TAB# template_file = os.path.join(template_dir, name) #LINE# #TAB# return template_file"
#LINE# #TAB# return ((j1 - j2) ** 2 + (j1 - j2) ** 2) ** 0.5 * (1 + ((j1 - j2) ** 2) / (1 + #LINE# #TAB# #TAB# j1 ** 2)) ** 0.5
"#LINE# #TAB# assert tp.is_protocol #LINE# #TAB# result = [] #LINE# #TAB# for member in tp.type_members: #LINE# #TAB# #TAB# typ = get_proper_type(member) #LINE# #TAB# #TAB# if not isinstance(typ, CallableType): #LINE# #TAB# #TAB# #TAB# result.append(member) #LINE# #TAB# return result"
"#LINE# #TAB# if os.path.exists(path): #LINE# #TAB# #TAB# with open(path, 'r') as fp: #LINE# #TAB# #TAB# #TAB# return fp.read() #LINE# #TAB# return ''"
"#LINE# #TAB# try: #LINE# #TAB# #TAB# float(value) #LINE# #TAB# #TAB# return True #LINE# #TAB# except (ValueError, TypeError): #LINE# #TAB# #TAB# return False"
"#LINE# #TAB# try: #LINE# #TAB# #TAB# sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM) #LINE# #TAB# #TAB# sock.bind(('', port)) #LINE# #TAB# #TAB# return sock #LINE# #TAB# except Exception as e: #LINE# #TAB# #TAB# logging.error( #LINE# #TAB# #TAB# #TAB# ) #LINE# #TAB# #TAB# return None"
"#LINE# #TAB# x = vectors[:, (0)] #LINE# #TAB# y = vectors[:, (1)] #LINE# #TAB# z = vectors[:, (2)] #LINE# #TAB# return x, y, z"
"#LINE# #TAB# parser = HyperKittyArgumentParser(prog='foo', description= #LINE# #TAB# #TAB# 'HyperKitty command line interface.') #LINE# #TAB# parser.add_argument('--host', default='localhost') #LINE# #TAB# parser.add_argument('--port', default=6379, type=int) #LINE# #TAB# return parser"
"#LINE# #TAB# if not HAVE_NUMPY: #LINE# #TAB# #TAB# raise ImportError('Numpy not available.') #LINE# #TAB# itksize = vnl_vector.size() #LINE# #TAB# shape = [itksize] #LINE# #TAB# pixelType = 'SI' #LINE# #TAB# numpy_dtype = _get_numpy_pixelid(pixelType) #LINE# #TAB# memview = itkPyVnlSI._get_array_view(pixelType, shape) #LINE# #TAB# ndarr_view = np.asarray(memview).view(dtype=numpy_dtype).reshape(shape) #LINE# #TAB# itk_view = NDArrayITKBase(ndarr_view, vnl_vector) #LINE# #TAB# return itk_view"
#LINE# #TAB# if log_level == logging.INFO: #LINE# #TAB# #TAB# return 'INFO' #LINE# #TAB# elif log_level == logging.WARNING: #LINE# #TAB# #TAB# return 'WARNING' #LINE# #TAB# else: #LINE# #TAB# #TAB# return f'INFO'
"#LINE# #TAB# logger = logging.getLogger('rfc822') #LINE# #TAB# logger.debug('parsing message string: %s', messageString) #LINE# #TAB# try: #LINE# #TAB# #TAB# content = html.unescape(messageString) #LINE# #TAB# except Exception: #LINE# #TAB# #TAB# logger.error('invalid html content: %s', messageString) #LINE# #TAB# #TAB# content = '' #LINE# #TAB# return content"
"#LINE# #TAB# with open('/proc/version_string', 'r') as f: #LINE# #TAB# #TAB# for line in f: #LINE# #TAB# #TAB# #TAB# m = VERSION_RE.match(line) #LINE# #TAB# #TAB# #TAB# if m: #LINE# #TAB# #TAB# #TAB# #TAB# return m.group(1) #LINE# #TAB# return None"
"#LINE# #TAB# if target.position is None: #LINE# #TAB# #TAB# func = sa.sql.func #LINE# #TAB# #TAB# stmt = sa.select([func.coalesce(func.max(mapper.mapped_table.c. #LINE# #TAB# #TAB# #TAB# position), -1)]) #LINE# #TAB# #TAB# target.position = connection.execute(stmt).scalar() + 1"
#LINE# #TAB# kstr = kstr.lower() #LINE# #TAB# while kstr in conn.keysym: #LINE# #TAB# #TAB# try: #LINE# #TAB# #TAB# #TAB# return conn.get_keycode(kstr) #LINE# #TAB# #TAB# except pyhsm.exception.KeyError: #LINE# #TAB# #TAB# #TAB# pass #LINE# #TAB# return None
"#LINE# #TAB# out = [] #LINE# #TAB# for line in txt.strip().split('\n'): #LINE# #TAB# #TAB# m = re.match('(\\d+)\\s*(\\d+)', line) #LINE# #TAB# #TAB# if m: #LINE# #TAB# #TAB# #TAB# out.append('') #LINE# #TAB# #TAB# elif line == '': #LINE# #TAB# #TAB# #TAB# out.append('') #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# out.append(line) #LINE# #TAB# return out"
"#LINE# #TAB# out = '' #LINE# #TAB# if isinstance(prefix, six.string_types): #LINE# #TAB# #TAB# out = prefix.decode('utf8') #LINE# #TAB# if isinstance(suffix, six.binary_type): #LINE# #TAB# #TAB# out = suffix.decode('utf8') #LINE# #TAB# return out"
"#LINE# #TAB# choices = [] #LINE# #TAB# for node in model.get_root_nodes(): #LINE# #TAB# #TAB# choice = cls.foo(node, for_node) #LINE# #TAB# #TAB# choices.append(choice) #LINE# #TAB# return choices"
"#LINE# #TAB# x = date.hour / 60.0 #LINE# #TAB# y = date.day / 60.0 #LINE# #TAB# if body == 1.0: #LINE# #TAB# #TAB# return x, y #LINE# #TAB# body = body - x #LINE# #TAB# a = np.sin(body / 2.0) #LINE# #TAB# b = np.cos(body / 2.0) #LINE# #TAB# c = np.cos(body / 2.0) #LINE# #TAB# return a, b, c"
"#LINE# #TAB# script_dir = os.path.dirname(os.path.realpath(sys.argv[0])) #LINE# #TAB# result = os.path.join(script_dir, name) #LINE# #TAB# return result"
"#LINE# #TAB# return cls.build_send_payload('foo', {'cacheDisabled': cacheDisabled} #LINE# #TAB# #TAB# ), None"
"#LINE# #TAB# for root, dirs, files in os.walk(dir): #LINE# #TAB# #TAB# for f in files: #LINE# #TAB# #TAB# #TAB# f = os.path.join(root, f) #LINE# #TAB# #TAB# #TAB# yield f"
#LINE# #TAB# parts = name.split('_') #LINE# #TAB# model = models[parts[0]] #LINE# #TAB# for part in parts[1:]: #LINE# #TAB# #TAB# model.verbose_name = part #LINE# #TAB# return model
"#LINE# #TAB# canonical, https, httpswww = (domain.canonical, domain.https, domain. #LINE# #TAB# #TAB# httpswww) #LINE# #TAB# if canonical.host == '127.0.0.1': #LINE# #TAB# #TAB# return True #LINE# #TAB# return False"
"#LINE# #TAB# for i in range(0, len(source_iter), n): #LINE# #TAB# #TAB# yield source_iter[i:i + n]"
#LINE# #TAB# if name.startswith('_'): #LINE# #TAB# #TAB# if value in locals(): #LINE# #TAB# #TAB# #TAB# return True #LINE# #TAB# else: #LINE# #TAB# #TAB# return False
"#LINE# #TAB# keys = [] #LINE# #TAB# if pat in dir(Object): #LINE# #TAB# #TAB# keys.append(Object(pat)) #LINE# #TAB# if isinstance(pat, str): #LINE# #TAB# #TAB# pat = re.compile(pat) #LINE# #TAB# for k in dir(Object): #LINE# #TAB# #TAB# if pat.search(k): #LINE# #TAB# #TAB# #TAB# keys.append(k) #LINE# #TAB# return keys"
"#LINE# #TAB# out = [] #LINE# #TAB# for app in apps_list: #LINE# #TAB# #TAB# if app.endswith('.json'): #LINE# #TAB# #TAB# #TAB# with open(app + '.json', 'r') as f: #LINE# #TAB# #TAB# #TAB# #TAB# app_dict = json.load(f) #LINE# #TAB# #TAB# #TAB# app_label = app_dict['app'].lower() #LINE# #TAB# #TAB# #TAB# if app_label not in out: #LINE# #TAB# #TAB# #TAB# #TAB# out.append(app_label) #LINE# #TAB# return out"
"#LINE# #TAB# print('foo() called!') #LINE# #TAB# with open('tmp.txt', 'w+') as f: #LINE# #TAB# #TAB# f.write('') #LINE# #TAB# #TAB# cmd = 'tmp.txt 2>&1' #LINE# #TAB# #TAB# proc = subprocess.Popen(cmd, stdout=f.stdout, stderr=f.stderr) #LINE# #TAB# #TAB# ret = proc.communicate()[0] #LINE# #TAB# #TAB# f.close() #LINE# #TAB# return ret"
#LINE# #TAB# new_user = User() #LINE# #TAB# new_user.id = str(user.id) #LINE# #TAB# new_user.first_name = user.first_name #LINE# #TAB# new_user.last_name = user.last_name #LINE# #TAB# user.email = user.email #LINE# #TAB# user.save() #LINE# #TAB# return new_user
"#LINE# #TAB# th = threading.Thread(parent=parent, name=worker, daemon=True) #LINE# #TAB# th.daemon = deleteWorkerLater #LINE# #TAB# th.start() #LINE# #TAB# return th"
"#LINE# #TAB# template_dir = get_template_dir() #LINE# #TAB# index_file = os.path.join(template_dir, ""index"") #LINE# #TAB# textfsm_obj = clitable.CliTable(index_file, template_dir) #LINE# #TAB# attrs = {""Command"": command, ""Platform"": platform} #LINE# #TAB# try: #LINE# #TAB# #TAB# textfsm_obj.ParseCmd(raw_output, attrs) #LINE# #TAB# #TAB# output = raw_output.decode() #LINE# #TAB# except CliTableError as e: #LINE# #TAB# #TAB# print(e.message) #LINE# #TAB# #TAB# return 1 #LINE# #TAB# return output"
"#LINE# #TAB# for k, v in src.items(): #LINE# #TAB# #TAB# if k in tgt and isinstance(tgt[k], dict) and isinstance(v, dict): #LINE# #TAB# #TAB# #TAB# tgt[k] = foo(tgt[k], v) #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# tgt[k] = v"
"#LINE# #TAB# res = np.zeros((4, 4)) #LINE# #TAB# m1 = mass1 / mass2 #LINE# #TAB# m2 = mass2 / mass2 #LINE# #TAB# xi = xi2 / mass1 #LINE# #TAB# s = (m1 * m2).sum() #LINE# #TAB# for k in range(3): #LINE# #TAB# #TAB# res[k] = 1.0 / s[k] #LINE# #TAB# return res"
#LINE# #TAB# if eps == 0: #LINE# #TAB# #TAB# return sum(alpha) #LINE# #TAB# if eps == 1: #LINE# #TAB# #TAB# return alpha ** 2 #LINE# #TAB# return alpha ** 2
#LINE# #TAB# ConversionFinder) ->MultifileObjectParser: #LINE# #TAB# class DummyParser(MultifileObjectParser): #LINE# #TAB# #TAB# pass #LINE# #TAB# DummyParser.parser_finder = parser_finder #LINE# #TAB# DummyParser.conversion_finder = conversion_finder #LINE# #TAB# return DummyParser
#LINE# #TAB# if e.errno == errno.ENOENT: #LINE# #TAB# #TAB# return 'e1' #LINE# #TAB# elif e.errno == errno.ENOENT: #LINE# #TAB# #TAB# return 'e2' #LINE# #TAB# else: #LINE# #TAB# #TAB# raise e
"#LINE# #TAB# with Tk() as tkinter: #LINE# #TAB# #TAB# tkinter.main('foo', title, message) #LINE# #TAB# #TAB# return tkinter"
#LINE# #TAB# number = str(number) #LINE# #TAB# if number == 0: #LINE# #TAB# #TAB# return '++' #LINE# #TAB# elif number < 0: #LINE# #TAB# #TAB# return '-' #LINE# #TAB# else: #LINE# #TAB# #TAB# return number
#LINE# #TAB# for s in sets: #LINE# #TAB# #TAB# for v in s: #LINE# #TAB# #TAB# #TAB# if v == s: #LINE# #TAB# #TAB# #TAB# #TAB# return True #LINE# #TAB# return False
#LINE# #TAB# ret = relative_scope_name #LINE# #TAB# while ret.endswith('/'): #LINE# #TAB# #TAB# ret = ret[:-1] + '/' #LINE# #TAB# return ret
#LINE# #TAB# #TAB# try: #LINE# #TAB# #TAB# #TAB# return cls.objects.get(uri=uri) #LINE# #TAB# #TAB# except cls.DoesNotExist: #LINE# #TAB# #TAB# #TAB# if not silent: #LINE# #TAB# #TAB# #TAB# #TAB# raise #LINE# #TAB# #TAB# return None
"#LINE# #TAB# sta_win.groupby('chan_id') #LINE# #TAB# count_win = [len(win) for win in sta_win.get_windows()] #LINE# #TAB# return {'chan_id': sta_win.chan_id, 'chan_name': sta_win.name, 'count': #LINE# #TAB# #TAB# count_win}"
"#LINE# #TAB# if n > 1: #LINE# #TAB# #TAB# raise Exception('n must be greater than 1') #LINE# #TAB# if a == 1: #LINE# #TAB# #TAB# return 1 #LINE# #TAB# elif a == 2: #LINE# #TAB# #TAB# return 2 #LINE# #TAB# elif a == 3: #LINE# #TAB# #TAB# return 3 * foo(a, n - 1) #LINE# #TAB# elif a == 4: #LINE# #TAB# #TAB# try: #LINE# #TAB# #TAB# #TAB# return foo(a, n - 2) #LINE# #TAB# #TAB# except Exception: #LINE# #TAB# #TAB# #TAB# raise Exception"
#LINE# #TAB# try: #LINE# #TAB# #TAB# return pkg_resources.get_distribution('instana').version #LINE# #TAB# except pkg_resources.DistributionNotFound: #LINE# #TAB# #TAB# return 'unknown'
"#LINE# #TAB# if password is None or not is_password_usable(encoded): #LINE# #TAB# #TAB# return False #LINE# #TAB# preferred = get_hasher(preferred) #LINE# #TAB# hasher = identify_hasher(encoded) #LINE# #TAB# must_update = hasher.algorithm!= preferred.algorithm #LINE# #TAB# is_correct = hasher.verify(password, encoded) #LINE# #TAB# if setter and is_correct and must_update: #LINE# #TAB# #TAB# setter(password) #LINE# #TAB# return is_correct"
#LINE# #TAB# if request.authorization and request.authorization[0] == 'Basic': #LINE# #TAB# #TAB# return True #LINE# #TAB# else: #LINE# #TAB# #TAB# return False
#LINE# #TAB# global session #LINE# #TAB# session = None
#LINE# #TAB# if file.endswith('.po'): #LINE# #TAB# #TAB# return file[:-3] #LINE# #TAB# elif file.endswith('.fr'): #LINE# #TAB# #TAB# return file[:-4] #LINE# #TAB# else: #LINE# #TAB# #TAB# return file
#LINE# #TAB# data = {} #LINE# #TAB# data['network'] = {} #LINE# #TAB# data['ip'] = {} #LINE# #TAB# data['ipv4'] = {} #LINE# #TAB# data['ipv6'] = {} #LINE# #TAB# data['ipv6'] = {} #LINE# #TAB# data['ipv4'] = {} #LINE# #TAB# data['ipv6'] = {} #LINE# #TAB# data['ipv6'] = {} #LINE# #TAB# return data
"#LINE# #TAB# ingredient = ing + '.ingredient' #LINE# #TAB# comments = [] #LINE# #TAB# for comment in re.findall('^\\s*\\[(.*)\\]', ingredient): #LINE# #TAB# #TAB# result = re.findall('^\\s*\\[(.*)\\]', comment) #LINE# #TAB# #TAB# if result: #LINE# #TAB# #TAB# #TAB# comments.append(comment[0]) #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# comments.append(comment) #LINE# #TAB# return comments, ingredient"
#LINE# #TAB# with open(filepath) as foo_file: #LINE# #TAB# #TAB# data = json.load(foo_file) #LINE# #TAB# return data[property]
#LINE# #TAB# tmpdir = tempfile.mkdtemp() #LINE# #TAB# os.mkdir(tmpdir) #LINE# #TAB# return tmpdir
"#LINE# #TAB# db = _connect_db(db_url=db_url, db_name=db_name) #LINE# #TAB# db['url'] = db_url #LINE# #TAB# db['database'] = db_name"
#LINE# #TAB# demux_samples = get_demux_samples() #LINE# #TAB# for sample in demux_samples: #LINE# #TAB# #TAB# if sample['id'] == sample_id: #LINE# #TAB# #TAB# #TAB# return sample #LINE# #TAB# else: #LINE# #TAB# #TAB# return None
"#LINE# #TAB# return get_block_overview(block_representation=block_representation, #LINE# #TAB# #TAB# coin_symbol=coin_symbol, txn_limit=1, api_key=api_key)['prev_block']"
#LINE# #TAB# dF = Ft / Fo #LINE# #TAB# return dF
"#LINE# #TAB# username = request.headers['X-Authorization'] #LINE# #TAB# try: #LINE# #TAB# #TAB# if auth(username, password): #LINE# #TAB# #TAB# #TAB# return True #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# return False #LINE# #TAB# except Exception: #LINE# #TAB# #TAB# return False"
"#LINE# #TAB# if isinstance(field, list) and len(field) == 1: #LINE# #TAB# #TAB# key_type = 'compound' #LINE# #TAB# #TAB# key_name = field[0] #LINE# #TAB# #TAB# return key_type, key_name #LINE# #TAB# else: #LINE# #TAB# #TAB# return field, False"
"#LINE# #TAB# for series in seriesList: #LINE# #TAB# #TAB# series.name = ""foo(%s)"" % (series.name) #LINE# #TAB# #TAB# val = safeMin(series) #LINE# #TAB# #TAB# if val is not None and val >= n: #LINE# #TAB# #TAB# #TAB# series.name = series.name #LINE# #TAB# return seriesList"
"#LINE# #TAB# sets = [] #LINE# #TAB# if depth == 0: #LINE# #TAB# #TAB# for cmdset in cmdsets: #LINE# #TAB# #TAB# #TAB# sets.append(set([job])) #LINE# #TAB# elif depth == 1: #LINE# #TAB# #TAB# for cmdset in cmdsets: #LINE# #TAB# #TAB# #TAB# foo(cmdset, depth - 1) #LINE# #TAB# #TAB# #TAB# sets.append(set([job])) #LINE# #TAB# else: #LINE# #TAB# #TAB# for job in job: #LINE# #TAB# #TAB# #TAB# sets = foo(job, cmdsets) #LINE# #TAB# return sets"
"#LINE# #TAB# img1 = crop(img1, padding=padding) #LINE# #TAB# img2 = crop(img2, padding=padding) #LINE# #TAB# return img1, img2"
#LINE# #TAB# if node1.resname == node2.resname: #LINE# #TAB# #TAB# return False #LINE# #TAB# elif node1.otm_atom == node2.otm_atom: #LINE# #TAB# #TAB# return True #LINE# #TAB# return False
"#LINE# #TAB# if isinstance(values, list): #LINE# #TAB# #TAB# for v in values: #LINE# #TAB# #TAB# #TAB# if isinstance(v, str): #LINE# #TAB# #TAB# #TAB# #TAB# values[v] = int(v) #LINE# #TAB# elif isinstance(values, dict): #LINE# #TAB# #TAB# values = {} #LINE# #TAB# #TAB# for k, v in values.items(): #LINE# #TAB# #TAB# #TAB# if isinstance(v, int): #LINE# #TAB# #TAB# #TAB# #TAB# values[k] = float(v) #LINE# #TAB# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# #TAB# values[k] = str(v) #LINE# #TAB# elif isinstance(values, pd.DataFrame): #LINE# #TAB# #TAB# values = values.tolist() #LINE# #TAB# return values"
"#LINE# #TAB# session = generic_session(session) #LINE# #TAB# url = base_url('foo') #LINE# #TAB# metadata = base_metadata(session, url) #LINE# #TAB# return metadata"
#LINE# #TAB# if a.base is not None: #LINE# #TAB# #TAB# return a.copy() #LINE# #TAB# return a
"#LINE# #TAB# try: #LINE# #TAB# #TAB# if isinstance(schema, list): #LINE# #TAB# #TAB# #TAB# return [foo(schema[i], path + [str(i)]) for i in range(len(schema))] #LINE# #TAB# #TAB# if isinstance(schema, dict): #LINE# #TAB# #TAB# #TAB# for key in schema: #LINE# #TAB# #TAB# #TAB# #TAB# if isinstance(schema[key], list): #LINE# #TAB# #TAB# #TAB# #TAB# #TAB# return foo(schema[key], path + [str(key)]) #LINE# #TAB# #TAB# return schema #LINE# #TAB# except: #LINE# #TAB# #TAB# return False"
"#LINE# with tf.variable_scope(""foo""): #LINE# #TAB# in_int = int(in_int) #LINE# for i in range(max_bits): #LINE# #TAB# if in_int == 0: #LINE# #TAB# #TAB# out_int = 0 #LINE# #TAB# elif in_int > 0: #LINE# #TAB# out_int = tf.expand_dims(out_int, new_dim_length, axis=i) #LINE# #TAB# else: #LINE# #TAB# out_int = tf.expand_dims(out_int, new_dim_length, axis=i) #LINE# return out_int"
"#LINE# #TAB# result = re.search('{2,}', class_name) #LINE# #TAB# if result: #LINE# #TAB# #TAB# return class_name[:-len(result.group(0))] #LINE# #TAB# return class_name"
"#LINE# #TAB# if np.isscalar(scale): #LINE# #TAB# #TAB# if scale == 0.0: #LINE# #TAB# #TAB# #TAB# scale = 1.0 #LINE# #TAB# #TAB# return scale #LINE# #TAB# elif isinstance(scale, np.ndarray): #LINE# #TAB# #TAB# if copy: #LINE# #TAB# #TAB# #TAB# scale = scale.copy() #LINE# #TAB# #TAB# scale[scale == 0.0] = 1.0 #LINE# #TAB# #TAB# return scale"
"#LINE# #TAB# results = [] #LINE# #TAB# with open(csvFile, 'r') as f: #LINE# #TAB# #TAB# data = json.load(f) #LINE# #TAB# for i in data: #LINE# #TAB# #TAB# results.append(i) #LINE# #TAB# return results"
"#LINE# #TAB# if description: #LINE# #TAB# #TAB# _foo(base=base, description=description, resource=resource, #LINE# #TAB# #TAB# #TAB# options=options) #LINE# #TAB# else: #LINE# #TAB# #TAB# _foo(base=base, description=description, resource=resource, #LINE# #TAB# #TAB# #TAB# options=options) #LINE# #TAB# return base"
#LINE# #TAB# if method in Lan.serviceTypeLookup.keys(): #LINE# #TAB# #TAB# return Lan.serviceTypeLookup[method] #LINE# #TAB# return None
"#LINE# #TAB# cmd = cmd.strip() #LINE# #TAB# if not cmd: #LINE# #TAB# #TAB# return '' #LINE# #TAB# return cmd.split('=', 1)[0]"
"#LINE# #TAB# msa = np.array(msa) #LINE# #TAB# cell_size = len(chimerics) #LINE# #TAB# result = np.zeros((cell_size, cell_size)) #LINE# #TAB# for i in range(cell_size): #LINE# #TAB# #TAB# c = chimerics[i] #LINE# #TAB# #TAB# d = np.sum(c) #LINE# #TAB# #TAB# if d!= 0: #LINE# #TAB# #TAB# #TAB# result[i, d] = np.nan #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# result[i, d] = np.nan #LINE# #TAB# return result"
"#LINE# #TAB# if string == '': #LINE# #TAB# #TAB# return '' #LINE# #TAB# pos = random.randint(0, len(string)) #LINE# #TAB# return string[:pos] + random.choice([c for c in string[pos + 1:] if c == '_']) + string[ #LINE# #TAB# #TAB# pos + 1:]"
#LINE# #TAB# frag = cls() #LINE# #TAB# frag.content = pods['content'] #LINE# #TAB# frag._resources = [FragmentResource(**d) for d in pods['resources']] #LINE# #TAB# frag.js_init_fn = pods['js_init_fn'] #LINE# #TAB# frag.js_init_version = pods['js_init_version'] #LINE# #TAB# frag.json_init_args = pods['json_init_args'] #LINE# #TAB# return frag
"#LINE# #TAB# output = subprocess.check_output(['pip', '-c', pip_cmd, '--quiet']) #LINE# #TAB# outdated = [] #LINE# #TAB# for line in output.splitlines(): #LINE# #TAB# #TAB# line = line.decode('utf-8') #LINE# #TAB# #TAB# if verbose: #LINE# #TAB# #TAB# #TAB# print(line) #LINE# #TAB# #TAB# outdated.append(line) #LINE# #TAB# if pip_cmd == 'pip': #LINE# #TAB# #TAB# pip_cmd = 'pip --quiet' #LINE# #TAB# if verbose: #LINE# #TAB# #TAB# print('Collected outdated packages:\n') #LINE# #TAB# #TAB# json.dumps(outdated, indent=4, sort_keys=True) #LINE# #TAB# return outdated"
"#LINE# #TAB# files=[] #LINE# #TAB# for g in groups.values(): #LINE# #TAB# #TAB# for fname in glob.glob(folder+""/*.*""): #LINE# #TAB# #TAB# #TAB# if fname not in files: #LINE# #TAB# #TAB# #TAB# #TAB# files.append(fname) #LINE# #TAB# return files"
"#LINE# #TAB# for i, x in enumerate(data_iterator): #LINE# #TAB# #TAB# try: #LINE# #TAB# #TAB# #TAB# val = float(net(x)) / sum(data_iterator) #LINE# #TAB# #TAB# except: #LINE# #TAB# #TAB# #TAB# val = 0 #LINE# #TAB# return val"
"#LINE# #TAB# global _foo #LINE# #TAB# if _foo is None: #LINE# #TAB# #TAB# with open(os.path.join(os.path.dirname(__file__), 'data/foo.json')) as f: #LINE# #TAB# #TAB# #TAB# _foo = json.load(f) #LINE# #TAB# return _foo"
#LINE# #TAB# for host in get_hosts(tree): #LINE# #TAB# #TAB# if host['cve'] == cve: #LINE# #TAB# #TAB# #TAB# yield host
"#LINE# #TAB# settings = get_settings(homedir) #LINE# #TAB# try: #LINE# #TAB# #TAB# emails = getattr(settings, 'EMAILS', []) #LINE# #TAB# except: #LINE# #TAB# #TAB# return False #LINE# #TAB# for email in emails: #LINE# #TAB# #TAB# if email.startswith('admin.'): #LINE# #TAB# #TAB# #TAB# return True #LINE# #TAB# return False"
"#LINE# #TAB# parts = name.split('.') #LINE# #TAB# module = '.'.join(parts[:-1]) #LINE# #TAB# m = __import__(module) #LINE# #TAB# for comp in parts[1:]: #LINE# #TAB# #TAB# m = getattr(m, comp) #LINE# #TAB# return m"
"#LINE# #TAB# if isinstance(s, six.string_types): #LINE# #TAB# #TAB# content = s #LINE# #TAB# #TAB# try: #LINE# #TAB# #TAB# #TAB# with open(s, 'r') as f: #LINE# #TAB# #TAB# #TAB# #TAB# content = f.read() #LINE# #TAB# #TAB# except IOError: #LINE# #TAB# #TAB# #TAB# pass #LINE# #TAB# #TAB# return content #LINE# #TAB# return s"
#LINE# #TAB# tree = ET.parse(stats_xml) #LINE# #TAB# root = tree.getroot() #LINE# #TAB# total = int(root.find('size/total/text').text) #LINE# #TAB# blinded = int(root.find('blinded').text) > 10 #LINE# #TAB# return blinded / total
"#LINE# #TAB# import pandas as pd #LINE# #TAB# return pd.DataFrame(['x', 'y', 'z'])[:, :, (['x', 'y', 'z'])].T"
#LINE# #TAB# v = actor.velocity() #LINE# #TAB# if v < 0: #LINE# #TAB# #TAB# return 0 #LINE# #TAB# return v
#LINE# #TAB# try: #LINE# #TAB# #TAB# return RequestInfo._instance #LINE# #TAB# except AttributeError: #LINE# #TAB# #TAB# info = RequestInfo() #LINE# #TAB# #TAB# info.request = request #LINE# #TAB# #TAB# return info
#LINE# #TAB# stack = [] #LINE# #TAB# obj_id = 1 #LINE# #TAB# while True: #LINE# #TAB# #TAB# try: #LINE# #TAB# #TAB# #TAB# obj = Store.objects.get(obj_id=obj_id) #LINE# #TAB# #TAB# #TAB# stack.append(obj) #LINE# #TAB# #TAB# except: #LINE# #TAB# #TAB# #TAB# break #LINE# #TAB# return stack
#LINE# #TAB# #TAB# resolved_packages = [] #LINE# #TAB# #TAB# for package in include_packages: #LINE# #TAB# #TAB# #TAB# resolved_packages.append(package) #LINE# #TAB# #TAB# packages_to_resolve = set(resolved_packages) #LINE# #TAB# #TAB# del resolved_packages #LINE# #TAB# #TAB# return packages_to_resolve
#LINE# #TAB# summary = '' #LINE# #TAB# for command_summary in command_summaries: #LINE# #TAB# #TAB# summary += command_summary #LINE# #TAB# return summary
#LINE# #TAB# type_ = response.headers.get('content-type') #LINE# #TAB# if type_ == 'text/plain': #LINE# #TAB# #TAB# return 'text/plain' #LINE# #TAB# elif type_ == 'application/json': #LINE# #TAB# #TAB# return 'application/json' #LINE# #TAB# else: #LINE# #TAB# #TAB# return type_
"#LINE# #TAB# return cls.build_send_payload('foo', {'eventName': eventName}), None"
#LINE# #TAB# for r in model.permissions.all(): #LINE# #TAB# #TAB# yield r.name
#LINE# #TAB# if 'AT' in seq: #LINE# #TAB# #TAB# return 'AT' #LINE# #TAB# elif 'VB' in seq: #LINE# #TAB# #TAB# return 'VB' #LINE# #TAB# elif 'AC' in seq: #LINE# #TAB# #TAB# return 'AC' #LINE# #TAB# elif 'R' in seq: #LINE# #TAB# #TAB# return 'R' #LINE# #TAB# else: #LINE# #TAB# #TAB# return ''
"#LINE# #TAB# e = [] #LINE# #TAB# e += [('%s=%s' % (e, str(arg1)))] #LINE# #TAB# e += [('%s=%s' % (arg2, str(arg2)))] #LINE# #TAB# return e"
"#LINE# #TAB# with settings(hide('running','stdout','stderr', 'warnings'), #LINE# #TAB# #TAB# warn_only=True): #LINE# #TAB# #TAB# return True"
"#LINE# #TAB# import pycountry #LINE# #TAB# country = pycountry.countries.get() #LINE# #TAB# if country: #LINE# #TAB# #TAB# return {'key': key, 'value': country.alpha_2} #LINE# #TAB# else: #LINE# #TAB# #TAB# return {'key': key, 'value': None}"
"#LINE# #TAB# if scheme!= 'nearest': #LINE# #TAB# #TAB# width = int(stretchDim[0]) #LINE# #TAB# #TAB# height = int(stretchDim[1]) #LINE# #TAB# #TAB# image = Image.new('RGB', (width, height), imageClass) #LINE# #TAB# else: #LINE# #TAB# #TAB# image = imageClass #LINE# #TAB# width = int(stretchDim[1]) #LINE# #TAB# height = int(stretchDim[2]) #LINE# #TAB# image.paste(image, (width, height)) #LINE# #TAB# return image"
#LINE# #TAB# if success is True: #LINE# #TAB# #TAB# return 'SUCCESS' #LINE# #TAB# elif not success: #LINE# #TAB# #TAB# return 'FAILED' #LINE# #TAB# else: #LINE# #TAB# #TAB# return 'FINISHED'
"#LINE# #TAB# file_root = tempfile.mkdtemp() #LINE# #TAB# if file_name == '': #LINE# #TAB# #TAB# file_name = file_ext #LINE# #TAB# if file_ext!= '': #LINE# #TAB# #TAB# file_ext += '.' #LINE# #TAB# with open(file_root + file_name, 'w') as fo: #LINE# #TAB# #TAB# fo.write(json.dumps(data, indent=2)) #LINE# #TAB# return file_root + file_name"
"#LINE# #TAB# if _random_name_re.match(logical_line): #LINE# #TAB# #TAB# pos = logical_line.find('-') #LINE# #TAB# #TAB# if pos > 0: #LINE# #TAB# #TAB# #TAB# yield pos, ""T108: '%s'"" % logical_line[:pos]"
"#LINE# #TAB# import functools #LINE# #TAB# res = [] #LINE# #TAB# for k in ['num_hidden_layers', 'hidden_layers']: #LINE# #TAB# #TAB# if k in hparams.hidden_layers: #LINE# #TAB# #TAB# #TAB# res.append( #LINE# #TAB# #TAB# #TAB# #TAB# functools.partial( #LINE# #TAB# #TAB# #TAB# #TAB# #TAB# 'normalization.add_layer', hparams.hidden_layers[k]), #LINE# #TAB# #TAB# #TAB# #TAB# hparams.hidden_layers[k] #LINE# #TAB# #TAB# #TAB# ) #LINE# #TAB# return res"
#LINE# #TAB# try: #LINE# #TAB# #TAB# return course_url.split('#')[0].split('/')[-1] #LINE# #TAB# except IndexError: #LINE# #TAB# #TAB# return course_url
"#LINE# #TAB# return [{'name': 'kube_shields', 'url': '%s://%s:%d' % ( #LINE# #TAB# #TAB# BASE_URL, cls.hostname, cls.port), 'endpoint_type': 'api_v1','version': #LINE# #TAB# #TAB# '1.0.0'}, {'name': 'kube_shields', 'url': '%s://%s:%s' % ( #LINE# #TAB# #TAB# BASE_URL, cls.hostname, cls.port), 'endpoint': '%s://%s:%d' % ( #LINE# #TAB# #TAB# BASE_URL, cls.hostname, cls.port), 'endpoint_type': 'api_v1', #LINE# #TAB# #TAB#'version': cls.VERSION}, {'name': 'kube_shields', 'url': '%s://%s:%s' % ( #LINE# #TAB# #TAB# BASE_URL, cls.hostname, cls.port)}], 200"
"#LINE# #TAB# if not isinstance(pn1, Set) or not isinstance(pn2, Set): #LINE# #TAB# #TAB# return False #LINE# #TAB# for e1 in pn1: #LINE# #TAB# #TAB# for e2 in pn2: #LINE# #TAB# #TAB# #TAB# if e1!= e2: #LINE# #TAB# #TAB# #TAB# #TAB# return False #LINE# #TAB# return True"
"#LINE# #TAB# with tempfile.NamedTemporaryFile('w', delete=False) as f: #LINE# #TAB# #TAB# f.write(seed) #LINE# #TAB# #TAB# f.flush() #LINE# #TAB# #TAB# device_id = f.name #LINE# #TAB# return device_id"
"#LINE# #TAB# if isinstance(transaction, cls): #LINE# #TAB# #TAB# return transaction.foo is not None #LINE# #TAB# elif isinstance(transaction, dict): #LINE# #TAB# #TAB# return any(cls.foo(item) for item in transaction.values()) #LINE# #TAB# elif isinstance(transaction, list): #LINE# #TAB# #TAB# return any(cls.foo(item) for item in transaction) #LINE# #TAB# else: #LINE# #TAB# #TAB# return False"
#LINE# #TAB# s = [] #LINE# #TAB# if num_seqs > 0: #LINE# #TAB# #TAB# for _ in range(start_at): #LINE# #TAB# #TAB# #TAB# s.append(base_name + '_' + str(start_at) + '_' + str( #LINE# #TAB# #TAB# #TAB# #TAB# num_seqs)) #LINE# #TAB# else: #LINE# #TAB# #TAB# for _ in range(num_seqs): #LINE# #TAB# #TAB# #TAB# s.append(base_name + '_' + str(start_at) + '_' + str( #LINE# #TAB# #TAB# #TAB# #TAB# num_seqs)) #LINE# #TAB# return s
"#LINE# #TAB# op = 0 #LINE# #TAB# if a == b: #LINE# #TAB# #TAB# op = 1 #LINE# #TAB# elif a == '-': #LINE# #TAB# #TAB# op = -1 #LINE# #TAB# else: #LINE# #TAB# #TAB# op = 0 #LINE# #TAB# if op == 0: #LINE# #TAB# #TAB# return True #LINE# #TAB# for x, y in zip(a, b): #LINE# #TAB# #TAB# op += ord(x) ^ ord(y) #LINE# #TAB# return op == 0"
"#LINE# #TAB# psi_tables = {} #LINE# #TAB# for k, v in element_map.items(): #LINE# #TAB# #TAB# if k in classnames: #LINE# #TAB# #TAB# #TAB# psi_tables[k] = v #LINE# #TAB# return psi_tables"
#LINE# #TAB# #TAB# if update: #LINE# #TAB# #TAB# #TAB# return cls.game_version_list #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# return cls.game_version
"#LINE# #TAB# units = [] #LINE# #TAB# for base_unit in orifs: #LINE# #TAB# #TAB# units.append(CodeUnit(base_unit, file_locator=file_locator)) #LINE# #TAB# return units"
"#LINE# #TAB# with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s: #LINE# #TAB# #TAB# s.connect(payload) #LINE# #TAB# #TAB# res = s.recv() #LINE# #TAB# #TAB# s.close() #LINE# #TAB# return res"
"#LINE# #TAB# data = {} #LINE# #TAB# with open(filename, 'r') as f: #LINE# #TAB# #TAB# for line in f: #LINE# #TAB# #TAB# #TAB# try: #LINE# #TAB# #TAB# #TAB# #TAB# key, val = line.split(':') #LINE# #TAB# #TAB# #TAB# #TAB# data[key] = val #LINE# #TAB# #TAB# #TAB# except ValueError: #LINE# #TAB# #TAB# #TAB# #TAB# pass #LINE# #TAB# return data"
#LINE# #TAB# global MAXBLOCK #LINE# #TAB# TRACER.MAXBLOCK = maxblock #LINE# #TAB# try: #LINE# #TAB# #TAB# yield #LINE# #TAB# finally: #LINE# #TAB# #TAB# TRACER.MAXBLOCK = maxblock
"#LINE# #TAB# if context is None: #LINE# #TAB# #TAB# context = get_global_context() #LINE# #TAB# llvmir = _encode_string(llvmir) #LINE# #TAB# strbuf = c_char_p(llvmir) #LINE# #TAB# with ffi.OutputString() as errmsg: #LINE# #TAB# #TAB# mod = ModuleRef(ffi.lib.LLVMPY_CreateModule(context, strbuf, #LINE# #TAB# #TAB# #TAB# errmsg), context) #LINE# #TAB# #TAB# if errmsg: #LINE# #TAB# #TAB# #TAB# mod.close() #LINE# #TAB# #TAB# #TAB# raise RuntimeError('LLVM IR parsing error\n{0}'.format(errmsg)) #LINE# #TAB# return mod"
"#LINE# #TAB# try: #LINE# #TAB# #TAB# return foo(y,yr)/psd #LINE# #TAB# except ZeroDivisionError: #LINE# #TAB# #TAB# return np.nan"
#LINE# #TAB# total = 0 #LINE# #TAB# edges = nxg.edges(data=True) #LINE# #TAB# for edge in edges: #LINE# #TAB# #TAB# if 'label' in edge[2]: #LINE# #TAB# #TAB# #TAB# total += edge[2]['label'] #LINE# #TAB# return total
"#LINE# #TAB# files = [] #LINE# #TAB# for f in os.listdir(os.getcwd()): #LINE# #TAB# #TAB# f = os.path.join(f,'settings.py') #LINE# #TAB# #TAB# if os.path.isfile(f): #LINE# #TAB# #TAB# #TAB# files.append((os.path.abspath(f), os.path.basename(f))) #LINE# #TAB# return files"
"#LINE# #TAB# if include_expired: #LINE# #TAB# #TAB# data = get_expired_names( cur, current_block, include_expired=include_expired) #LINE# #TAB# else: #LINE# #TAB# #TAB# data = get_names( cur, current_block) #LINE# #TAB# return data"
"#LINE# #TAB# #TAB# res_label = list(residue[0])[0][2] #LINE# #TAB# #TAB# atom_labels = {x[2] for x in itertools.chain( #LINE# #TAB# #TAB# #TAB# *residue[1].values())} #LINE# #TAB# #TAB# if (all(x in atom_labels for x in ['N', 'CA', 'C', 'O'])) and ( #LINE# #TAB# #TAB# #TAB# #TAB# len(res_label) == 3): #LINE# #TAB# #TAB# #TAB# return True #LINE# #TAB# #TAB# return False"
"#LINE# #TAB# try: #LINE# #TAB# #TAB# for f in obj._plugins: #LINE# #TAB# #TAB# #TAB# if callable(getattr(f, 'func')): #LINE# #TAB# #TAB# #TAB# #TAB# return f.func() #LINE# #TAB# #TAB# return obj #LINE# #TAB# except: #LINE# #TAB# #TAB# return None"
"#LINE# #TAB# url_patterns = [] #LINE# #TAB# for route in current_app.url_map.itervalues(): #LINE# #TAB# #TAB# if hasattr(route, 'url_patterns'): #LINE# #TAB# #TAB# #TAB# url_patterns += route.url_patterns #LINE# #TAB# return url_patterns"
#LINE# #TAB# try: #LINE# #TAB# #TAB# with open('README.rst') as f: #LINE# #TAB# #TAB# #TAB# readme = f.read() #LINE# #TAB# #TAB# return readme.split('\n')[0] #LINE# #TAB# except Exception: #LINE# #TAB# #TAB# return None
"#LINE# #TAB# try: #LINE# #TAB# #TAB# query = event[""context""][""request""][""query""] #LINE# #TAB# #TAB# event[""context""][""request""][""query""] = varmap(_sanitize, query) #LINE# #TAB# except (KeyError, TypeError): #LINE# #TAB# #TAB# pass #LINE# #TAB# return event"
"#LINE# #TAB# #TAB# res = cls.call('bar', data=data) #LINE# #TAB# #TAB# if res == cls.OP_PUSH: #LINE# #TAB# #TAB# #TAB# return cls.STACK_DATA #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# return res"
#LINE# #TAB# if not SharedInstance.instance: #LINE# #TAB# #TAB# clear_cache() #LINE# #TAB# #TAB# SharedInstance.instance = BitShares(**SharedInstance.config) #LINE# #TAB# return SharedInstance.instance
#LINE# #TAB# tree = etree.fromstring(xmlcontent) #LINE# #TAB# root = tree.getroot() #LINE# #TAB# return root
"#LINE# #TAB# with h5py.File(h5, 'r') as h: #LINE# #TAB# #TAB# ret = unwrapArray(h, recursive=True, readH5pyDataset=readH5pyDataset) #LINE# #TAB# return ret"
"#LINE# #TAB# x = row[0] #LINE# #TAB# y = row[1] #LINE# #TAB# if y == 0: #LINE# #TAB# #TAB# return 0 #LINE# #TAB# if y > 1: #LINE# #TAB# #TAB# return foo(x, y - 1, dem_adjustment) #LINE# #TAB# if x > 1: #LINE# #TAB# #TAB# return foo(y, x - 1, dem_adjustment) #LINE# #TAB# return 0"
"#LINE# #TAB# try: #LINE# #TAB# #TAB# signal[np.isnan(signal)] = np.nan #LINE# #TAB# except (TypeError, ValueError): #LINE# #TAB# #TAB# pass #LINE# #TAB# return signal"
"#LINE# #TAB# fnames = [] #LINE# #TAB# for root, dirs, filenames in os.walk(os.path.join(os.path.dirname(__file__), #LINE# #TAB# #TAB# DIRPATH_SCHEMAS)): #LINE# #TAB# #TAB# for fname in filenames: #LINE# #TAB# #TAB# #TAB# if fname.endswith('.xsd'): #LINE# #TAB# #TAB# #TAB# #TAB# continue #LINE# #TAB# #TAB# #TAB# fname = os.path.join(root, fname) #LINE# #TAB# #TAB# #TAB# if os.path.isfile(fname): #LINE# #TAB# #TAB# #TAB# #TAB# fnames.append(fname) #LINE# #TAB# return fnames"
"#LINE# #TAB# energy_matrix = np.zeros((size, size)) #LINE# #TAB# for i in range(0, size): #LINE# #TAB# #TAB# i1 = i * smooth_factor #LINE# #TAB# #TAB# i2 = i * smooth_factor + 1 #LINE# #TAB# #TAB# energy_matrix[i1, i2] = energy_matrix[i1, i2] #LINE# #TAB# return energy_matrix"
#LINE# #TAB# for line in lines: #LINE# #TAB# #TAB# if line.strip(): #LINE# #TAB# #TAB# #TAB# yield line
"#LINE# #TAB# namedtuple_rows = [] #LINE# #TAB# for col_name, row in zip(colnames, rows): #LINE# #TAB# #TAB# namedtuple_rows.append(pseudo_namedtuple_row(col_name, row)) #LINE# #TAB# return namedtuple_rows"
"#LINE# #TAB# keys = list(attributes_set) #LINE# #TAB# for attr in keys: #LINE# #TAB# #TAB# if not verify_if_event(log, attr): #LINE# #TAB# #TAB# #TAB# attributes_set.remove(attr) #LINE# #TAB# return attributes_set"
"#LINE# #TAB# if name in _names: #LINE# #TAB# #TAB# return _names[name][0] #LINE# #TAB# if residue == None: #LINE# #TAB# #TAB# return _names[name][1] #LINE# #TAB# else: #LINE# #TAB# #TAB# res = random.randint(1, len(_names) - 1) #LINE# #TAB# #TAB# if res in _names: #LINE# #TAB# #TAB# #TAB# return res #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# res = random.randint(1, len(_names)) #LINE# #TAB# #TAB# #TAB# return _names[name][0]"
"#LINE# #TAB# account = get_object_or_404(Account, pk=accountid) #LINE# #TAB# if request.user.is_authenticated: #LINE# #TAB# #TAB# logged_in_user = get_logged_in_user(request) #LINE# #TAB# #TAB# filename = request.path_qs['filename'] #LINE# #TAB# #TAB# with db_connect() as db_conn: #LINE# #TAB# #TAB# #TAB# with db_conn.cursor() as cursor: #LINE# #TAB# #TAB# #TAB# #TAB# cursor.execute(SQL['download'], filename) #LINE# #TAB# #TAB# #TAB# #TAB# doc = cursor.fetchone() #LINE# #TAB# else: #LINE# #TAB# #TAB# filename = None #LINE# #TAB# resp = HttpResponse(filename.encode('utf-8')) #LINE# #TAB# resp['Content-Type'] = 'application/pdf' #LINE# #TAB# resp['Content-Length'] = str(len(doc)) #LINE# #TAB# return resp"
#LINE# #TAB# c = NameCollector(ctx) #LINE# #TAB# c.collect(tree) #LINE# #TAB# return c
"#LINE# #TAB# command_args_package_name = [cls.executable, '-f', file_path, 'Package'] #LINE# #TAB# command_args_version = [cls.executable, '-f', file_path, 'Version'] #LINE# #TAB# package_name = CM.run_command_check_output(command_args_package_name) #LINE# #TAB# package_version = CM.run_command_check_output(command_args_version) #LINE# #TAB# package_info = PackageInfo() #LINE# #TAB# package_info.package = package_name.strip() #LINE# #TAB# package_info.version = package_version.strip() #LINE# #TAB# return package_info"
"#LINE# #TAB# if t == 0: #LINE# #TAB# #TAB# p = l[1] #LINE# #TAB# #TAB# for j in range(1, len(l)): #LINE# #TAB# #TAB# #TAB# p = p + [l[j]] #LINE# #TAB# else: #LINE# #TAB# #TAB# p = [] #LINE# #TAB# #TAB# for i in range(1, len(l)): #LINE# #TAB# #TAB# #TAB# if l[i]!= l[j]: #LINE# #TAB# #TAB# #TAB# #TAB# p.append(l[i]) #LINE# #TAB# #TAB# #TAB# #TAB# t += 1 #LINE# #TAB# return p"
#LINE# #TAB# roles = [] #LINE# #TAB# status = client.list_account_roles() #LINE# #TAB# if status['account']!= '': #LINE# #TAB# #TAB# roles = status['account']['roles'] #LINE# #TAB# else: #LINE# #TAB# #TAB# roles = status['account']['roles'] #LINE# #TAB# return roles
#LINE# #TAB# if confirm == 'y': #LINE# #TAB# #TAB# return True #LINE# #TAB# else: #LINE# #TAB# #TAB# return False
#LINE# #TAB# try: #LINE# #TAB# #TAB# return int(x) #LINE# #TAB# except ValueError: #LINE# #TAB# #TAB# return 0
#LINE# #TAB# df = df.copy() #LINE# #TAB# if s in df.columns: #LINE# #TAB# #TAB# df = df[df.columns.str.contains(s)] #LINE# #TAB# return df
"#LINE# #TAB# if isinstance(param, list): #LINE# #TAB# #TAB# return param #LINE# #TAB# else: #LINE# #TAB# #TAB# return [param]"
#LINE# #TAB# data_size = 0 #LINE# #TAB# data_size += calculate_size_str(name) #LINE# #TAB# data_size += BOOLEAN_SIZE_IN_BYTES #LINE# #TAB# return data_size
"#LINE# #TAB# _, ext = os.path.splitext(fname) #LINE# #TAB# ext = ext[1:] if ext.endswith('.') else ext #LINE# #TAB# if not ext: #LINE# #TAB# #TAB# return None #LINE# #TAB# protocol = None #LINE# #TAB# try: #LINE# #TAB# #TAB# with open(fname, 'rb') as f: #LINE# #TAB# #TAB# #TAB# protocol = f.read(4) #LINE# #TAB# except: #LINE# #TAB# #TAB# pass #LINE# #TAB# return protocol"
"#LINE# #TAB# engineio_server.routes[engineio_endpoint] = app #LINE# #TAB# app.router.add_route('GET', view_func=engineio_server.get) #LINE# #TAB# app.router.add_route('POST', view_func=engineio_endpoint, method='GET') #LINE# #TAB# app.router.add_route('GET', view_func=engineio_server.get) #LINE# #TAB# app.router.add_route('POST', view_func=engineio_endpoint, method='POST') #LINE# #TAB# return app"
#LINE# #TAB# strings = [] #LINE# #TAB# for string in string_set: #LINE# #TAB# #TAB# strings.append(string) #LINE# #TAB# return strings
#LINE# #TAB# if type(my_element) == list: #LINE# #TAB# #TAB# for x in my_list: #LINE# #TAB# #TAB# #TAB# if x == my_element: #LINE# #TAB# #TAB# #TAB# #TAB# break #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# my_list.append(x) #LINE# #TAB# else: #LINE# #TAB# #TAB# my_list.append(my_element) #LINE# #TAB# return my_list
"#LINE# #TAB# out = {} #LINE# #TAB# for k, v in dico.items(): #LINE# #TAB# #TAB# out[v] = k #LINE# #TAB# return out"
#LINE# #TAB# try: #LINE# #TAB# #TAB# ret = eval(str1) #LINE# #TAB# except: #LINE# #TAB# #TAB# print(str1) #LINE# #TAB# #TAB# ret = str1 #LINE# #TAB# return ret
#LINE# #TAB# if options.input: #LINE# #TAB# #TAB# sys.stdout.write('\n'.join(options.input)) #LINE# #TAB# #TAB# if options.strings: #LINE# #TAB# #TAB# #TAB# for s in options.strings: #LINE# #TAB# #TAB# #TAB# #TAB# sys.stdout.write(s) #LINE# #TAB# elif options.strings: #LINE# #TAB# #TAB# for s in options.strings: #LINE# #TAB# #TAB# #TAB# sys.stdout.write(s) #LINE# #TAB# else: #LINE# #TAB# #TAB# pass
#LINE# #TAB# link_pages = [] #LINE# #TAB# i = 0 #LINE# #TAB# while i < len(links): #LINE# #TAB# #TAB# link_page = [] #LINE# #TAB# #TAB# while i < len(links) and len(link_page) < 10: #LINE# #TAB# #TAB# #TAB# link_page.append(links[i]) #LINE# #TAB# #TAB# #TAB# i += 1 #LINE# #TAB# #TAB# link_pages.append(link_page) #LINE# #TAB# return link_pages
"#LINE# #TAB# if ""end-age"" in soup.text or soup.text.endswith(""et al""): #LINE# #TAB# #TAB# return ""bar"" #LINE# #TAB# return ""bar"""
"#LINE# #TAB# joystick_c = unbox(joystick, 'SDL_Joystick *') #LINE# #TAB# rc = lib.sdl_joysticknumhats(joystick_c) #LINE# #TAB# return rc"
"#LINE# #TAB# data = response.json() #LINE# #TAB# if isinstance(data, dict): #LINE# #TAB# #TAB# return Resource(**data) #LINE# #TAB# if isinstance(data, list): #LINE# #TAB# #TAB# return ResourceList(**data) #LINE# #TAB# if isinstance(data, dict): #LINE# #TAB# #TAB# return Resource(**data) #LINE# #TAB# return data"
"#LINE# #TAB# if isinstance(value, str): #LINE# #TAB# #TAB# if value.lower() == 'true': #LINE# #TAB# #TAB# #TAB# return True #LINE# #TAB# #TAB# elif value.lower() == 'false': #LINE# #TAB# #TAB# #TAB# return False #LINE# #TAB# #TAB# try: #LINE# #TAB# #TAB# #TAB# return list([value]) #LINE# #TAB# #TAB# except ValueError: #LINE# #TAB# #TAB# #TAB# return [value]"
#LINE# #TAB# if require: #LINE# #TAB# #TAB# dependencies = (f for f in XsdValidator.__subclasses__() if f not in #LINE# #TAB# #TAB# #TAB# DEPENDENCIES) #LINE# #TAB# #TAB# for dependency in dependencies: #LINE# #TAB# #TAB# #TAB# if dependency(require): #LINE# #TAB# #TAB# #TAB# #TAB# return XsdValidator(dependency) #LINE# #TAB# return None
#LINE# #TAB# if id_ in channels(chid): #LINE# #TAB# #TAB# return [chid_to_name(chid) for chid_ in channels(chid) if #LINE# #TAB# #TAB# #TAB# is_enum(chid)]
#LINE# #TAB# if quality == 1: #LINE# #TAB# #TAB# return id_type + '-' + str(id_value) #LINE# #TAB# elif quality == 2: #LINE# #TAB# #TAB# return id_type + '-' + str(id_value) #LINE# #TAB# else: #LINE# #TAB# #TAB# return id_type + '-' + str(id_value) + '-' + quality
"#LINE# #TAB# for key in attrs: #LINE# #TAB# #TAB# if not key.startswith('_'): #LINE# #TAB# #TAB# #TAB# yield key[1:], attrs[key]"
"#LINE# #TAB# if params: #LINE# #TAB# #TAB# for k, v in params.items(): #LINE# #TAB# #TAB# #TAB# params[k] = v #LINE# #TAB# return params"
"#LINE# #TAB# if 'type' not in data_dict or data_dict['type']!= type_name: #LINE# #TAB# #TAB# raise ValueError('{} is not a valid type for {}'.format(type_name, #LINE# #TAB# #TAB# #TAB# data_dict['type'])) #LINE# #TAB# return data_dict"
"#LINE# #TAB# position = 0 #LINE# #TAB# for position, basescore in enumerate(scores): #LINE# #TAB# #TAB# if basescore >= threshold: #LINE# #TAB# #TAB# #TAB# break #LINE# #TAB# return position, 0"
"#LINE# #TAB# model = KNeighborsClassifier(n_components=1) #LINE# #TAB# model.read(fname) #LINE# #TAB# lookup = dict() #LINE# #TAB# for i, entry in enumerate(model.train.entry): #LINE# #TAB# #TAB# if entry[1] in lookup: #LINE# #TAB# #TAB# #TAB# k = lookup[entry[1]] #LINE# #TAB# #TAB# #TAB# lookup[k] = i #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# lookup[k] = i #LINE# #TAB# return model, lookup"
"#LINE# #TAB# outfile = os.path.join(outdir, 'plot') #LINE# #TAB# os.makedirs(outfile, exist_ok=True) #LINE# #TAB# return outfile"
"#LINE# #TAB# if isinstance(value, str): #LINE# #TAB# #TAB# return value #LINE# #TAB# return value.__s3key__"
"#LINE# #TAB# try: #LINE# #TAB# #TAB# if os.path.isfile(path): #LINE# #TAB# #TAB# #TAB# with open(path, 'r') as f: #LINE# #TAB# #TAB# #TAB# #TAB# r = f.read() #LINE# #TAB# #TAB# #TAB# return r.split('\n')[0] #LINE# #TAB# except Exception: #LINE# #TAB# #TAB# pass #LINE# #TAB# return False"
#LINE# #TAB# try: #LINE# #TAB# #TAB# int(txt) #LINE# #TAB# #TAB# return Piccolo.ID_MAP[int(txt)] #LINE# #TAB# except: #LINE# #TAB# #TAB# return txt
"#LINE# #TAB# objects = [] #LINE# #TAB# while berdecoder(content): #LINE# #TAB# #TAB# try: #LINE# #TAB# #TAB# #TAB# obj, content = berdecoder(content) #LINE# #TAB# #TAB# #TAB# objects.append(obj) #LINE# #TAB# #TAB# except EOFError: #LINE# #TAB# #TAB# #TAB# break #LINE# #TAB# return objects"
"#LINE# #TAB# count = stdio.readInt() #LINE# #TAB# a = create2DArray(count, None) #LINE# #TAB# for i in range(count): #LINE# #TAB# #TAB# a[i] = stdio.readInt() #LINE# #TAB# return a"
"#LINE# #TAB# with tempfile.NamedTemporaryFile(dir=tmp_dir) as f: #LINE# #TAB# #TAB# urls = [f.name for f in os.listdir(tmp_dir) if f.suffix == '.pkl'] #LINE# #TAB# #TAB# r = requests.get(urls) #LINE# #TAB# #TAB# with open(f.name, 'wb') as out: #LINE# #TAB# #TAB# #TAB# out.write(r.content) #LINE# #TAB# return"
"#LINE# #TAB# if isinstance(val, six.string_types): #LINE# #TAB# #TAB# return val.split() #LINE# #TAB# return val"
#LINE# #TAB# res = 0 #LINE# #TAB# for i in range(len(left_bytes)): #LINE# #TAB# #TAB# for j in range(len(right_bytes)): #LINE# #TAB# #TAB# #TAB# if left_bytes[i]!= right_bytes[j]: #LINE# #TAB# #TAB# #TAB# #TAB# res += 1 #LINE# #TAB# return res
"#LINE# #TAB# details = {'id': card.id, 'type': card.type, 'title': card.title,'subtitle': #LINE# #TAB# #TAB# card.subtitle} #LINE# #TAB# return details"
"#LINE# #TAB# with open('/proc/meminfo', 'rb') as meminfo: #LINE# #TAB# #TAB# meminfo.seek(0) #LINE# #TAB# #TAB# if meminfo.read(1024) == b'': #LINE# #TAB# #TAB# #TAB# return True #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# return False"
#LINE# #TAB# with OTA_lock: #LINE# #TAB# #TAB# if ota is None: #LINE# #TAB# #TAB# #TAB# ota = DEFAULT_TA #LINE# #TAB# #TAB# if not ota: #LINE# #TAB# #TAB# #TAB# return True #LINE# #TAB# return ota
"#LINE# #TAB# entities = [] #LINE# #TAB# if text.startswith('&') and text.endswith('&': #LINE# #TAB# #TAB# entities.append('&') #LINE# #TAB# #TAB# text = text[2:] #LINE# #TAB# if any(c in text for c in entities): #LINE# #TAB# #TAB# return #LINE# #TAB# for part in text.split(' '): #LINE# #TAB# #TAB# if part[0]!= '&': #LINE# #TAB# #TAB# #TAB# entities.append('&') #LINE# #TAB# #TAB# if part[0]!= '&': #LINE# #TAB# #TAB# #TAB# entities.append('%s%s' % (part[0], '=')) #LINE# #TAB# for entity in entities: #LINE# #TAB# #TAB# if entity[0]!= '&': #LINE# #TAB# #TAB# #TAB# entities.append('%s%s' % (entity[0], entity[1])) #LINE# #TAB# return"
#LINE# #TAB# #TAB# cls._status = None #LINE# #TAB# #TAB# pass
"#LINE# #TAB# if lock is not None: #LINE# #TAB# #TAB# try: #LINE# #TAB# #TAB# #TAB# lock.release() #LINE# #TAB# #TAB# #TAB# logger.debug('Your lock is released.') #LINE# #TAB# #TAB# #TAB# return True #LINE# #TAB# #TAB# except (ThreadError, RuntimeError): #LINE# #TAB# #TAB# #TAB# return False"
"#LINE# #TAB# node = nodes.Node(id=target_id, env=env, lineno=lineno) #LINE# #TAB# node.attr['kind'] = 'config' #LINE# #TAB# return node"
"#LINE# #TAB# if isinstance(obj, sa.Model): #LINE# #TAB# #TAB# d = {} #LINE# #TAB# #TAB# for f in obj._meta.fields: #LINE# #TAB# #TAB# #TAB# d[f.name] = getattr(obj, f.name) #LINE# #TAB# #TAB# return d #LINE# #TAB# else: #LINE# #TAB# #TAB# return obj.__class__.__name__"
#LINE# #TAB# try: #LINE# #TAB# #TAB# return fn._has_foo #LINE# #TAB# except AttributeError: #LINE# #TAB# #TAB# return False
"#LINE# #TAB# if isinstance(vals, str): #LINE# #TAB# #TAB# return True #LINE# #TAB# elif isinstance(vals, (tuple, list)): #LINE# #TAB# #TAB# return all(isinstance(i, str) for i in vals) #LINE# #TAB# else: #LINE# #TAB# #TAB# return False"
"#LINE# #TAB# X_pred = X.T @ X #LINE# #TAB# y_pred = y.copy() #LINE# #TAB# weights = weights.T @ weights #LINE# #TAB# y_pred[y == 0] = 0 #LINE# #TAB# d_pred = family.predict(X_pred, weights) #LINE# #TAB# d_link = family.derivative(y_pred, link) #LINE# #TAB# return d_pred, d_link"
"#LINE# #TAB# if asse_equal_type_re.match(logical_line): #LINE# #TAB# #TAB# yield 0, 'SL317: assertEqual(type(A), B) sentences not allowed'"
#LINE# #TAB# try: #LINE# #TAB# #TAB# ip = ipaddress.ip_address(u'' + ip_address) #LINE# #TAB# #TAB# if ip.is_loopback or ip.is_link_local or ip.is_loopback: #LINE# #TAB# #TAB# #TAB# return True #LINE# #TAB# #TAB# return False #LINE# #TAB# except ValueError: #LINE# #TAB# #TAB# return False
"#LINE# #TAB# regions = {} #LINE# #TAB# print('Loading regions...') #LINE# #TAB# with open('regions.json', 'r') as f: #LINE# #TAB# #TAB# for r in json.load(f): #LINE# #TAB# #TAB# #TAB# regions[r['region']] = r['name'] #LINE# #TAB# #TAB# print('Done!') #LINE# #TAB# return regions"
#LINE# #TAB# for notebook in config['notebook']: #LINE# #TAB# #TAB# if notebook['path'] == path: #LINE# #TAB# #TAB# #TAB# return notebook['name'] #LINE# #TAB# return None
#LINE# #TAB# if type(value) == str: #LINE# #TAB# #TAB# if max_width and len(value) > max_width: #LINE# #TAB# #TAB# #TAB# return value[:max_width - 3] + '...' #LINE# #TAB# #TAB# return value #LINE# #TAB# return value
"#LINE# #TAB# try: #LINE# #TAB# #TAB# return int(__CONFIG__.get(section, option, default)) #LINE# #TAB# except (ConfigParser.NoSectionError, ConfigParser.NoOptionError) as err: #LINE# #TAB# #TAB# if raise_exception and default is None: #LINE# #TAB# #TAB# #TAB# raise err #LINE# #TAB# #TAB# return default"
#LINE# #TAB# bit_arr = [] #LINE# #TAB# for i in range(len(arr)): #LINE# #TAB# #TAB# for j in range(8): #LINE# #TAB# #TAB# #TAB# bit_arr.append(arr[i * 8 + j] & 1) #LINE# #TAB# return bit_arr
"#LINE# #TAB# if retries == 0: #LINE# #TAB# #TAB# return mysql.connect(host=host, db=db, user=user, password=password) #LINE# #TAB# else: #LINE# #TAB# #TAB# time.sleep(sleep) #LINE# #TAB# #TAB# retries -= 1 #LINE# #TAB# #TAB# connection = mysql.connect(host=host, db=db, user=user, password=password) #LINE# #TAB# return connection"
"#LINE# #TAB# inputs = {} #LINE# #TAB# for k, v in example_command.items(): #LINE# #TAB# #TAB# k = str(k) #LINE# #TAB# #TAB# if type(v) == list: #LINE# #TAB# #TAB# #TAB# for i in v: #LINE# #TAB# #TAB# #TAB# #TAB# inputs[k] = i #LINE# #TAB# return inputs"
"#LINE# #TAB# try: #LINE# #TAB# #TAB# c = ContentType.objects.get(app_label=app_name, model_name=model_name) #LINE# #TAB# except ContentType.DoesNotExist: #LINE# #TAB# #TAB# raise Http404 #LINE# #TAB# return c.content_type"
"#LINE# #TAB# try: #LINE# #TAB# #TAB# c = ContentType.objects.get(app_label=app_name, model_name=model_name) #LINE# #TAB# except ContentType.DoesNotExist: #LINE# #TAB# #TAB# raise Http404 #LINE# #TAB# return c.content_type"
#LINE# #TAB# try: #LINE# #TAB# #TAB# return env['app_name'] #LINE# #TAB# except KeyError: #LINE# #TAB# #TAB# return env['app']
#LINE# #TAB# if type(error) in _SENTINEL_ERRORS: #LINE# #TAB# #TAB# raise _SENTINEL_ERRORS[type(error)] #LINE# #TAB# elif type(error) in _SENTINEL_FALLBACK_ERRORS: #LINE# #TAB# #TAB# raise _SENTINEL_FALLBACK_ERRORS[type(error)] #LINE# #TAB# elif type(error) is dict and 'error' in error: #LINE# #TAB# #TAB# for key in error.keys(): #LINE# #TAB# #TAB# #TAB# if key in _SENTINEL_ERRORS[type(error[key])]: #LINE# #TAB# #TAB# #TAB# #TAB# raise _SENTINEL_ERRORS[type(error[key])][key] #LINE# #TAB# raise error
#LINE# #TAB# if direction =='read': #LINE# #TAB# #TAB# name = f'{name}_read' #LINE# #TAB# elif direction == 'write': #LINE# #TAB# #TAB# name = f'{name}_write' #LINE# #TAB# else: #LINE# #TAB# #TAB# raise NotImplementedError( #LINE# #TAB# #TAB# #TAB# f'Unsupported direction {direction!r}') #LINE# #TAB# return name
#LINE# #TAB# out = gdal.GetDriverByName('MEM') #LINE# #TAB# dst = None #LINE# #TAB# if srs is not None: #LINE# #TAB# #TAB# dst = (gdal.GDT_Float32 * max(extent)) * srs #LINE# #TAB# if res < 0: #LINE# #TAB# #TAB# res = 0 #LINE# #TAB# out.SetGeoTransform(res) #LINE# #TAB# out.SetGeoTransform(dst) #LINE# #TAB# out.GetRasterBand(1).SetDataType(dtype) #LINE# #TAB# return out
"#LINE# #TAB# colnames = [] #LINE# #TAB# indices = {} #LINE# #TAB# with open(filename, 'r') as f: #LINE# #TAB# #TAB# for i, line in enumerate(f): #LINE# #TAB# #TAB# #TAB# if line.startswith('#'): #LINE# #TAB# #TAB# #TAB# #TAB# continue #LINE# #TAB# #TAB# #TAB# if '_' in line: #LINE# #TAB# #TAB# #TAB# #TAB# idx = i #LINE# #TAB# #TAB# #TAB# #TAB# colnames.append(line[idx]) #LINE# #TAB# #TAB# #TAB# #TAB# indices[idx] = i #LINE# #TAB# return colnames, indices"
"#LINE# #TAB# eigenvalue = [] #LINE# #TAB# eigenvectors = [] #LINE# #TAB# for i in range(len(esys_mapdata)): #LINE# #TAB# #TAB# if esys_mapdata[i][0] == 0: #LINE# #TAB# #TAB# #TAB# eigenvalue.append(esys_mapdata[i][1]) #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# eigenvalue.append(esys_mapdata[i][1]) #LINE# #TAB# #TAB# eigenvectors.append(esys_mapdata[i][2]) #LINE# #TAB# return eigenvalue, eigenvectors"
#LINE# #TAB# global __grains__ #LINE# #TAB# if __grains__ is None: #LINE# #TAB# #TAB# __grains__ = {} #LINE# #TAB# if proxy and 'grains' in proxy: #LINE# #TAB# #TAB# ret = proxy['grains'] #LINE# #TAB# else: #LINE# #TAB# #TAB# ret = {} #LINE# #TAB# #TAB# for key in __grains__: #LINE# #TAB# #TAB# #TAB# ret[key] = salt.utils.data.decode(__salt__['grains.get'](key)) #LINE# #TAB# return ret
#LINE# #TAB# parts = regex.split('/') #LINE# #TAB# if len(parts) == 1: #LINE# #TAB# #TAB# return True #LINE# #TAB# if len(parts) == 2: #LINE# #TAB# #TAB# return True #LINE# #TAB# return False
#LINE# #TAB# parsed = OrderedDict(type=get_type_desc(arg)) #LINE# #TAB# parsed['name'] = arg.__name__ #LINE# #TAB# parsed['signature'] = str(signature_func(arg)) #LINE# #TAB# try: #LINE# #TAB# #TAB# parsed['fullargspec'] = str(inspect.getfullargspec(arg)) #LINE# #TAB# except Exception as e: #LINE# #TAB# #TAB# parsed['fullargspec'] = str(inspect.getargspec(arg)) #LINE# #TAB# parsed['isbuiltin'] = inspect.isbuiltin(arg) #LINE# #TAB# return parsed
"#LINE# #TAB# if os.path.isabs(template): #LINE# #TAB# #TAB# path = template #LINE# #TAB# else: #LINE# #TAB# #TAB# path = os.path.join(os.getcwd(), template) #LINE# #TAB# return path"
#LINE# #TAB# rp = ReviewConfig() #LINE# #TAB# if app_config: #LINE# #TAB# #TAB# rp.app_config = app_config #LINE# #TAB# if not ini_config: #LINE# #TAB# #TAB# return rp #LINE# #TAB# from configparser import ConfigParser #LINE# #TAB# sections = ini_config.sections() #LINE# #TAB# for section in sections: #LINE# #TAB# #TAB# rp.add_section(section) #LINE# #TAB# #TAB# if section in app_config: #LINE# #TAB# #TAB# #TAB# rp.add_section(section) #LINE# #TAB# return rp
#LINE# #TAB# data = foo.__dict__ #LINE# #TAB# lReturn = [] #LINE# #TAB# for item in data: #LINE# #TAB# #TAB# lReturn.append(item) #LINE# #TAB# return lReturn
#LINE# #TAB# compression_method = decompressor.COMPRESSION_METHOD.lower() #LINE# #TAB# if compression_method not in cls._decompressors: #LINE# #TAB# #TAB# raise KeyError('Decompressor for compression method: {0:s} not set.'.format( #LINE# #TAB# #TAB# #TAB# decompressor)) #LINE# #TAB# cls._decompressors[compression_method] = decompressor
#LINE# #TAB# try: #LINE# #TAB# #TAB# return hashlib.md5(data).hexdigest() #LINE# #TAB# except: #LINE# #TAB# #TAB# return 0
#LINE# #TAB# z = x.copy() #LINE# #TAB# z.update(y) #LINE# #TAB# return z
#LINE# #TAB# name_list = url_dict['Name'] #LINE# #TAB# if name_list in authn_subj_list: #LINE# #TAB# #TAB# return authn_subj_list[name_list] #LINE# #TAB# else: #LINE# #TAB# #TAB# return None
"#LINE# #TAB# psi = -0.0094 #LINE# #TAB# valid = T == 298.15 #LINE# #TAB# return psi, valid"
#LINE# #TAB# code = code_object.co_const #LINE# #TAB# return code
"#LINE# #TAB# for pattern, pattern_matches in matches: #LINE# #TAB# #TAB# if fnmatch(name, pattern): #LINE# #TAB# #TAB# #TAB# return True #LINE# #TAB# return False"
"#LINE# #TAB# try: #LINE# #TAB# #TAB# mib_max = np.max(mib) #LINE# #TAB# #TAB# if mib_max > xi_complement: #LINE# #TAB# #TAB# #TAB# raise ValueError #LINE# #TAB# except: #LINE# #TAB# #TAB# pass #LINE# #TAB# foo_sdas = sdas #LINE# #TAB# for i in range(1, len(sdas)): #LINE# #TAB# #TAB# area = np.argmax((sdas[i][1] - mib[i]) / (mib_max + #LINE# #TAB# #TAB# #TAB# xi_complement)) #LINE# #TAB# #TAB# foo_sdas[i] = area #LINE# #TAB# print(reachability_plot) #LINE# #TAB# return foo_sdas"
"#LINE# #TAB# args = shlex.split(' ') #LINE# #TAB# env = os.environ.copy() #LINE# #TAB# env['PATH'] = os.path.join(work_dir, *args) #LINE# #TAB# p = subprocess.Popen(commands, #LINE# #TAB# #TAB# #TAB# #TAB# #TAB# #TAB# #TAB# shell=False, #LINE# #TAB# #TAB# #TAB# #TAB# #TAB# #TAB# stdout=subprocess.PIPE, #LINE# #TAB# #TAB# #TAB# #TAB# #TAB# #TAB# #TAB# stderr=subprocess.STDOUT) #LINE# #TAB# stdout, stderr = p.communicate(args) #LINE# #TAB# stderr = stderr.decode('utf-8') #LINE# #TAB# if p.returncode!= 0: #LINE# #TAB# #TAB# raise subprocess.CalledProcessError(p.returncode, stdout, stderr) #LINE# #TAB# return p.returncode"
"#LINE# #TAB# if isinstance(value, str): #LINE# #TAB# #TAB# try: #LINE# #TAB# #TAB# #TAB# return type(value) #LINE# #TAB# #TAB# except (AttributeError, TypeError): #LINE# #TAB# #TAB# #TAB# raise TypeError('{} is not a valid differential class'.format(value)) #LINE# #TAB# else: #LINE# #TAB# #TAB# try: #LINE# #TAB# #TAB# #TAB# return type(value) #LINE# #TAB# #TAB# except TypeError: #LINE# #TAB# #TAB# #TAB# raise ValueError('{} is not a valid differential class'.format(value)) #LINE# #TAB# #TAB# except Exception: #LINE# #TAB# #TAB# #TAB# raise ValueError('{} is not a valid different class'.format(value)) #LINE# #TAB# return value"
"#LINE# #TAB# with open(name, 'r+') as f: #LINE# #TAB# #TAB# it = json.load(f) #LINE# #TAB# return it"
#LINE# #TAB# if strategy == 'random': #LINE# #TAB# #TAB# r = random.choice #LINE# #TAB# else: #LINE# #TAB# #TAB# r = random.choice #LINE# #TAB# while True: #LINE# #TAB# #TAB# try: #LINE# #TAB# #TAB# #TAB# yield next(gen) #LINE# #TAB# #TAB# except StopIteration: #LINE# #TAB# #TAB# #TAB# return
"#LINE# #TAB# soup = BeautifulSoup(section, 'lxml') #LINE# #TAB# paragraphs = soup.findAll('p') #LINE# #TAB# if len(paragraphs) < min_paragraph_length: #LINE# #TAB# #TAB# paragraphs = [] #LINE# #TAB# #TAB# for paragraph in paragraphs: #LINE# #TAB# #TAB# #TAB# paragraph = strip_tags(paragraph) #LINE# #TAB# #TAB# #TAB# paragraphs.append(paragraph) #LINE# #TAB# return paragraphs"
"#LINE# #TAB# if width == 1: #LINE# #TAB# #TAB# return np.frombuffer(data, dtype='uint8') #LINE# #TAB# elif width == 2: #LINE# #TAB# #TAB# return np.frombuffer(data, dtype='uint16') #LINE# #TAB# elif width == 3: #LINE# #TAB# #TAB# return np.frombuffer(data, dtype='uint32') #LINE# #TAB# else: #LINE# #TAB# #TAB# raise ValueError"
"#LINE# #TAB# field.setText(str(field.text()).replace(',','')) #LINE# #TAB# try: #LINE# #TAB# #TAB# if len(str(field.text()).split())!= num: #LINE# #TAB# #TAB# #TAB# raise ValueError #LINE# #TAB# #TAB# for i in range(num): #LINE# #TAB# #TAB# #TAB# field.setText(str(field.text()[:i]).replace(',','')) #LINE# #TAB# #TAB# _show_consistency(field, message) #LINE# #TAB# #TAB# return 1 #LINE# #TAB# except ValueError: #LINE# #TAB# #TAB# _show_consistency(field, message) #LINE# #TAB# #TAB# return 2"
"#LINE# #TAB# if not base: #LINE# #TAB# #TAB# return [] #LINE# #TAB# stabs = _distribute_gens_by_base(base, gens) #LINE# #TAB# orbits, transversals = _orbits_transversals_from_bsgs(base, stabs) #LINE# #TAB# transversals = [{x: h._array_form for x, h in y.items()} for y in #LINE# #TAB# #TAB# transversals] #LINE# #TAB# return transversals"
"#LINE# #TAB# path, filename = os.path.split(fullpath) #LINE# #TAB# filename, ext = os.path.splitext(filename) #LINE# #TAB# sys.path.insert(0, path) #LINE# #TAB# module = importlib.import_module(filename, path) #LINE# #TAB# importlib.reload(module) #LINE# #TAB# del sys.path[0] #LINE# #TAB# return module"
"#LINE# #TAB# if name.count('/') > 1: #LINE# #TAB# #TAB# return '%s/%s/%s' % (location, name, size) #LINE# #TAB# elif name.count('//') > 1: #LINE# #TAB# #TAB# return '%s/%s/%s' % (location, name, size) #LINE# #TAB# elif name.count('//') > 1: #LINE# #TAB# #TAB# return '%s/%s' % (name, location) #LINE# #TAB# elif name.count('\\') > 1: #LINE# #TAB# #TAB# return '%s/%s' % (name, location) #LINE# #TAB# return ''"
"#LINE# #TAB# task = cls(config['task_name'], dependencies=dependencies) #LINE# #TAB# sequence = [] #LINE# #TAB# for name, task_dependencies in dependencies.items(): #LINE# #TAB# #TAB# sequence.extend(cls.foo(config, task_dependencies)) #LINE# #TAB# return task, sequence"
#LINE# #TAB# if model_a.name!= model_b.name: #LINE# #TAB# #TAB# return False #LINE# #TAB# if model_a.module_name == model_b.module_name: #LINE# #TAB# #TAB# if model_a.signature!= model_b.signature: #LINE# #TAB# #TAB# #TAB# return False #LINE# #TAB# if model_a.modules!= model_b.modules: #LINE# #TAB# #TAB# return False #LINE# #TAB# for m in model_a.modules: #LINE# #TAB# #TAB# if m.name!= model_b.module_name: #LINE# #TAB# #TAB# #TAB# return False #LINE# #TAB# return True
"#LINE# #TAB# archive = zipfile.ZipFile(zip_filename, 'w', zipfile.ZIP_DEFLATED, base=base_path #LINE# #TAB# #TAB# ) #LINE# #TAB# for f in files: #LINE# #TAB# #TAB# archive.write(f, arcname=os.path.basename(f)) #LINE# #TAB# return archive"
#LINE# #TAB# try: #LINE# #TAB# #TAB# os.unlink(mount_point) #LINE# #TAB# except OSError: #LINE# #TAB# #TAB# pass
#LINE# #TAB# if elapsed < lease_time: #LINE# #TAB# #TAB# return int(elapsed / lease_time) #LINE# #TAB# else: #LINE# #TAB# #TAB# return elapsed
"#LINE# #TAB# tzi = getattr(dt, 'tzinfo', None) #LINE# #TAB# if tzi is not None: #LINE# #TAB# #TAB# dt = dt.astimezone(UTC) #LINE# #TAB# #TAB# tzi = UTC #LINE# #TAB# base = float(dt.toordinal()) #LINE# #TAB# cdate = getattr(dt, 'date', lambda : None)() #LINE# #TAB# if cdate is not None: #LINE# #TAB# #TAB# midnight_time = datetime.time(0, tzinfo=tzi) #LINE# #TAB# #TAB# rdt = datetime.datetime(midnight_time.year, midnight_time.month, midnight_time. #LINE# #TAB# #TAB# #TAB# day, tzinfo=tzi) #LINE# #TAB# #TAB# base += (dt - rdt).total_seconds() / SEC_PER_DAY #LINE# #TAB# return base"
#LINE# #TAB# if node.tail is None: #LINE# #TAB# #TAB# node.tail = value #LINE# #TAB# elif node.tail is not None: #LINE# #TAB# #TAB# node.tail = value #LINE# #TAB# else: #LINE# #TAB# #TAB# node.tail = value #LINE# #TAB# return node
#LINE# #TAB# try: #LINE# #TAB# #TAB# return str(int(tag)) #LINE# #TAB# except ValueError: #LINE# #TAB# #TAB# return tag
#LINE# #TAB# queryset = query.no_dereference() #LINE# #TAB# queryset = queryset.filter(Q(deleted=False) | Q(deleted=True) | Q( #LINE# #TAB# #TAB# deleted__isnull=True) | Q(deleted=True) | Q(deleted=True)) #LINE# #TAB# return queryset
"#LINE# #TAB# vertices_neighbours = _get_vertices_neighbours(nets) #LINE# #TAB# for subgraph_vertices in _get_connected_subgraphs(vertices_resources, #LINE# #TAB# #TAB# vertices_neighbours): #LINE# #TAB# #TAB# for subgraph in _get_subgraphs(subgraph_vertices, vertices_neighbours): #LINE# #TAB# #TAB# #TAB# cuthill_mckee = _cuthill_mckee(subgraph_vertices, subgraph) #LINE# #TAB# #TAB# #TAB# yield cuthill_mckee[0], cuthill_mckee[1]"
#LINE# #TAB# cursor.execute('SELECT * FROM metadata') #LINE# #TAB# rows = cursor.fetchall() #LINE# #TAB# return [row[0] for row in rows]
#LINE# #TAB# yaml = _YAML() #LINE# #TAB# yaml.allow_duplicate_keys = True #LINE# #TAB# return yaml
#LINE# #TAB# installed_dists_by_name = {} #LINE# #TAB# for installed_dist in installed_dists: #LINE# #TAB# #TAB# installed_dists_by_name[installed_dist.project_name] = installed_dist #LINE# #TAB# for requirement in dist.requires(): #LINE# #TAB# #TAB# if requirement.project_name not in installed_dists_by_name: #LINE# #TAB# #TAB# #TAB# yield requirement
#LINE# #TAB# if text.endswith(suffix): #LINE# #TAB# #TAB# return text[:-len(suffix)] #LINE# #TAB# return text
"#LINE# #TAB# a = xyz[0] #LINE# #TAB# b = xyz[1] #LINE# #TAB# c = xyz[2] #LINE# #TAB# return a, b, c"
#LINE# #TAB# if i >= 2 ** 28: #LINE# #TAB# #TAB# raise ValueError('value of {} is too large'.format(i)) #LINE# #TAB# elif i < 0: #LINE# #TAB# #TAB# raise ValueError('value cannot be negative') #LINE# #TAB# return (i + 1) * 4 - 4
"#LINE# #TAB# config = module.params['config'] #LINE# #TAB# try: #LINE# #TAB# #TAB# f = open(config, 'r') #LINE# #TAB# #TAB# ip_addr = json.loads(f.read()) #LINE# #TAB# #TAB# f.close() #LINE# #TAB# except IOError as e: #LINE# #TAB# #TAB# if e.errno == errno.ENOENT: #LINE# #TAB# #TAB# #TAB# return False #LINE# #TAB# #TAB# module.fail_json(msg='Failed to open the allocation file %s for reading' % #LINE# #TAB# #TAB# #TAB# config.filename) #LINE# #TAB# except ValueError as e: #LINE# #TAB# #TAB# module.fail_json(msg='Failed to parse the allocation file %s for reading' % #LINE# #TAB# #TAB# #TAB# config.filename) #LINE# #TAB# except Exception as e: #LINE# #TAB# #TAB# module.fail_json(msg='Failed to parse the allocation file"
"#LINE# #TAB# sock = DDPSocket() #LINE# #TAB# sock.setsockopt(socket.SOL_SOCKET, DDPSocket.SO_REUSEADDR, 1) #LINE# #TAB# sock.setsockopt(socket.SOL_SOCKET, DDPSocket.SO_REUSEADDR, 1) #LINE# #TAB# sock.settimeout(timeout) #LINE# #TAB# return sock"
"#LINE# #TAB# if os.path.isdir(directory): #LINE# #TAB# #TAB# return [(f'{directory}/__init__', f) for f in os.listdir(directory) if #LINE# #TAB# #TAB# #TAB# os.path.isfile(os.path.join(directory, f)) and f.endswith('.py')] #LINE# #TAB# if flush_local_modules: #LINE# #TAB# #TAB# foo = [] #LINE# #TAB# #TAB# for filename in os.listdir(directory): #LINE# #TAB# #TAB# #TAB# if filename.endswith('.py'): #LINE# #TAB# #TAB# #TAB# #TAB# foo.append((f'{directory}/__init__.py', os.path.join( #LINE# #TAB# #TAB# #TAB# #TAB# #TAB# directory, filename))) #LINE# #TAB# return foo"
"#LINE# #TAB# cmd = comm.strip().split(' ') #LINE# #TAB# try: #LINE# #TAB# #TAB# json_data = json.loads(comm) #LINE# #TAB# except ValueError: #LINE# #TAB# #TAB# args = None #LINE# #TAB# else: #LINE# #TAB# #TAB# if json_data: #LINE# #TAB# #TAB# #TAB# args = json_data #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# raise ValueError('{} is not a valid json json string'.format( #LINE# #TAB# #TAB# #TAB# #TAB# comm)) #LINE# #TAB# return cmd, args"
"#LINE# #TAB# try: #LINE# #TAB# #TAB# return portgroup_shaping_policy(pg_name, pg_default_port_config #LINE# #TAB# #TAB# #TAB# ).shaping_policy #LINE# #TAB# except: #LINE# #TAB# #TAB# return ''"
"#LINE# #TAB# if url: #LINE# #TAB# #TAB# url = unquote(url) #LINE# #TAB# #TAB# parsed = urlparse(url) #LINE# #TAB# #TAB# return parsed.username, parsed.password #LINE# #TAB# return '', ''"
"#LINE# #TAB# matches = [] #LINE# #TAB# with open(filename) as f: #LINE# #TAB# #TAB# for line in f: #LINE# #TAB# #TAB# #TAB# r = line.rstrip().split('\t') #LINE# #TAB# #TAB# #TAB# confidence = float(r[1]) #LINE# #TAB# #TAB# #TAB# if confidence!= 0.0: #LINE# #TAB# #TAB# #TAB# #TAB# matches.append((int(r[0]), r[1])) #LINE# #TAB# return matches"
#LINE# #TAB# p = [] #LINE# #TAB# if type(elements) == int: #LINE# #TAB# #TAB# elements = int(elements) #LINE# #TAB# if elements <= 0: #LINE# #TAB# #TAB# return p #LINE# #TAB# if elements == 1: #LINE# #TAB# #TAB# p.append(0) #LINE# #TAB# else: #LINE# #TAB# #TAB# for i in range(len(p)): #LINE# #TAB# #TAB# #TAB# p.append(p[i]) #LINE# #TAB# #TAB# return p
"#LINE# #TAB# #TAB# started = False #LINE# #TAB# #TAB# for idx, s in enumerate(mol2_lst): #LINE# #TAB# #TAB# #TAB# if s.startswith('@<TRIPOS>ATOM'): #LINE# #TAB# #TAB# #TAB# #TAB# first_idx = idx + 1 #LINE# #TAB# #TAB# #TAB# #TAB# started = True #LINE# #TAB# #TAB# #TAB# elif started and s.startswith('@<TRIPOS>'): #LINE# #TAB# #TAB# #TAB# #TAB# last_idx_plus1 = idx #LINE# #TAB# #TAB# #TAB# #TAB# break #LINE# #TAB# #TAB# return mol2_lst[first_idx:last_idx_plus1]"
#LINE# #TAB# for key in dictnode_tree: #LINE# #TAB# #TAB# if key == src: #LINE# #TAB# #TAB# #TAB# dictnode_tree[key] = dictnode_tree[key][0] #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# src.append(key) #LINE# #TAB# #TAB# #TAB# try: #LINE# #TAB# #TAB# #TAB# #TAB# dictnode_tree[key][-1] = dictnode_tree[key][-1] #LINE# #TAB# #TAB# #TAB# except KeyError: #LINE# #TAB# #TAB# #TAB# #TAB# pass #LINE# #TAB# return dictnode_tree
#LINE# #TAB# try: #LINE# #TAB# #TAB# returning = options['returnType'] #LINE# #TAB# except KeyError: #LINE# #TAB# #TAB# return base_context.returnType #LINE# #TAB# else: #LINE# #TAB# #TAB# if type(returning) is str: #LINE# #TAB# #TAB# #TAB# return ReturnType(returning) #LINE# #TAB# #TAB# return returning
#LINE# #TAB# if use_ordered_dict: #LINE# #TAB# #TAB# dict_ = OrderedDict #LINE# #TAB# if index_col is not None: #LINE# #TAB# #TAB# columns = [col for col in df.columns if col!= index_col] #LINE# #TAB# else: #LINE# #TAB# #TAB# columns = df.columns #LINE# #TAB# data = [] #LINE# #TAB# for row in df.iterrows(): #LINE# #TAB# #TAB# new_row = {} #LINE# #TAB# #TAB# for key in columns: #LINE# #TAB# #TAB# #TAB# new_row[key] = row[key] #LINE# #TAB# #TAB# data.append(new_row) #LINE# #TAB# return data
#LINE# #TAB# #TAB# if not now: #LINE# #TAB# #TAB# #TAB# now = datetime.datetime.now() #LINE# #TAB# #TAB# offset = timestamp - now #LINE# #TAB# #TAB# return offset
"#LINE# #TAB# graph = _dot_graph(nicknames, relations, name, format, program, directed) #LINE# #TAB# graph.name = name #LINE# #TAB# graph.relations = relations #LINE# #TAB# graph.directed = directed #LINE# #TAB# return graph"
"#LINE# #TAB# all_columns = list(filter(lambda el: el[-2:] == '_I', df.columns)) #LINE# #TAB# for column in all_columns: #LINE# #TAB# #TAB# del df[column]"
"#LINE# #TAB# if not in_dict: #LINE# #TAB# #TAB# return in_dict #LINE# #TAB# for key, val in in_dict.items(): #LINE# #TAB# #TAB# if val is not None: #LINE# #TAB# #TAB# #TAB# if isinstance(val, dict): #LINE# #TAB# #TAB# #TAB# #TAB# foo(val) #LINE# #TAB# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# #TAB# in_dict[key] = [val] #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# in_dict.pop(key, None) #LINE# #TAB# return in_dict"
#LINE# #TAB# handler = logging.StreamHandler() #LINE# #TAB# handler.setLevel(logging.DEBUG) #LINE# #TAB# formatter = logging.Formatter( #LINE# #TAB# #TAB# '%(asctime)s - %(levelname)s - %(module)s: %(message)s') #LINE# #TAB# handler.setFormatter(formatter) #LINE# #TAB# handler.addFilter(FooFilter()) #LINE# #TAB# return handler
"#LINE# #TAB# result = {} #LINE# #TAB# for key in d: #LINE# #TAB# #TAB# if key not in skip and not isinstance(d[key], (list, tuple)): #LINE# #TAB# #TAB# #TAB# result[key] = d[key] #LINE# #TAB# return result"
"#LINE# #TAB# frontend_modules = _load_frontend_modules(config, internal_attributes) #LINE# #TAB# for backend in frontend_modules: #LINE# #TAB# #TAB# callback(backend, config) #LINE# #TAB# return None"
"#LINE# #TAB# func_name = func.__name__ #LINE# #TAB# func_lineno = func.__code__.co_firstlineno #LINE# #TAB# src = inspect.getsourcelines(func)[1] #LINE# #TAB# data = {'file': func_name, 'lineno': func_lineno,'source': src} #LINE# #TAB# return data"
"#LINE# #TAB# try: #LINE# #TAB# #TAB# pickle.dumps(obj_class, 2) #LINE# #TAB# #TAB# return True #LINE# #TAB# except: #LINE# #TAB# #TAB# return False"
"#LINE# #TAB# #TAB# return [models.DbReference(reference=x.text) for x in entry.iterfind( #LINE# #TAB# #TAB# #TAB# './dbReference', namespaces=NAMESPACES)]"
"#LINE# #TAB# for histories_per_epoch in histories: #LINE# #TAB# #TAB# for i in range(1, len(histories_per_epoch)): #LINE# #TAB# #TAB# #TAB# yield histories_per_epoch[i][0], histories_per_epoch[i][1]"
"#LINE# #TAB# code = sys.exc_info()[1] #LINE# #TAB# report = '{code}:{report}'.format(code=code, report=report) #LINE# #TAB# return report"
"#LINE# #TAB# for name in os.listdir(dirpath): #LINE# #TAB# #TAB# full_name = os.path.join(dirpath, name) #LINE# #TAB# #TAB# if os.path.isdir(full_name): #LINE# #TAB# #TAB# #TAB# for entry in foo(full_name, cond=cond): #LINE# #TAB# #TAB# #TAB# #TAB# yield entry #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# yield full_name"
#LINE# #TAB# if value < 0: #LINE# #TAB# #TAB# return value + '-' #LINE# #TAB# return value
"#LINE# #TAB# with open(jsonParams, 'r') as f: #LINE# #TAB# #TAB# jsonFile = f.read() #LINE# #TAB# parsedJSON = json.loads(jsonFile) #LINE# #TAB# return parsedJSON[blockNames.ControlFileParams.generalParams], parsedJSON[ #LINE# #TAB# #TAB# blockNames.ControlFileParams.spawningBlockname], parsedJSON[ #LINE# #TAB# #TAB# blockNames.ControlFileParams.simulationBlockname], parsedJSON[ #LINE# #TAB# #TAB# blockNames.ControlFileParams.clusteringBlockname]"
"#LINE# #TAB# result = [] #LINE# #TAB# for i in dir(obj): #LINE# #TAB# #TAB# if callable(getattr(obj, i)) and not i.startswith('_'): #LINE# #TAB# #TAB# #TAB# result.append((i, getattr(obj, i))) #LINE# #TAB# return result"
#LINE# #TAB# if format == 'insdc': #LINE# #TAB# #TAB# return [] #LINE# #TAB# return [word for word in foo() if format.lower() == word.lower()]
#LINE# #TAB# keys = p[0] #LINE# #TAB# p[0] = keys + [p[1]] #LINE# #TAB# p[0][1] = keys + [p[3]]
"#LINE# #TAB# theta = 0.0 #LINE# #TAB# valid = T == 298.15 #LINE# #TAB# return theta, valid"
#LINE# #TAB# if match.end >= len(chars): #LINE# #TAB# #TAB# return True #LINE# #TAB# return match.input_string[match.end] in chars
"#LINE# #TAB# body = cls.admin_client.networks.get(subnet_id=subnet_id, router_id= #LINE# #TAB# #TAB# router_id, name=name) #LINE# #TAB# vpn_service = body['vpn_service'] #LINE# #TAB# cls.vpn_services.append(vpn_service) #LINE# #TAB# return vpn_service"
"#LINE# #TAB# table = formatting.Table(['Id', 'KeyName'], 'Rules') #LINE# #TAB# for rule in rules: #LINE# #TAB# #TAB# table.add_row([rule['id'], rule['keyName']]) #LINE# #TAB# return table"
"#LINE# #TAB# if isinstance(schema, string_types): #LINE# #TAB# #TAB# obj = ICachedItemMapper(schema) #LINE# #TAB# elif isinstance(schema, dict): #LINE# #TAB# #TAB# obj = ICachedItemMapper(schema) #LINE# #TAB# else: #LINE# #TAB# #TAB# obj = ICachedItemMapper(schema) #LINE# #TAB# return obj"
#LINE# #TAB# try: #LINE# #TAB# #TAB# urllib.parse.urlparse(uri) #LINE# #TAB# #TAB# return True #LINE# #TAB# except Exception: #LINE# #TAB# #TAB# return False
"#LINE# #TAB# urls = [] #LINE# #TAB# if resource[-1] == '/': #LINE# #TAB# #TAB# resources = resource[:-1] #LINE# #TAB# #TAB# for r in resources: #LINE# #TAB# #TAB# #TAB# if r.endswith('/'): #LINE# #TAB# #TAB# #TAB# #TAB# r = r[:-1] #LINE# #TAB# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# #TAB# r = r[:-1] #LINE# #TAB# #TAB# #TAB# urls += [(""r"", r)] #LINE# #TAB# else: #LINE# #TAB# #TAB# urls = ["""", resource] #LINE# #TAB# return urls"
#LINE# #TAB# result = True #LINE# #TAB# try: #LINE# #TAB# #TAB# subprocess.check_call(command) #LINE# #TAB# #TAB# result = True #LINE# #TAB# except subprocess.CalledProcessError: #LINE# #TAB# #TAB# result = False #LINE# #TAB# return result
"#LINE# #TAB# try: #LINE# #TAB# #TAB# return apply_func(fget, fset, fdel) #LINE# #TAB# except AttributeError: #LINE# #TAB# #TAB# return value_not_found"
"#LINE# #TAB# q = q.copy() #LINE# #TAB# for i in range(q.shape[1]): #LINE# #TAB# #TAB# if q[i, 0]!= x[i]: #LINE# #TAB# #TAB# #TAB# return False #LINE# #TAB# if add_v: #LINE# #TAB# #TAB# f = f[i] #LINE# #TAB# return True"
#LINE# #TAB# numerator = f / df_num #LINE# #TAB# denominator = f / df_den #LINE# #TAB# if denominator == 0.0: #LINE# #TAB# #TAB# return numerator * df_den #LINE# #TAB# elif denominator == 1.0: #LINE# #TAB# #TAB# return numerator * df_num #LINE# #TAB# return numerator / denominator
#LINE# #TAB# request_handler.is_authenticated = validator(request_handler.request) #LINE# #TAB# return request_handler
"#LINE# #TAB# if isinstance(path, Path): #LINE# #TAB# #TAB# path = str(path) #LINE# #TAB# if isinstance(path, str): #LINE# #TAB# #TAB# path = Path(path) #LINE# #TAB# if not isinstance(path, Path): #LINE# #TAB# #TAB# raise TypeError('invalid path type') #LINE# #TAB# if isinstance(path, Path): #LINE# #TAB# #TAB# return str(path) #LINE# #TAB# return path"
"#LINE# #TAB# n = X.shape[0] #LINE# #TAB# J = np.zeros((n, n)) #LINE# #TAB# for i in range(n): #LINE# #TAB# #TAB# for j in range(n): #LINE# #TAB# #TAB# #TAB# J[i, j] = cells[j] #LINE# #TAB# return J"
"#LINE# #TAB# if trun[""conf""][""VERBOSE""]: #LINE# #TAB# #TAB# cij.emph(""rnr:trun:exit { name: %r }"" % tsuite[""name""]) #LINE# #TAB# rcode = 0 #LINE# #TAB# for hook in tsuite[""hooks""][""exit""]:#TAB# #LINE# #TAB# #TAB# rcode = script_run(trun, hook) #LINE# #TAB# #TAB# if rcode: #LINE# #TAB# #TAB# #TAB# break #LINE# #TAB# if trun[""conf""][""VERBOSE""]: #LINE# #TAB# #TAB# cij.emph(""rnr:trun::exit { rcode: %r }"" % rcode, rcode) #LINE# #TAB# return rcode"
"#LINE# #TAB# for filename in os.listdir(path): #LINE# #TAB# #TAB# if filename.endswith('.exe') and os.access(os.path.join(path, filename), os.X_OK): #LINE# #TAB# #TAB# #TAB# yield filename"
"#LINE# #TAB# if nsname and nspid: #LINE# #TAB# #TAB# nspath = os.path.join(nspath, nsname) #LINE# #TAB# elif nspath is None: #LINE# #TAB# #TAB# nspath = os.getcwd() #LINE# #TAB# else: #LINE# #TAB# #TAB# nspath = nspath #LINE# #TAB# if nspath is not None: #LINE# #TAB# #TAB# return os.path.join(nspath, nspid) #LINE# #TAB# else: #LINE# #TAB# #TAB# return nspath"
#LINE# #TAB# for item in items: #LINE# #TAB# #TAB# if item['groupid'] in groupids: #LINE# #TAB# #TAB# #TAB# yield item
#LINE# #TAB# if 'type' in schema: #LINE# #TAB# #TAB# return schema['type'] #LINE# #TAB# elif 'enum' in schema: #LINE# #TAB# #TAB# return [x.name for x in schema['enum']] #LINE# #TAB# else: #LINE# #TAB# #TAB# return []
"#LINE# #TAB# while isinstance(node, Node): #LINE# #TAB# #TAB# yield node #LINE# #TAB# #TAB# node = node.nextSibling"
#LINE# #TAB# if running_tm_ver == '1': #LINE# #TAB# #TAB# return True #LINE# #TAB# elif running_tm_ver == '2': #LINE# #TAB# #TAB# return True #LINE# #TAB# else: #LINE# #TAB# #TAB# return False
"#LINE# #TAB# assert metric in ['l1', 'l2'] #LINE# #TAB# data = samples.astype(float) #LINE# #TAB# if metric == 'l1': #LINE# #TAB# #TAB# data = l1(data) #LINE# #TAB# elif metric == 'l2': #LINE# #TAB# #TAB# data = l2(data) #LINE# #TAB# return data"
"#LINE# #TAB# for key, value in cls.__dict__.items(): #LINE# #TAB# #TAB# if isinstance(value, property): #LINE# #TAB# #TAB# #TAB# yield key, value"
"#LINE# #TAB# assert match in ['exact', 'exact'] #LINE# #TAB# if col_names is not None: #LINE# #TAB# #TAB# details = state.details #LINE# #TAB# else: #LINE# #TAB# #TAB# details = state.details #LINE# #TAB# foo_test = [] #LINE# #TAB# for col in col_names: #LINE# #TAB# #TAB# foo_test.append(details[col][0]) #LINE# #TAB# if sort: #LINE# #TAB# #TAB# foo_test.sort(key=lambda x: x[1]) #LINE# #TAB# return foo_test"
#LINE# #TAB# key = variants['key'] #LINE# #TAB# position = fields_to_position(variants) #LINE# #TAB# variants['position'] = position #LINE# #TAB# variants['title'] = key #LINE# #TAB# variants['variant'] = variants #LINE# #TAB# return variants
"#LINE# #TAB# try: #LINE# #TAB# #TAB# res = requests.head(url, headers={'User-Agent': 'Mozilla/5.0'}) #LINE# #TAB# #TAB# res.raise_for_status() #LINE# #TAB# except requests.exceptions.ConnectionError: #LINE# #TAB# #TAB# return -1 #LINE# #TAB# if res.status_code!= 200: #LINE# #TAB# #TAB# return -1 #LINE# #TAB# else: #LINE# #TAB# #TAB# return res.status_code"
"#LINE# #TAB# with monitor('weighting riskinputs', monitor=monitor) as risk: #LINE# #TAB# #TAB# alpha = riskmodel.alpha(riskinputs) #LINE# #TAB# #TAB# beta = param['beta'] #LINE# #TAB# #TAB# log_prob = param['log_prob'] #LINE# #TAB# #TAB# prob = riskmodel.score(riskinputs, alpha=alpha, log_prob=log_prob) #LINE# #TAB# D = monitor('weighting riskinputs', riskinputs, param, monitor=monitor) #LINE# #TAB# D[0, 0] += 1 #LINE# #TAB# D[1, 1] -= 1 #LINE# #TAB# D[np.isnan(D)] = 0 #LINE# #TAB# return D"
#LINE# #TAB# plugin_name = plugin_class.NAME.lower() #LINE# #TAB# if plugin_name in cls._plugin_classes: #LINE# #TAB# raise KeyError('Plugin class already set for name: {0:s}.'.format( #LINE# #TAB# #TAB# plugin_class.NAME)) #LINE# #TAB# cls._plugin_classes[plugin_name] = plugin_class
"#LINE# #TAB# data = get_apps(app, env=env, region=region) #LINE# #TAB# result = [] #LINE# #TAB# for d in data: #LINE# #TAB# #TAB# try: #LINE# #TAB# #TAB# #TAB# data[d] = data[app]['details'] #LINE# #TAB# #TAB# except KeyError: #LINE# #TAB# #TAB# #TAB# pass #LINE# #TAB# return result"
#LINE# #TAB# V2 = V * np.log(2) #LINE# #TAB# return V2
#LINE# #TAB# body = cls.admin_client. floating_ips.get(external_network_id= #LINE# #TAB# #TAB# external_network_id) #LINE# #TAB# return body['address']
#LINE# #TAB# if type(rows) == tuple: #LINE# #TAB# #TAB# if left: #LINE# #TAB# #TAB# #TAB# return [row[0] for row in rows] #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# return [row[0] for row in rows] #LINE# #TAB# else: #LINE# #TAB# #TAB# return rows
"#LINE# #TAB# body = '' #LINE# #TAB# for key, value in params.items(): #LINE# #TAB# #TAB# if key == 'dwgsim': #LINE# #TAB# #TAB# #TAB# body += f' [{key}]: {value}' #LINE# #TAB# #TAB# elif value == 'true': #LINE# #TAB# #TAB# #TAB# body += f' [{key}]: {value}' #LINE# #TAB# #TAB# elif value == 'false': #LINE# #TAB# #TAB# #TAB# body += f' [{key}]: {value}' #LINE# #TAB# return body"
"#LINE# #TAB# outfile = outdir / '.tsv' #LINE# #TAB# df.to_csv(outfile, index=False, sep='\t') #LINE# #TAB# return outfile"
#LINE# #TAB# config.LOGGER.info('Fetching files on Kolibri Studio...') #LINE# #TAB# files_to_diff = set() #LINE# #TAB# for file_id in files_to_diff: #LINE# #TAB# #TAB# with tree.get_node(file_id) as node: #LINE# #TAB# #TAB# #TAB# config.LOGGER.info('Fetching file: {}'.format(file_id)) #LINE# #TAB# #TAB# #TAB# files_to_diff.add(file_id) #LINE# #TAB# return files_to_diff
"#LINE# #TAB# foo = os.path.join(project_folder, 'foo') #LINE# #TAB# return foo"
"#LINE# #TAB# span = ts.span #LINE# #TAB# if span[0] < start or span[1] > end: #LINE# #TAB# #TAB# return ts.pad((pad, 0), mode='constant', constant_values=(span[0], #LINE# #TAB# #TAB# #TAB# start, end)) #LINE# #TAB# elif span[0] == start and span[1] < end: #LINE# #TAB# #TAB# return ts.pad((pad, 0), mode='constant', constant_values=(span[1], #LINE# #TAB# #TAB# #TAB# start, end)) #LINE# #TAB# return ts"
"#LINE# #TAB# global tmp_github_token #LINE# #TAB# if tmp_github_token is not None: #LINE# #TAB# #TAB# with open(tmp_github_token, 'r') as f: #LINE# #TAB# #TAB# #TAB# pass #LINE# #TAB# else: #LINE# #TAB# #TAB# tmp_github_token = '' #LINE# #TAB# return tmp_github_token"
#LINE# #TAB# x = np.arange(Nu) / float(Nc) #LINE# #TAB# y = np.arange(Nc) / float(Nu) #LINE# #TAB# if y == 0 or y == 1: #LINE# #TAB# #TAB# clust = 0 #LINE# #TAB# else: #LINE# #TAB# #TAB# clust = 1 #LINE# #TAB# return clust
"#LINE# #TAB# max_size = powerline.segment_conf('cwd','max_dir_size') #LINE# #TAB# if max_size: #LINE# #TAB# #TAB# return name[:max_size] #LINE# #TAB# return name"
#LINE# #TAB# filename = get_filename(experiment) #LINE# #TAB# template = get_template('space_section.html') #LINE# #TAB# context = {} #LINE# #TAB# context['title'] = filename #LINE# #TAB# context['title']['title'] = experiment.title #LINE# #TAB# context['title']['url'] = filename #LINE# #TAB# rendered = template.render(**context) #LINE# #TAB# return rendered
#LINE# #TAB# if 'id' in data: #LINE# #TAB# #TAB# return data['id'] #LINE# #TAB# else: #LINE# #TAB# #TAB# return data
"#LINE# #TAB# if isinstance(obj, datetime): #LINE# #TAB# #TAB# obj = obj.isoformat() #LINE# #TAB# return obj"
#LINE# #TAB# model = LockBaseModel() #LINE# #TAB# if lock_base_model: #LINE# #TAB# #TAB# model.lock_level = 1 #LINE# #TAB# return model
#LINE# #TAB# image = Image.open(BytesIO(data)) #LINE# #TAB# image = Image.open(BytesIO(image.read())) #LINE# #TAB# return image
#LINE# #TAB# is_marker = False #LINE# #TAB# try: #LINE# #TAB# #TAB# if fhpatch.read(1) == '\n': #LINE# #TAB# #TAB# #TAB# is_marker = True #LINE# #TAB# #TAB# elif fhpatch.read(1) == '\r\n': #LINE# #TAB# #TAB# #TAB# is_marker = True #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# is_marker = True #LINE# #TAB# except IOError: #LINE# #TAB# #TAB# pass #LINE# #TAB# return is_marker
"#LINE# #TAB# with open('./sequence_length', 'r') as f: #LINE# #TAB# #TAB# l = int(f.read()) #LINE# #TAB# #TAB# return l #LINE# #TAB# return 0"
"#LINE# #TAB# actions = [] #LINE# #TAB# for func_name in dir(cls): #LINE# #TAB# #TAB# func = getattr(cls, func_name) #LINE# #TAB# #TAB# if not hasattr(func, '__call__') or getattr(func, #LINE# #TAB# #TAB# #TAB# '__daemonocle_exposed__', False) is not True: #LINE# #TAB# #TAB# #TAB# continue #LINE# #TAB# #TAB# action = func_name.replace('_', '-') #LINE# #TAB# #TAB# if action not in actions: #LINE# #TAB# #TAB# #TAB# actions.append(action) #LINE# #TAB# return actions"
"#LINE# #TAB# try: #LINE# #TAB# #TAB# with open(path, 'r') as f: #LINE# #TAB# #TAB# #TAB# return [line.strip() for line in f.readlines()] #LINE# #TAB# except IOError: #LINE# #TAB# #TAB# return []"
#LINE# #TAB# #TAB# java_object = JavaObject(clazz) #LINE# #TAB# #TAB# return java_object
"#LINE# #TAB# if not rate: #LINE# #TAB# #TAB# return #LINE# #TAB# factor, scale = rate.split(':', 1) #LINE# #TAB# scale = int(scale) #LINE# #TAB# if scale < 1: #LINE# #TAB# #TAB# raise ValueError('Invalid rate: {}'.format(rate)) #LINE# #TAB# return (float(scale) * 1000) / factor"
"#LINE# #TAB# if '.' not in job.task: #LINE# #TAB# #TAB# return job #LINE# #TAB# major, minor = job.task.split('.') #LINE# #TAB# if LooseVersion(major) < LooseVersion('0.1.5'): #LINE# #TAB# #TAB# return job #LINE# #TAB# return job"
"#LINE# #TAB# text = text.replace('&lt;', '<') #LINE# #TAB# text = text.replace('&gt;', '>') #LINE# #TAB# text = text.replace('&quot;', '""') #LINE# #TAB# return text"
"#LINE# #TAB# if isinstance(obj, dict): #LINE# #TAB# #TAB# return {k: foo(v) for k, v in obj.items()} #LINE# #TAB# elif isinstance(obj, list): #LINE# #TAB# #TAB# return [foo(i) for i in obj] #LINE# #TAB# elif isinstance(obj, tuple): #LINE# #TAB# #TAB# return obj.__class__([foo(i) for i in obj]) #LINE# #TAB# else: #LINE# #TAB# #TAB# return obj"
"#LINE# #TAB# model_prop = getattr(model_cls, prop_name) #LINE# #TAB# if model_prop is None: #LINE# #TAB# #TAB# return None #LINE# #TAB# else: #LINE# #TAB# #TAB# return model_prop"
"#LINE# #TAB# with open('lizard_inbox.txt', 'r') as f: #LINE# #TAB# #TAB# try: #LINE# #TAB# #TAB# #TAB# f.read() #LINE# #TAB# #TAB# #TAB# del f.readlines() #LINE# #TAB# #TAB# except IOError: #LINE# #TAB# #TAB# #TAB# pass"
#LINE# #TAB# if context.advance == 1: #LINE# #TAB# #TAB# context.advance = 0 #LINE# #TAB# elif context.advance == 2: #LINE# #TAB# #TAB# context.advance = 3 #LINE# #TAB# elif context.advance == 4: #LINE# #TAB# #TAB# context.advance = 5 #LINE# #TAB# return context
#LINE# #TAB# new_gmt_datadir = os.environ.get('GMT_DATADIR') #LINE# #TAB# if new_gmt_datadir == old_gmt_datadir: #LINE# #TAB# #TAB# del os.environ['GMT_DATADIR'] #LINE# #TAB# else: #LINE# #TAB# #TAB# os.environ['GMT_DATADIR'] = new_gmt_datadir
"#LINE# #TAB# files = [] #LINE# #TAB# if os.path.isdir(default_config_path): #LINE# #TAB# #TAB# for dirpath, dirnames, filenames in os.walk(default_config_path): #LINE# #TAB# #TAB# #TAB# for filename in filenames: #LINE# #TAB# #TAB# #TAB# #TAB# filename = os.path.join(dirpath, filename) #LINE# #TAB# #TAB# #TAB# #TAB# if filename.endswith('.json'): #LINE# #TAB# #TAB# #TAB# #TAB# #TAB# with open(filename, 'r') as fp: #LINE# #TAB# #TAB# #TAB# #TAB# #TAB# #TAB# content = json.load(fp) #LINE# #TAB# #TAB# #TAB# #TAB# #TAB# files.append(content) #LINE# #TAB# return files"
"#LINE# #TAB# if file_name.endswith("".gz""): #LINE# #TAB# #TAB# f = gzip.open(file_name, ""rb"") #LINE# #TAB# else: #LINE# #TAB# #TAB# f = open(file_name, ""w"") #LINE# #TAB# return f"
"#LINE# #TAB# clusters = context['clusters'] #LINE# #TAB# result = None #LINE# #TAB# if cluster in clusters: #LINE# #TAB# #TAB# if show_progress: #LINE# #TAB# #TAB# #TAB# show_progress_bar(context, result, cluster) #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# show_progress_bar(context, result, cluster) #LINE# #TAB# else: #LINE# #TAB# #TAB# show_progress_bar(context, result, cluster) #LINE# #TAB# return result"
#LINE# #TAB# encoded = {} #LINE# #TAB# for key in to_encode: #LINE# #TAB# #TAB# if to_encode[key] == 'b': #LINE# #TAB# #TAB# #TAB# encoded['b'] = int(to_encode[key]) #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# encoded[key] = to_encode[key] #LINE# #TAB# return encoded
"#LINE# #TAB# x = ZeroPadding2D(((1, 0), (1, 0)))(x) #LINE# #TAB# for i in range(num_blocks): #LINE# #TAB# #TAB# x = darknet_conv2d_bn_leaky(num_filters, (3, 3), strides=(2, 2))(x) #LINE# #TAB# #TAB# x = darknet_conv2d_bn_leaky(num_filters, (3, 3), strides=(2, 2))(x) #LINE# #TAB# #TAB# x = Add()([x, x]) #LINE# #TAB# return x"
#LINE# #TAB# i = 1 #LINE# #TAB# while True: #LINE# #TAB# #TAB# a = c #LINE# #TAB# #TAB# b = i #LINE# #TAB# #TAB# while b == 1: #LINE# #TAB# #TAB# #TAB# a = a + 1 #LINE# #TAB# #TAB# #TAB# b = b + 1 #LINE# #TAB# #TAB# if a < 0: #LINE# #TAB# #TAB# #TAB# i = 0 #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# i = i + 1 #LINE# #TAB# return i
#LINE# #TAB# coordinates = deepcopy(frac_coordinates) #LINE# #TAB# for coord in range(coordinates.shape[0]): #LINE# #TAB# #TAB# coordinates[coord] = lattice_array[coord] #LINE# #TAB# return coordinates
"#LINE# #TAB# key = _expnum_ccd_key(expnum, ccd, version) #LINE# #TAB# if prefix: #LINE# #TAB# #TAB# key = ""%s/%s/%s"" % (prefix, key, ccd) #LINE# #TAB# if key in expnum_ccd_to_foo: #LINE# #TAB# #TAB# return expnum_ccd_to_foo[key] #LINE# #TAB# else: #LINE# #TAB# #TAB# return expnum_ccd_to_foo[expnum]"
#LINE# #TAB# out = [] #LINE# #TAB# for i in range(len(stack)): #LINE# #TAB# #TAB# out.append(yen(stack[i])) #LINE# #TAB# return out
#LINE# #TAB# if s.startswith(start): #LINE# #TAB# #TAB# raise ValueError('Value {0} not found'.format(s)) #LINE# #TAB# return s[len(start):]
"#LINE# #TAB# if not isinstance(value, (int, float)): #LINE# #TAB# #TAB# raise TypeError(""Glyph left margin must be an :ref:`type-int-float`, not %s."" #LINE# #TAB# #TAB# #TAB# #TAB# #TAB# #TAB# % type(value).__name__) #LINE# #TAB# return value"
"#LINE# #TAB# if counts.sum() <= n: #LINE# #TAB# #TAB# return counts #LINE# #TAB# nz = counts.nonzero()[0] #LINE# #TAB# result = zeros(n, dtype=dtype) #LINE# #TAB# for i in nz: #LINE# #TAB# #TAB# result[i] += counts[i].cumsum() #LINE# #TAB# return result"
"#LINE# #TAB# res = {} #LINE# #TAB# for k, v in d.items(): #LINE# #TAB# #TAB# if isinstance(v, dict): #LINE# #TAB# #TAB# #TAB# res[k] = foo(v) #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# res[k] = v #LINE# #TAB# return res"
"#LINE# #TAB# if isinstance(o, type(None)): #LINE# #TAB# #TAB# try: #LINE# #TAB# #TAB# #TAB# return json.dumps(o) #LINE# #TAB# #TAB# except: #LINE# #TAB# #TAB# #TAB# return o"
"#LINE# #TAB# method = request.method.lower() #LINE# #TAB# if method.lower() == 'post': #LINE# #TAB# #TAB# return direct(request, ""/"", method=method) #LINE# #TAB# elif method.lower() == 'put': #LINE# #TAB# #TAB# return direct(request, ""/"", method=method) #LINE# #TAB# elif method.lower() == 'delete': #LINE# #TAB# #TAB# return direct(request, ""/"", method=method) #LINE# #TAB# return None"
#LINE# #TAB# for s in structures: #LINE# #TAB# #TAB# t1 = s.get_lattice() #LINE# #TAB# #TAB# try: #LINE# #TAB# #TAB# #TAB# if t1.lattice!= t2.lattice: #LINE# #TAB# #TAB# #TAB# #TAB# raise ValueError('Structure does not have the same lattice') #LINE# #TAB# except ValueError: #LINE# #TAB# #TAB# pass #LINE# #TAB# return
#LINE# #TAB# msg_hash = hashlib.sha1(message).digest() #LINE# #TAB# return msg_hash
"#LINE# #TAB# if month > 13: #LINE# #TAB# #TAB# raise ValueError('Incorrect month index') #LINE# #TAB# if month in (IYYAR, TAMMUZ, ELUL, TEVETH, VEADAR): #LINE# #TAB# #TAB# return 29 #LINE# #TAB# if month == ADAR and not leap(year): #LINE# #TAB# #TAB# return 29 #LINE# #TAB# if month == HESHVAN and year_days(year) % 10!= 5: #LINE# #TAB# #TAB# return 29 #LINE# #TAB# if month == KISLEV and year_days(year) % 10 == 3: #LINE# #TAB# #TAB# return 29 #LINE# #TAB# return 30"
#LINE# #TAB# if url.startswith('http'): #LINE# #TAB# #TAB# url = url[4:] #LINE# #TAB# if url.startswith('https'): #LINE# #TAB# #TAB# if url.endswith('ftp'): #LINE# #TAB# #TAB# #TAB# url = url[:-5] #LINE# #TAB# #TAB# if url.endswith('file'): #LINE# #TAB# #TAB# #TAB# url = url[:-4] #LINE# #TAB# return url
#LINE# #TAB# for i in range(len(l)): #LINE# #TAB# #TAB# if l[i]!= l[i + 1]: #LINE# #TAB# #TAB# #TAB# return False #LINE# #TAB# return True
"#LINE# #TAB# for i in range(control_board.num_controls): #LINE# #TAB# #TAB# center_x, center_y = fitted_params[i] #LINE# #TAB# #TAB# low_vals = fitted_params[i] #LINE# #TAB# #TAB# high_vals = fitted_params[i + 1] #LINE# #TAB# #TAB# control_board.control_board[center_x, center_y] = low_vals #LINE# #TAB# #TAB# for j in range(control_board.num_control_points): #LINE# #TAB# #TAB# #TAB# control_board.control_board[control_board.num_control_points[j #LINE# #TAB# #TAB# #TAB# #TAB# ], low_vals, high_vals] = high_vals"
"#LINE# #TAB# country_deaths = {} #LINE# #TAB# for country in instance.countries.keys(): #LINE# #TAB# #TAB# for item in instance.countries[country]: #LINE# #TAB# #TAB# #TAB# country_deaths[country] = {} #LINE# #TAB# #TAB# if country in country_deaths: #LINE# #TAB# #TAB# #TAB# del country_deaths[country] #LINE# #TAB# return {'country_deaths': country_deaths, 'country_deaths_per_country': #LINE# #TAB# #TAB# country_deaths}"
"#LINE# #TAB# result = {} #LINE# #TAB# for child in tree.iter(): #LINE# #TAB# #TAB# result[child.tag] = {} #LINE# #TAB# #TAB# for key, value in child.attrib.items(): #LINE# #TAB# #TAB# #TAB# if key.lower() == 'height': #LINE# #TAB# #TAB# #TAB# #TAB# result[child.tag].update({'height': value}) #LINE# #TAB# #TAB# #TAB# elif key.lower() == 'width': #LINE# #TAB# #TAB# #TAB# #TAB# result[child.tag].update({'width': value}) #LINE# #TAB# return result"
#LINE# #TAB# ret = [] #LINE# #TAB# for line in open(sys.stderr): #LINE# #TAB# #TAB# if line.find(search_string) >= 0: #LINE# #TAB# #TAB# #TAB# if ret.count(replacement_line): #LINE# #TAB# #TAB# #TAB# #TAB# ret.append(replacement_line) #LINE# #TAB# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# #TAB# ret.append(line) #LINE# #TAB# return ret
#LINE# #TAB# p1 = p.term() #LINE# #TAB# if p1.has_terminals(): #LINE# #TAB# #TAB# return 'FUNC' #LINE# #TAB# elif p1.has_children(): #LINE# #TAB# #TAB# return 'FUNC' #LINE# #TAB# else: #LINE# #TAB# #TAB# return 'FUNC'
#LINE# #TAB# if align & 1: #LINE# #TAB# #TAB# return align - 1 #LINE# #TAB# else: #LINE# #TAB# #TAB# return 0
#LINE# #TAB# unassigned = [] #LINE# #TAB# for analysis in analysis_request.getAnalyses(): #LINE# #TAB# #TAB# status = api.get_workflow_status_of(analysis) #LINE# #TAB# #TAB# if status not in unassigned: #LINE# #TAB# #TAB# #TAB# return False #LINE# #TAB# #TAB# if status == 'unassigned': #LINE# #TAB# #TAB# #TAB# unassigned.append(True) #LINE# #TAB# #TAB# elif status == 'accepted': #LINE# #TAB# #TAB# #TAB# return True #LINE# #TAB# return False
#LINE# #TAB# if not host: #LINE# #TAB# #TAB# return True #LINE# #TAB# elif host == '127.0.0.1': #LINE# #TAB# #TAB# return True #LINE# #TAB# elif host == '127.0.0.1': #LINE# #TAB# #TAB# return True #LINE# #TAB# else: #LINE# #TAB# #TAB# return False
"#LINE# #TAB# if isinstance(arg, (list, tuple)): #LINE# #TAB# #TAB# try: #LINE# #TAB# #TAB# #TAB# res = lookup_dict[arg[0]] #LINE# #TAB# #TAB# except KeyError: #LINE# #TAB# #TAB# #TAB# res = arg #LINE# #TAB# elif isinstance(arg, str): #LINE# #TAB# #TAB# if arg.startswith('Backend'): #LINE# #TAB# #TAB# #TAB# res = lookup_dict[arg] #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# res = lookup_dict[arg] #LINE# #TAB# elif arg.startswith('alert/'): #LINE# #TAB# #TAB# res = lookup_dict[arg] #LINE# #TAB# else: #LINE# #TAB# #TAB# res = arg #LINE# #TAB# return res"
"#LINE# #TAB# res = [] #LINE# #TAB# conn = connection.cursor() #LINE# #TAB# conn.execute('SELECT * FROM %s WHERE %s LIMIT 0' % (db, tbl, index)) #LINE# #TAB# result = conn.fetchall() #LINE# #TAB# for row in result: #LINE# #TAB# #TAB# res.append(row[0]) #LINE# #TAB# return res"
#LINE# #TAB# try: #LINE# #TAB# #TAB# os.makedirs(path) #LINE# #TAB# except OSError as exc: #LINE# #TAB# #TAB# if exc.errno == errno.EEXIST: #LINE# #TAB# #TAB# #TAB# pass #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# raise
"#LINE# #TAB# repo_name = project_element.attrib.get('name') #LINE# #TAB# store_handler = getattr(project_element,'store_handler', None) #LINE# #TAB# if store_handler is not None: #LINE# #TAB# #TAB# return store_handler #LINE# #TAB# project_handler = getattr(project_element, 'project_handler', None) #LINE# #TAB# if project_handler is not None: #LINE# #TAB# #TAB# return project_handler #LINE# #TAB# store_handler = getattr(project_element,'store_handler', None) #LINE# #TAB# if store_handler is not None: #LINE# #TAB# #TAB# return store_handler #LINE# #TAB# return None"
"#LINE# #TAB# bool=False) ->str: #LINE# #TAB# if table_code == 1: #LINE# #TAB# #TAB# print('Table code == 1', table_code) #LINE# #TAB# elif table_code == 2: #LINE# #TAB# #TAB# print('Table code == 2', table_code) #LINE# #TAB# elif table_code == 3: #LINE# #TAB# #TAB# print('Table code == 3', table_code) #LINE# #TAB# else: #LINE# #TAB# #TAB# print('Table code == 4', table_code) #LINE# #TAB# #TAB# raise NotImplementedError(table_name) #LINE# #TAB# return table_name"
"#LINE# #TAB# for recipes in node.run_list: #LINE# #TAB# #TAB# for key in recipes: #LINE# #TAB# #TAB# #TAB# if isinstance(recipes[key], dict): #LINE# #TAB# #TAB# #TAB# #TAB# if node == recipes[key]: #LINE# #TAB# #TAB# #TAB# #TAB# #TAB# return key #LINE# #TAB# return None"
"#LINE# #TAB# parts = name.split('.') #LINE# #TAB# base = parts[0] #LINE# #TAB# ext = '.' + parts[-1] #LINE# #TAB# return {'base': base, 'ext': ext}"
"#LINE# #TAB# mean = [0.485, 0.456, 0.406] #LINE# #TAB# std = [0.229, 0.224, 0.225] #LINE# #TAB# image = image.convert('RGB') #LINE# #TAB# result = np.asarray(image) #LINE# #TAB# if mean[0]!= 0: #LINE# #TAB# #TAB# mean = [mean[0], mean[1]] #LINE# #TAB# if std[0]!= 0: #LINE# #TAB# #TAB# std = [std[0], std[1]] #LINE# #TAB# result = crop_and_resize(result, 224) #LINE# #TAB# return result"
#LINE# #TAB# f = open(template_file) #LINE# #TAB# xl = f.read() #LINE# #TAB# f.close() #LINE# #TAB# return xl
#LINE# #TAB# import os #LINE# #TAB# if platform.system() == 'Windows': #LINE# #TAB# #TAB# return os.path.expanduser('~/.local/share') #LINE# #TAB# elif platform.system() == 'Linux': #LINE# #TAB# #TAB# return '/usr/local/share' #LINE# #TAB# else: #LINE# #TAB# #TAB# return '/usr/share'
"#LINE# #TAB# if line.startswith(""#""): #LINE# #TAB# #TAB# key = line[1:].strip() #LINE# #TAB# #TAB# val = line[3:].strip() #LINE# #TAB# #TAB# if key in prop_dict: #LINE# #TAB# #TAB# #TAB# del prop_dict[key]"
#LINE# #TAB# if ':' not in s: #LINE# #TAB# #TAB# return 1 #LINE# #TAB# try: #LINE# #TAB# #TAB# i = int(s.split(':')[0]) #LINE# #TAB# except ValueError: #LINE# #TAB# #TAB# try: #LINE# #TAB# #TAB# #TAB# i = int(s.split(':')[1]) #LINE# #TAB# #TAB# except ValueError: #LINE# #TAB# #TAB# #TAB# pass #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# return i #LINE# #TAB# else: #LINE# #TAB# #TAB# return i
"#LINE# #TAB# import os #LINE# #TAB# os.environ['ENVIRONMENT'] = 'ENVIRONMENT' #LINE# #TAB# try: #LINE# #TAB# #TAB# import anaconda #LINE# #TAB# except ImportError: #LINE# #TAB# #TAB# pass #LINE# #TAB# else: #LINE# #TAB# #TAB# try: #LINE# #TAB# #TAB# #TAB# os.environ['ID'] = anaconda.__version__ #LINE# #TAB# #TAB# except (AttributeError, KeyError): #LINE# #TAB# #TAB# #TAB# pass #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# os.environ['ID'] += '_' + str(anaconda.__version__) #LINE# #TAB# return"
"#LINE# #TAB# res = [] #LINE# #TAB# for name in dir(cls): #LINE# #TAB# #TAB# if name.startswith('_'): #LINE# #TAB# #TAB# #TAB# continue #LINE# #TAB# #TAB# if isinstance(getattr(cls, name), property): #LINE# #TAB# #TAB# #TAB# if name!= '_id': #LINE# #TAB# #TAB# #TAB# #TAB# res.append(name) #LINE# #TAB# return res"
#LINE# #TAB# conn = sqlite3.connect(database_name) #LINE# #TAB# curs = conn.cursor() #LINE# #TAB# curs.execute('SELECT * from devices;') #LINE# #TAB# all_devices = [] #LINE# #TAB# query = 'SELECT * from devices;' #LINE# #TAB# curs.execute(query) #LINE# #TAB# for row in curs.fetchall(): #LINE# #TAB# #TAB# if any(search_string in row['device_name'] for search_string in #LINE# #TAB# #TAB# #TAB# search_string): #LINE# #TAB# #TAB# #TAB# all_devices.append(row) #LINE# #TAB# return all_devices
#LINE# #TAB# try: #LINE# #TAB# #TAB# return obj.dtend #LINE# #TAB# except AttributeError: #LINE# #TAB# #TAB# try: #LINE# #TAB# #TAB# #TAB# return obj.duration #LINE# #TAB# #TAB# except AttributeError: #LINE# #TAB# #TAB# #TAB# return obj.dtstart
"#LINE# #TAB# tdict = {} #LINE# #TAB# for alias in typealiases: #LINE# #TAB# #TAB# if ':' in alias: #LINE# #TAB# #TAB# #TAB# alias, val = alias.split(':') #LINE# #TAB# #TAB# #TAB# tdict[alias] = val #LINE# #TAB# return tdict"
"#LINE# #TAB# try: #LINE# #TAB# #TAB# ret = getattr(settings, section) #LINE# #TAB# except AttributeError: #LINE# #TAB# #TAB# ret = default #LINE# #TAB# return ret"
#LINE# #TAB# if state.chosen is not None: #LINE# #TAB# #TAB# return state.chosen #LINE# #TAB# else: #LINE# #TAB# #TAB# return ''
#LINE# #TAB# logger = logging.getLogger(name) #LINE# #TAB# logger.propagate = True #LINE# #TAB# return logger
"#LINE# #TAB# if DJANGO_VERSION < (1, 8): #LINE# #TAB# #TAB# child.alias = alias_map.get(child.alias, child.alias) #LINE# #TAB# else: #LINE# #TAB# #TAB# child.alias = alias_map[child.alias] = child.alias #LINE# #TAB# return child"
"#LINE# #TAB# return {k: request_parameters[k] if type(request_parameters[k]) == dict else #LINE# #TAB# #TAB# request_parameters[k] for k in ['year','month', 'day', 'hour','minute', #LINE# #TAB# #TAB#'second'] if type(request_parameters[k]) == int else request_parameters[k]}"
"#LINE# #TAB# with open(filename, 'rb') as f: #LINE# #TAB# #TAB# f.seek(2048, 2) #LINE# #TAB# #TAB# return struct.unpack('<I', f.read(4))[0]"
"#LINE# #TAB# fig = plt.figure() #LINE# #TAB# ax = fig.add_subplot(111) #LINE# #TAB# ax.plot(exp_ind[0], exp_ind[1], swim_speed[0], color='red') #LINE# #TAB# for i in range(1, len(exp_ind)): #LINE# #TAB# #TAB# ax.plot(exp_ind[i], exp_ind[i + 1] + swim_speed[i], color='blue') #LINE# #TAB# ax.set_title('Speed during experimental indices') #LINE# #TAB# return fig"
"#LINE# #TAB# #TAB# cert = cls(token=api_token, id=cert_id) #LINE# #TAB# #TAB# cert.load() #LINE# #TAB# #TAB# return cert"
"#LINE# #TAB# check_parameter(path, doc_root) #LINE# #TAB# if os.path.isfile(path): #LINE# #TAB# #TAB# return os.path.normpath(os.path.join(doc_root, path)) #LINE# #TAB# return path"
#LINE# #TAB# try: #LINE# #TAB# #TAB# return int(txt) #LINE# #TAB# except: #LINE# #TAB# #TAB# return None
"#LINE# #TAB# if value is NoneValue: #LINE# #TAB# #TAB# return True #LINE# #TAB# if isinstance(value, type): #LINE# #TAB# #TAB# return False #LINE# #TAB# for func in globals(): #LINE# #TAB# #TAB# func = getattr(type, func, None) #LINE# #TAB# #TAB# if func is not None: #LINE# #TAB# #TAB# #TAB# return True #LINE# #TAB# return False"
#LINE# #TAB# global __context__ #LINE# #TAB# __context__ = None
"#LINE# #TAB# for idx in indices: #LINE# #TAB# #TAB# full = os.path.join(indir, idx) #LINE# #TAB# #TAB# if os.path.isfile(full): #LINE# #TAB# #TAB# #TAB# return full"
#LINE# #TAB# global _paths #LINE# #TAB# path = path or foo(path) #LINE# #TAB# if path not in _paths: #LINE# #TAB# #TAB# _paths.append(path) #LINE# #TAB# return path
"#LINE# #TAB# with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s: #LINE# #TAB# #TAB# s.bind((start_port, 0)) #LINE# #TAB# #TAB# return s.getsockname()[1]"
"#LINE# #TAB# old_mtime = os.path.getmtime(file_path) #LINE# #TAB# file_mtime = os.path.getmtime(file_path) #LINE# #TAB# return old_mtime, file_mtime"
#LINE# #TAB# if name.startswith('http'): #LINE# #TAB# #TAB# return 'http:' + name #LINE# #TAB# elif name.startswith('https'): #LINE# #TAB# #TAB# return 'https:' + name #LINE# #TAB# else: #LINE# #TAB# #TAB# return 'unknown'
"#LINE# #TAB# try: #LINE# #TAB# #TAB# config_filename = get_default_config_filename(ipython_dir) #LINE# #TAB# #TAB# if not os.path.isfile(config_filename): #LINE# #TAB# #TAB# #TAB# return {} #LINE# #TAB# #TAB# with open(config_filename, 'r') as f: #LINE# #TAB# #TAB# #TAB# config = loads(f.read()) #LINE# #TAB# #TAB# return config #LINE# #TAB# except FileNotFoundError: #LINE# #TAB# #TAB# return {}"
"#LINE# #TAB# if options.filename: #LINE# #TAB# #TAB# f = open(options.filename, 'r') #LINE# #TAB# #TAB# first = f.readline().strip() #LINE# #TAB# #TAB# second = f.readline().strip() #LINE# #TAB# #TAB# f.close() #LINE# #TAB# #TAB# if first: #LINE# #TAB# #TAB# #TAB# c = first #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# c = '""' + second + '""' #LINE# #TAB# else: #LINE# #TAB# #TAB# c = str(options) #LINE# #TAB# #TAB# f = open(options.filename, 'w') #LINE# #TAB# f.write(c) #LINE# #TAB# f.close() #LINE# #TAB# return '\n' + c"
#LINE# #TAB# import os #LINE# #TAB# data = os.path.basename(sys.executable) #LINE# #TAB# return data
#LINE# #TAB# record.start = record.start + n_bases #LINE# #TAB# return record
"#LINE# #TAB# mask = np.zeros_like(points) #LINE# #TAB# if priority is not None: #LINE# #TAB# #TAB# threshold = priority #LINE# #TAB# #TAB# for i, point in enumerate(points): #LINE# #TAB# #TAB# #TAB# mask[i] = ((point.x - radius) ** 2 + #LINE# #TAB# #TAB# #TAB# #TAB# #TAB# ((point.y - radius) ** 2) < threshold) #LINE# #TAB# return mask"
#LINE# #TAB# try: #LINE# #TAB# #TAB# aminame = Image_Name.objects.get(id=inst_img_id) #LINE# #TAB# except: #LINE# #TAB# #TAB# aminame = 'unknown' #LINE# #TAB# return aminame
"#LINE# #TAB# try: #LINE# #TAB# #TAB# code, message = response.split(' ') #LINE# #TAB# except ValueError: #LINE# #TAB# #TAB# return 'Command error' #LINE# #TAB# if code == -1: #LINE# #TAB# #TAB# return message #LINE# #TAB# else: #LINE# #TAB# #TAB# return f'Command error {code}'"
"#LINE# #TAB# for function in node.body: #LINE# #TAB# #TAB# if isinstance(function, ast.FunctionDef): #LINE# #TAB# #TAB# #TAB# return function"
"#LINE# #TAB# return { #LINE# #TAB# #TAB# route.name: dict( #LINE# #TAB# #TAB# #TAB# [( #LINE# #TAB# #TAB# #TAB# #TAB# blueprint.name, #LINE# #TAB# #TAB# #TAB# #TAB# (blueprint.path.startswith(base_path)), #LINE# #TAB# #TAB# #TAB# ) #LINE# #TAB# #TAB# #TAB# for blueprint in app.blueprints #LINE# #TAB# #TAB# ] #LINE# #TAB# }"
"#LINE# #TAB# try: #LINE# #TAB# #TAB# module_path, class_name = dotted_path.rsplit('.', 1) #LINE# #TAB# except ValueError as err: #LINE# #TAB# #TAB# raise ImportError(""%s doesn't look like a module path"" % dotted_path #LINE# #TAB# #TAB# #TAB# ) from err #LINE# #TAB# module = import_module(module_path) #LINE# #TAB# try: #LINE# #TAB# #TAB# return getattr(module, class_name) #LINE# #TAB# except AttributeError as err: #LINE# #TAB# #TAB# raise ImportError( #LINE# #TAB# #TAB# #TAB# 'Module ""%s"" does not define a ""%s"" attribute/class' % ( #LINE# #TAB# #TAB# #TAB# module_path, class_name)) from err"
#LINE# #TAB# managers = dict() #LINE# #TAB# if admin_required is None: #LINE# #TAB# #TAB# return managers #LINE# #TAB# for service in managers: #LINE# #TAB# #TAB# if admin_required and resource_manager_is_admin(service): #LINE# #TAB# #TAB# #TAB# managers[service] = True #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# for resource_manager_name in resource_manager._registry.values(): #LINE# #TAB# #TAB# #TAB# #TAB# if resource_manager_name!= admin_required: #LINE# #TAB# #TAB# #TAB# #TAB# #TAB# managers[service_manager_name] = False #LINE# #TAB# #TAB# #TAB# #TAB# #TAB# managers[service_manager_name].append(resource_manager_name) #LINE# #TAB# return managers
#LINE# #TAB# from django.forms.widgets import DateTimeBaseInput #LINE# #TAB# try: #LINE# #TAB# #TAB# from django.forms.widgets import DateTimeBaseInput #LINE# #TAB# #TAB# return DateTimeBaseInput #LINE# #TAB# except ImportError: #LINE# #TAB# #TAB# if test: #LINE# #TAB# #TAB# #TAB# raise ImportError( #LINE# #TAB# #TAB# #TAB# #TAB# 'django.forms.widgets.widgets must be installed to get the class from django.forms.widgets.' #LINE# #TAB# #TAB# #TAB# #TAB# ) #LINE# #TAB# #TAB# return DateTimeBaseInput
"#LINE# #TAB# out_files = [] #LINE# #TAB# for in_file in in_files: #LINE# #TAB# #TAB# if ""regex"" in in_file: #LINE# #TAB# #TAB# #TAB# regex = in_file.split(""\\"")[0] #LINE# #TAB# #TAB# #TAB# matches = fnmatch.filter(regex, in_file) #LINE# #TAB# #TAB# #TAB# if matches: #LINE# #TAB# #TAB# #TAB# #TAB# out_files.append((in_file, matches[0])) #LINE# #TAB# #TAB# #TAB# elif isinstance(matches, dict): #LINE# #TAB# #TAB# #TAB# #TAB# for key, val in matches.items(): #LINE# #TAB# #TAB# #TAB# #TAB# #TAB# out_files.append((in_file, key, val)) #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# out_files.append(in_file) #LINE# #TAB# return out_"
"#LINE# #TAB# import sqlite3 #LINE# #TAB# db_file = sqlite3.connect(':memory:') #LINE# #TAB# conn = sqlite3.connect(db_file) #LINE# #TAB# c = conn.cursor() #LINE# #TAB# c.execute('select key, value from database') #LINE# #TAB# data = c.fetchall() #LINE# #TAB# c.close() #LINE# #TAB# print(data[0]) #LINE# #TAB# return data[1], data[2]"
"#LINE# #TAB# for name, annotation in raw_annotations.items(): #LINE# #TAB# #TAB# if name == '__foo__': #LINE# #TAB# #TAB# #TAB# continue #LINE# #TAB# #TAB# if module_name and inspect.ismodule(module_name): #LINE# #TAB# #TAB# #TAB# module = importlib.import_module(module_name) #LINE# #TAB# #TAB# _foo_annotations[name] = annotation #LINE# #TAB# return _foo_annotations"
"#LINE# #TAB# if not rule: #LINE# #TAB# #TAB# return False #LINE# #TAB# for rule in rules: #LINE# #TAB# #TAB# if fnmatch.fnmatch(rule, name): #LINE# #TAB# #TAB# #TAB# return rule #LINE# #TAB# return True"
"#LINE# #TAB# try: #LINE# #TAB# #TAB# if subprocess.check_output('git rev-parse --verify HEAD'.split()[0], #LINE# #TAB# #TAB# #TAB# stderr=subprocess.STDOUT): #LINE# #TAB# #TAB# #TAB# return 0 #LINE# #TAB# #TAB# return 1 #LINE# #TAB# except subprocess.CalledProcessError: #LINE# #TAB# #TAB# return 2"
"#LINE# #TAB# if not testcases_root: #LINE# #TAB# #TAB# return #LINE# #TAB# config_file = os.path.join(testcases_root, 'testcases.yaml') #LINE# #TAB# if not os.path.exists(config_file): #LINE# #TAB# #TAB# return #LINE# #TAB# with open(config_file, 'r') as fh: #LINE# #TAB# #TAB# for line in fh: #LINE# #TAB# #TAB# #TAB# if not line.strip(): #LINE# #TAB# #TAB# #TAB# #TAB# continue #LINE# #TAB# #TAB# #TAB# testcase = parse_testcase_file(line) #LINE# #TAB# #TAB# #TAB# testcase['is_missing'] = False"
"#LINE# #TAB# file_name = 'GLWS.TXT' #LINE# #TAB# home = os.path.expanduser('~') + '/' + 'GLWS.TXT' #LINE# #TAB# file_path = os.path.join(home, file_name) #LINE# #TAB# z = get_zip_file(file_path) #LINE# #TAB# data = pd.read_csv(z.open(file_path), header=None, sep=',', quotechar='""') #LINE# #TAB# data.columns = gamelog_columns #LINE# #TAB# return data"
"#LINE# #TAB# if isinstance(value, six.string_types): #LINE# #TAB# #TAB# if not value: #LINE# #TAB# #TAB# #TAB# raise ValueError('Input {} must be a string'.format(input_names)) #LINE# #TAB# if isinstance(value, (tuple, list)): #LINE# #TAB# #TAB# if len(value)!= 1: #LINE# #TAB# #TAB# #TAB# raise ValueError('Input {} must be a list of two values'.format( #LINE# #TAB# #TAB# #TAB# #TAB# input_names)) #LINE# #TAB# for input_name, input_value in six.iteritems(input_names): #LINE# #TAB# #TAB# if input_value and not isinstance(input_value, six.string_types): #LINE# #TAB# #TAB# #TAB# raise ValueError('Input {} must be a string'.format(input_name)) #LINE# #TAB# return value"
"#LINE# #TAB# log = get_mod_logger(mod) #LINE# #TAB# try: #LINE# #TAB# #TAB# return {'new': mod.get_event_info(),'modded': mod.get_event_info()} #LINE# #TAB# except AttributeError: #LINE# #TAB# #TAB# pass #LINE# #TAB# return {}"
#LINE# #TAB# result = dict() #LINE# #TAB# for key in data: #LINE# #TAB# #TAB# value = data[key] #LINE# #TAB# #TAB# if boxed_type == 'date': #LINE# #TAB# #TAB# #TAB# value = parse_date(value) #LINE# #TAB# #TAB# elif boxed_type == 'year': #LINE# #TAB# #TAB# #TAB# value = parse_year(value) #LINE# #TAB# #TAB# elif boxed_type =='month': #LINE# #TAB# #TAB# #TAB# value = parse_month(value) #LINE# #TAB# #TAB# elif boxed_type == 'year': #LINE# #TAB# #TAB# #TAB# value = parse_year(value) #LINE# #TAB# #TAB# result[key] = value #LINE# #TAB# return result
#LINE# #TAB# unique_repo_list = list() #LINE# #TAB# for repo in repo_list: #LINE# #TAB# #TAB# if repo not in unique_repo_list: #LINE# #TAB# #TAB# #TAB# unique_repo_list.append(repo) #LINE# #TAB# return unique_repo_list
"#LINE# #TAB# _regex = r'<(.*?)>' #LINE# #TAB# return [x for x in re.finditer(_regex, text)]"
"#LINE# #TAB# try: #LINE# #TAB# #TAB# return vicon.GetSubjectParam(name, param) #LINE# #TAB# except vicon.ViconError: #LINE# #TAB# #TAB# return None"
"#LINE# #TAB# if a.dtype!= dtype: #LINE# #TAB# #TAB# raise TypeError('{} is not of type {}'.format(a.dtype, dtype)) #LINE# #TAB# return a"
"#LINE# #TAB# result = False #LINE# #TAB# if isinstance(mem_size_str, str): #LINE# #TAB# #TAB# size = int(mem_size_str) #LINE# #TAB# elif isinstance(mem_size_str, int) and reserve_time is not None: #LINE# #TAB# #TAB# size = int(reserve_time) #LINE# #TAB# #TAB# if size == '1GB': #LINE# #TAB# #TAB# #TAB# result = True #LINE# #TAB# #TAB# elif size == '1MB': #LINE# #TAB# #TAB# #TAB# result = True #LINE# #TAB# #TAB# elif size == '10GB': #LINE# #TAB# #TAB# #TAB# result = True #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# result = False #LINE# #TAB# else: #LINE# #TAB# #TAB# result = True #LINE# #TAB# return result"
"#LINE# #TAB# d = pd.read_table(fn, header=None) #LINE# #TAB# cols = d.columns if usecols is None else usecols #LINE# #TAB# names = [] #LINE# #TAB# for i in range(len(cols)): #LINE# #TAB# #TAB# names.append(cols[i]) #LINE# #TAB# return names"
"#LINE# #TAB# if len(cloud) < 4: #LINE# #TAB# #TAB# return cloud #LINE# #TAB# if not cloud[3].isdigit() and cloud[3] not in ('/', '-'): #LINE# #TAB# #TAB# if cloud[3] == 'O': #LINE# #TAB# #TAB# #TAB# return cloud[:3] + '0' + cloud[4:] #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# return cloud + '.' + cloud[3] #LINE# #TAB# return cloud"
"#LINE# #TAB# t = {} #LINE# #TAB# for k, v in mapping.items(): #LINE# #TAB# #TAB# t[k] = set([v]) #LINE# #TAB# return t"
#LINE# #TAB# start = 0 #LINE# #TAB# while start < len(s) and s[start] == char: #LINE# #TAB# #TAB# start += 1 #LINE# #TAB# if start == len(s): #LINE# #TAB# #TAB# return start #LINE# #TAB# else: #LINE# #TAB# #TAB# return -1
"#LINE# #TAB# global px4_state #LINE# #TAB# if px4_state is None: #LINE# #TAB# #TAB# px4_state = DCM_State(ATT.Roll, ATT.Pitch, ATT.Yaw) #LINE# #TAB# px4_state.update(IMU) #LINE# #TAB# return px4_state"
#LINE# #TAB# if getenv('SSH_USER') is None: #LINE# #TAB# #TAB# return '/bin/sh' #LINE# #TAB# uid = os.getpwuid(os.getuid()) #LINE# #TAB# if uid is None: #LINE# #TAB# #TAB# return '/bin/sh' #LINE# #TAB# else: #LINE# #TAB# #TAB# return uid
"#LINE# #TAB# return {getattr(vpc, 'name', name): vpc for name in vpc.all_gateways #LINE# #TAB# #TAB# () if name!= 'default'}"
"#LINE# #TAB# if k in o: #LINE# #TAB# #TAB# return o[k].get('label') + ':' + v #LINE# #TAB# elif k == 'type': #LINE# #TAB# #TAB# return o[0].get('label') + v #LINE# #TAB# elif k == 'group': #LINE# #TAB# #TAB# g = o[0].get('group') #LINE# #TAB# #TAB# j = o[1].get('label') #LINE# #TAB# #TAB# return {'type': g, 'label': j, 'value': v} #LINE# #TAB# else: #LINE# #TAB# #TAB# return {'type': k, 'label': v}"
#LINE# #TAB# label = QLabel() #LINE# #TAB# label.setPixmap(QPixmap(str(name))) #LINE# #TAB# return label
"#LINE# #TAB# if p.h.startswith('!= '): #LINE# #TAB# #TAB# f = item.font(0) #LINE# #TAB# #TAB# f.setBold(True) #LINE# #TAB# #TAB# item.setFont(0, f) #LINE# #TAB# #TAB# return True #LINE# #TAB# return False"
"#LINE# #TAB# name = path[0] + '/' + ext #LINE# #TAB# if isinstance(obj, dict): #LINE# #TAB# #TAB# for k in obj.keys(): #LINE# #TAB# #TAB# #TAB# yield foo(obj[k], path + '/' + k, ext) #LINE# #TAB# elif isinstance(obj, list): #LINE# #TAB# #TAB# for i in obj: #LINE# #TAB# #TAB# #TAB# yield foo(i, path + '/' + k, ext) #LINE# #TAB# elif isinstance(obj, basestring): #LINE# #TAB# #TAB# yield obj"
"#LINE# #TAB# res = [] #LINE# #TAB# for i in x: #LINE# #TAB# #TAB# if isinstance(i, tuple): #LINE# #TAB# #TAB# #TAB# res.append(i) #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# res.append(i) #LINE# #TAB# return res"
"#LINE# #TAB# if textfile!= 'trip.txt': #LINE# #TAB# #TAB# raise ValueError('{} is not a proper text file name'.format(textfile)) #LINE# #TAB# df = pd.read_csv(os.path.join(textfile_path, textfile), dtype={ #LINE# #TAB# #TAB# 'trip_id': object}, low_memory=False) #LINE# #TAB# if len(df) == 0: #LINE# #TAB# #TAB# raise ValueError('{} has no records'.format(os.path.join( #LINE# #TAB# #TAB# #TAB# textfile_path, textfile))) #LINE# #TAB# df['trip_id'] = df['trip_id'].astype(int) #LINE# #TAB# df.rename(columns={'trip_id': 'trip_id'}, inplace=True) #LINE# #TAB# return df"
"#LINE# #TAB# git_dir = os.path.join(os.path.dirname(__file__),'shared', 'templates') #LINE# #TAB# if os.path.isdir(git_dir): #LINE# #TAB# #TAB# return git_dir #LINE# #TAB# return None"
"#LINE# #TAB# try: #LINE# #TAB# #TAB# return cls #LINE# #TAB# except TypeError: #LINE# #TAB# #TAB# pass #LINE# #TAB# try: #LINE# #TAB# #TAB# if issubclass(cls, ResponseMicroService) or issubclass(cls, #LINE# #TAB# #TAB# #TAB# RequestMicroService): #LINE# #TAB# #TAB# #TAB# raise cls #LINE# #TAB# except TypeError: #LINE# #TAB# #TAB# pass #LINE# #TAB# return cls"
"#LINE# #TAB# try: #LINE# #TAB# #TAB# return node.cardinality() #LINE# #TAB# except AttributeError: #LINE# #TAB# #TAB# return [(node, 1)]"
#LINE# #TAB# plugin_data = {} #LINE# #TAB# plugin_data['dashboard'] = dashboard_entry #LINE# #TAB# if dashboard_entry.plugin_name: #LINE# #TAB# #TAB# plugin_data['title'] = dashboard_entry.plugin_name #LINE# #TAB# #TAB# plugin_data['slug'] = dashboard_entry.slug #LINE# #TAB# if request: #LINE# #TAB# #TAB# try: #LINE# #TAB# #TAB# #TAB# request.user = request.user #LINE# #TAB# #TAB# except AttributeError: #LINE# #TAB# #TAB# #TAB# pass #LINE# #TAB# #TAB# plugin_data['request'] = request #LINE# #TAB# return plugin_data
"#LINE# #TAB# img_fits = fits.getdata(extname) #LINE# #TAB# img_coords = img_fits[:, :, (0)] #LINE# #TAB# img_params = img_fits[:, :, (1)] #LINE# #TAB# return img_coords, img_params"
"#LINE# #TAB# theta = 0.12 #LINE# #TAB# valid = T == 298.15 #LINE# #TAB# return theta, valid"
"#LINE# #TAB# url = '{}/api/v1/schools/{}/class_device'.format(API_BASE, school_id) #LINE# #TAB# resp = requests.get(url) #LINE# #TAB# code = resp.status_code #LINE# #TAB# data = resp.data.decode('utf-8') #LINE# #TAB# if code == 200: #LINE# #TAB# #TAB# return {'school_id': school_id, 'class_dev': data} #LINE# #TAB# else: #LINE# #TAB# #TAB# return {'school_id': school_id, 'class_dev': code}"
"#LINE# #TAB# blueprint = Blueprint(app) #LINE# #TAB# blueprint.add_url_rule('/<path:relative_path>', filter=os.path.join( #LINE# #TAB# #TAB# settings.LOAN_URL, 'index')) #LINE# #TAB# blueprint.add_url_rule('/<path:relative_path>', filter=os.path.join( #LINE# #TAB# #TAB# settings.LOAN_URL, 'index')) #LINE# #TAB# return blueprint"
"#LINE# #TAB# if not isinstance(ns, dict): #LINE# #TAB# #TAB# return ns #LINE# #TAB# for k, v in ns.items(): #LINE# #TAB# #TAB# if isinstance(v, Number): #LINE# #TAB# #TAB# #TAB# ns[k] = foo(v) #LINE# #TAB# #TAB# elif isinstance(v, dict): #LINE# #TAB# #TAB# #TAB# ns[k] = foo(v) #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# pass #LINE# #TAB# return ns"
#LINE# #TAB# if obj is not None: #LINE# #TAB# #TAB# return prefix + '/' + obj + suffix #LINE# #TAB# else: #LINE# #TAB# #TAB# return ''
#LINE# #TAB# try: #LINE# #TAB# #TAB# if exception is not None: #LINE# #TAB# #TAB# #TAB# raise exception #LINE# #TAB# #TAB# return 0 #LINE# #TAB# except Exception as e: #LINE# #TAB# #TAB# print('Error executing mutmut mutation test: {0}'.format(e)) #LINE# #TAB# #TAB# return 1
"#LINE# #TAB# return {'id': input_dict['id'],'stem': input_dict['stem'], 'level': #LINE# #TAB# #TAB# input_dict['level'],'stem_value': input_dict['stem_value']}"
"#LINE# #TAB# if alphabet and base_num.isdigit(): #LINE# #TAB# #TAB# num = base_num #LINE# #TAB# elif base_num.isdigit(): #LINE# #TAB# #TAB# num = int(base_num) #LINE# #TAB# elif base_num.startswith('1'): #LINE# #TAB# #TAB# num = int(base_num[1:]) #LINE# #TAB# elif base_num.startswith('2'): #LINE# #TAB# #TAB# num = int(base_num[2:]) #LINE# #TAB# else: #LINE# #TAB# #TAB# raise ValueError('Unrecognised base value: {num}'.format(num= #LINE# #TAB# #TAB# #TAB# base_num, base=base)) #LINE# #TAB# out = ''.join([alphabet[i] for i in range(num.bit_length())]) #LINE# #TAB# return out"
#LINE# #TAB# for p in entity_predictions: #LINE# #TAB# #TAB# if p['type']!= 'duckling': #LINE# #TAB# #TAB# #TAB# continue #LINE# #TAB# #TAB# yield p
"#LINE# #TAB# return {k: getattr(settings, k) for k in dir(cls) if not k. #LINE# #TAB# #TAB# startswith('_')}"
"#LINE# #TAB# buff = nd4j_array.data() #LINE# #TAB# address = buff.pointer().address() #LINE# #TAB# dtype = get_context_dtype() #LINE# #TAB# mapping = { #LINE# #TAB# #TAB# 'double': ctypes.c_double, #LINE# #TAB# #TAB# 'float': ctypes.c_float #LINE# #TAB# } #LINE# #TAB# Pointer = ctypes.POINTER(mapping[dtype]) #LINE# #TAB# pointer = ctypes.cast(address, Pointer) #LINE# #TAB# np_array = np.ctypeslib.as_array(pointer, tuple(nd4j_array.shape())) #LINE# #TAB# return np_array"
#LINE# #TAB# if name not in creator_funcs: #LINE# #TAB# #TAB# raise ValueError('Invalid creator function %r' % name) #LINE# #TAB# return creator_funcs[name]
#LINE# #TAB# if 'data' in data: #LINE# #TAB# #TAB# return data['data'][attribute_name] #LINE# #TAB# return ''
#LINE# #TAB# ret = True #LINE# #TAB# try: #LINE# #TAB# #TAB# r = auth.get(url) #LINE# #TAB# #TAB# if r.status_code == 200: #LINE# #TAB# #TAB# #TAB# ret = True #LINE# #TAB# except Exception as e: #LINE# #TAB# #TAB# ret = e #LINE# #TAB# return ret
"#LINE# #TAB# filepath = os.path.dirname(os.path.abspath(base_file)) #LINE# #TAB# filename = os.path.join(filepath, csv_name) #LINE# #TAB# engine = 'python' if sep!= ',' else 'c' #LINE# #TAB# float_precision = {} #LINE# #TAB# if engine == 'c': #LINE# #TAB# #TAB# float_precision = {'float_precision': 'high'} #LINE# #TAB# data = pd.read_csv(filename, sep=sep, engine=engine, **float_precision) #LINE# #TAB# if convert_float: #LINE# #TAB# #TAB# data = data.astype(float) #LINE# #TAB# return data"
"#LINE# #TAB# Operator = fields.SQL_OPERATORS[clause[1]] #LINE# #TAB# tab_sql = cls.get_sql_table() #LINE# #TAB# qu1 = tab_sql.select(tab_sql.id_line, where=Operator(tab_sql.title, #LINE# #TAB# #TAB# clause[2])) #LINE# #TAB# return [('id', 'in', qu1)]"
#LINE# #TAB# result = numpy.empty(vector_length) #LINE# #TAB# result[:-shift] = vector[0:-shift] #LINE# #TAB# result[-shift:] = vector[shift:] #LINE# #TAB# return result
#LINE# #TAB# result = '' #LINE# #TAB# for c in name: #LINE# #TAB# #TAB# if c.isupper(): #LINE# #TAB# #TAB# #TAB# if result == '_': #LINE# #TAB# #TAB# #TAB# #TAB# result = '_%s' % c.lower() #LINE# #TAB# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# #TAB# result += '_' + c.lower() #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# result += c #LINE# #TAB# return result
"#LINE# #TAB# return {'fvCEp': Endpoint, 'fvStCEp': Endpoint, 'fvCrtrn': #LINE# #TAB# #TAB# AttributeCriterion}"
#LINE# #TAB# if not is_hex(value): #LINE# #TAB# #TAB# raise ArgumentTypeError('Expected hex value.') #LINE# #TAB# return value
#LINE# #TAB# if type_string == 'boolean': #LINE# #TAB# #TAB# return 'true' #LINE# #TAB# if type_string == 'integer': #LINE# #TAB# #TAB# return 'number' #LINE# #TAB# if type_string =='string': #LINE# #TAB# #TAB# return'string' #LINE# #TAB# return type_string
"#LINE# #TAB# m = len(contactMap) #LINE# #TAB# eigenvalues = np.zeros(m) #LINE# #TAB# eigv = np.zeros(m) #LINE# #TAB# for c in contactMap: #LINE# #TAB# #TAB# i = 0 #LINE# #TAB# #TAB# while i < m: #LINE# #TAB# #TAB# #TAB# if c!= 0 and contactMap[c]!= 1: #LINE# #TAB# #TAB# #TAB# #TAB# i += 1 #LINE# #TAB# #TAB# #TAB# eigv[:, (i)] = np.linalg.norm(contactMap[c], axis=0) #LINE# #TAB# #TAB# #TAB# eigv[:, (i)] = np.linalg.norm(contactMap[c], axis=0) #LINE# #TAB# #TAB# eigv[:, (i)] = np.linalg.norm(eigv[:, (i)], axis=0) #LINE# #TAB# return eigenvalues, eigv"
"#LINE# #TAB# if points is None: #LINE# #TAB# #TAB# points = [nodes] #LINE# #TAB# ret = [] #LINE# #TAB# for i in range(deep): #LINE# #TAB# #TAB# if isinstance(points, vtk.vtkPolyData): #LINE# #TAB# #TAB# #TAB# ret.append(foo(nodes[i], points=points, dtype=dtype)) #LINE# #TAB# #TAB# elif isinstance(points, vtk.vtkNDArray): #LINE# #TAB# #TAB# #TAB# ret.append(foo(nodes[i], points=points, dtype=dtype, deep=deep)) #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# ret.append(nodes[i]) #LINE# #TAB# return ret"
"#LINE# #TAB# print('checking pi for %s' % ip_address) #LINE# #TAB# match = re.search('\\d+\\.\\d+\\.\\d+', ip_address) #LINE# #TAB# if match is not None: #LINE# #TAB# #TAB# print('Found %s in nmap' % match.group()) #LINE# #TAB# #TAB# return True #LINE# #TAB# else: #LINE# #TAB# #TAB# print('Could not find %s in nmap' % ip_address) #LINE# #TAB# #TAB# return False"
"#LINE# #TAB# if ext == '': #LINE# #TAB# #TAB# return None #LINE# #TAB# for parser, keyword in cls.suggestParsers: #LINE# #TAB# #TAB# if parser == text: #LINE# #TAB# #TAB# #TAB# return keyword #LINE# #TAB# return None"
"#LINE# #TAB# source_list = cls() #LINE# #TAB# for src_file in glob.glob(os.path.join(path, '*.sdetect')): #LINE# #TAB# #TAB# print('Reading {}'.format(src_file)) #LINE# #TAB# #TAB# source_list.append(Source(src_file)) #LINE# #TAB# return source_list"
"#LINE# #TAB# images = [] #LINE# #TAB# preload_images = soup.find_all('preload_images') #LINE# #TAB# for item in preload_images: #LINE# #TAB# #TAB# if item.tag == 'img': #LINE# #TAB# #TAB# #TAB# images.append(item.attrs['src']) #LINE# #TAB# filenames = [f for f in images if f.name.endswith('.jpg')] #LINE# #TAB# return images, filenames"
"#LINE# #TAB# try: #LINE# #TAB# #TAB# if isinstance(pointlist, list) or isinstance(pointlist, tuple): #LINE# #TAB# #TAB# #TAB# for i, point in enumerate(pointlist): #LINE# #TAB# #TAB# #TAB# #TAB# assert isinstance(point, Point) #LINE# #TAB# #TAB# return True #LINE# #TAB# except: #LINE# #TAB# #TAB# return False"
#LINE# #TAB# t = time.gps() #LINE# #TAB# return t / 3600.0
#LINE# #TAB# try: #LINE# #TAB# #TAB# os.scandir(path) #LINE# #TAB# #TAB# return True #LINE# #TAB# except OSError: #LINE# #TAB# #TAB# return False
"#LINE# #TAB# if name.startswith('t_'): #LINE# #TAB# #TAB# return name.replace('t_', '') #LINE# #TAB# if name.startswith('b_'): #LINE# #TAB# #TAB# return name.replace('b_', '') #LINE# #TAB# if name.startswith('c_'): #LINE# #TAB# #TAB# return name.replace('c_', '') #LINE# #TAB# return name"
#LINE# #TAB# if slice_obj.start is None and slice_obj.stop is None: #LINE# #TAB# #TAB# return None #LINE# #TAB# if slice_obj.start and slice_obj.stop is None: #LINE# #TAB# #TAB# return None #LINE# #TAB# if slice_obj.stop and slice_obj.start > slice_obj.stop: #LINE# #TAB# #TAB# return None #LINE# #TAB# if slice_obj.start and slice_obj.start < slice_obj.stop: #LINE# #TAB# #TAB# return None #LINE# #TAB# if slice_obj.stop and slice_obj.stop < slice_obj.start: #LINE# #TAB# #TAB# return None #LINE# #TAB# return slice_obj.stop
#LINE# #TAB# import datetime #LINE# #TAB# t1 = datetime.datetime.now() #LINE# #TAB# date = t1.strftime('%Y-%m-%d %H:%M:%S') #LINE# #TAB# return date
#LINE# #TAB# try: #LINE# #TAB# #TAB# version = pkg_resources.get_distribution(package_name).version #LINE# #TAB# #TAB# if version and ignore_cache: #LINE# #TAB# #TAB# #TAB# return None #LINE# #TAB# #TAB# return version #LINE# #TAB# except: #LINE# #TAB# #TAB# pass #LINE# #TAB# try: #LINE# #TAB# #TAB# return pkg_resources.get_distribution(package_name).version #LINE# #TAB# except: #LINE# #TAB# #TAB# return None
"#LINE# #TAB# aic = np.zeros(yk.size) #LINE# #TAB# aic[-1] = 0.0 #LINE# #TAB# for K in range(yk.size - 2, -1, -1): #LINE# #TAB# #TAB# aic[K] = aic[K + 1] + 2 * aic[K + 1] / (NF - K - 2) #LINE# #TAB# return aic"
"#LINE# #TAB# p = np.copy(normalisation_parameters) #LINE# #TAB# new_y = np.dot(y, p) #LINE# #TAB# if np.isnan(new_y): #LINE# #TAB# #TAB# new_y = np.zeros_like(y) #LINE# #TAB# else: #LINE# #TAB# #TAB# new_y = y / np.sum(new_y) #LINE# #TAB# return new_y"
"#LINE# #TAB# assert isinstance(var_instance, SymbolVAR) #LINE# #TAB# from symbols import BOUNDLIST #LINE# #TAB# from symbols import VARARRAY #LINE# #TAB# assert isinstance(bounds, BOUNDLIST) #LINE# #TAB# var_instance.__class__ = VARARRAY #LINE# #TAB# var_instance.class_ = CLASS.array #LINE# #TAB# var_instance.bounds = bounds #LINE# #TAB# return var_instance"
"#LINE# #TAB# for command in commands: #LINE# #TAB# #TAB# with open(os.devnull, 'w') as devnull: #LINE# #TAB# #TAB# #TAB# try: #LINE# #TAB# #TAB# #TAB# #TAB# output = subprocess.check_output(['cmake', command, '-s', #LINE# #TAB# #TAB# #TAB# #TAB# #TAB# cmake_with_sdist]) #LINE# #TAB# #TAB# #TAB# except subprocess.CalledProcessError: #LINE# #TAB# #TAB# #TAB# #TAB# continue #LINE# #TAB# #TAB# if output: #LINE# #TAB# #TAB# #TAB# return True #LINE# #TAB# return False"
#LINE# #TAB# n = float(n) #LINE# #TAB# Ht_est = sum(Ht_est) / float(n) #LINE# #TAB# Hs_est = sum(Hs_est) / float(n) #LINE# #TAB# if (n - 1.0) * Ht_est == 0.0: #LINE# #TAB# #TAB# return 0.0 #LINE# #TAB# Hs_est_ = sum(Hs_est) / float(n) #LINE# #TAB# d_est = (Ht_est - Hs_est_) / float(n) #LINE# #TAB# return d_est
"#LINE# #TAB# b0 = 0.903 * 2 / 3 #LINE# #TAB# b1 = 8.181 * 2 / 3 #LINE# #TAB# b2 = 0 #LINE# #TAB# Cphi = -0.0909 * 2 / 3 ** (3 / 2) #LINE# #TAB# C0 = Cphi / (2 * sqrt(np_abs(i2c['SM'] * i2c['Cl']))) #LINE# #TAB# C1 = 0 #LINE# #TAB# alph1 = 2 #LINE# #TAB# alph2 = -9 #LINE# #TAB# omega = -9 #LINE# #TAB# valid = T == 298.15 #LINE# #TAB# return b0, b1, b2, C0, C1, alph1, alph2, omega, valid"
"#LINE# #TAB# unique_labels = [] #LINE# #TAB# for i in range(1, len(labels)): #LINE# #TAB# #TAB# if labels[i] == i: #LINE# #TAB# #TAB# #TAB# unique_labels.append(i) #LINE# #TAB# return unique_labels"
"#LINE# #TAB# cwd = os.getcwd() #LINE# #TAB# files = glob.glob(ses_path + '/*') #LINE# #TAB# if not files: #LINE# #TAB# #TAB# print('No files found.') #LINE# #TAB# #TAB# return [] #LINE# #TAB# for f in files: #LINE# #TAB# #TAB# full_path = os.path.join(cwd, f) #LINE# #TAB# #TAB# if is_txt(full_path): #LINE# #TAB# #TAB# #TAB# files.append(f) #LINE# #TAB# #TAB# elif os.path.isdir(full_path): #LINE# #TAB# #TAB# #TAB# files.extend([f for f in glob.glob(full_path) if is_txt(f)]) #LINE# #TAB# #TAB# elif os.path.isfile(full_path): #LINE# #TAB# #TAB# #TAB# files.append(full_path) #LINE# #TAB# return files"
"#LINE# #TAB# psi = -0.0102 #LINE# #TAB# valid = logical_and(T >= 298.15, T <= 523.25) #LINE# #TAB# return psi, valid"
"#LINE# #TAB# config = get_default(based_on=based_on, filename=filename) #LINE# #TAB# if isinstance(config_string, dict): #LINE# #TAB# #TAB# parts = config_string.items() #LINE# #TAB# #TAB# for part in parts: #LINE# #TAB# #TAB# #TAB# if isinstance(part, dict): #LINE# #TAB# #TAB# #TAB# #TAB# key = part.keys()[0] #LINE# #TAB# #TAB# #TAB# #TAB# val = part[key] #LINE# #TAB# #TAB# #TAB# #TAB# config.set(key, val) #LINE# #TAB# return config"
"#LINE# #TAB# try: #LINE# #TAB# #TAB# next_link = grab.xpath_one('//a[contains(@class, ""b-pager__next"")]') #LINE# #TAB# except IndexError: #LINE# #TAB# #TAB# logging.debug('No results found') #LINE# #TAB# #TAB# return True #LINE# #TAB# else: #LINE# #TAB# #TAB# logging.debug('Status: %s', str(next_link)) #LINE# #TAB# #TAB# return False"
#LINE# #TAB# arr = [] #LINE# #TAB# for u in qs: #LINE# #TAB# #TAB# mean = np.mean(u) #LINE# #TAB# #TAB# arr.append(mean) #LINE# #TAB# return arr
"#LINE# #TAB# x = 0 #LINE# #TAB# y = 0 #LINE# #TAB# z = 0 #LINE# #TAB# try: #LINE# #TAB# #TAB# f = open('pixel-map.fits') #LINE# #TAB# #TAB# f.readline() #LINE# #TAB# #TAB# x = float(f.readline().split()[0]) #LINE# #TAB# #TAB# y = float(f.readline().split()[1]) #LINE# #TAB# #TAB# z = float(f.readline().split()[2]) #LINE# #TAB# finally: #LINE# #TAB# #TAB# f.close() #LINE# #TAB# return x, y, z"
"#LINE# #TAB# if data_dict.get('overriding_foo'): #LINE# #TAB# #TAB# data_dict = overriding_foo(data_dict) #LINE# #TAB# results = foo(**data_dict) #LINE# #TAB# if results.get('metadata_modified_date'): #LINE# #TAB# #TAB# metadata_modified_date = results['metadata_modified_date'] #LINE# #TAB# #TAB# limit = 10 #LINE# #TAB# #TAB# return {'result': results,'metadata_modified_date': metadata_modified_date, #LINE# #TAB# #TAB# #TAB# 'limit': limit} #LINE# #TAB# else: #LINE# #TAB# #TAB# return {'result': data_dict}"
"#LINE# #TAB# kernel = np.ones(shape, dtype=np.float64) #LINE# #TAB# for i in range(shape[-1]): #LINE# #TAB# #TAB# for j in range(shape[i]): #LINE# #TAB# #TAB# #TAB# kernel[i][j] = 1 #LINE# #TAB# return kernel"
#LINE# #TAB# d = {} #LINE# #TAB# for k in sorted(y.keys()): #LINE# #TAB# #TAB# if y[k] == 0: #LINE# #TAB# #TAB# #TAB# d[k] = 1 #LINE# #TAB# #TAB# elif y[k] == 1: #LINE# #TAB# #TAB# #TAB# d[k] = 0 #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# d[k] = 1 #LINE# #TAB# return d
"#LINE# #TAB# if root is None: #LINE# #TAB# #TAB# return None #LINE# #TAB# result = depth_first_search(graph, root) #LINE# #TAB# if result is None: #LINE# #TAB# #TAB# return [] #LINE# #TAB# import dotty #LINE# #TAB# output = dotty.tuplet(str(result)) #LINE# #TAB# print(output) #LINE# #TAB# return output"
"#LINE# #TAB# for item in filter_list: #LINE# #TAB# #TAB# if re.search(item, uri): #LINE# #TAB# #TAB# #TAB# return True #LINE# #TAB# return False"
"#LINE# #TAB# attr_value = framework.get_variable(attr_name) #LINE# #TAB# if not attr_value: #LINE# #TAB# #TAB# return None #LINE# #TAB# else: #LINE# #TAB# #TAB# var = create_parameter(attr_name, attr_value) #LINE# #TAB# #TAB# framework_var = framework.Var(var) #LINE# #TAB# #TAB# return framework_var"
"#LINE# #TAB# while True: #LINE# #TAB# #TAB# try: #LINE# #TAB# #TAB# #TAB# ret = subprocess.call(['/bin/sh', '-c', path, command], stdout= #LINE# #TAB# #TAB# #TAB# #TAB# subprocess.PIPE, stderr=subprocess.PIPE) #LINE# #TAB# #TAB# except subprocess.CalledProcessError: #LINE# #TAB# #TAB# #TAB# if ret.returncode == 0: #LINE# #TAB# #TAB# #TAB# #TAB# break #LINE# #TAB# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# #TAB# raise #LINE# #TAB# return ret"
"#LINE# #TAB# if 'data' not in data: #LINE# #TAB# #TAB# return {} #LINE# #TAB# payload = {'data': data.get('data', {})} #LINE# #TAB# if 'datetime' in data: #LINE# #TAB# #TAB# payload['datetime'] = data.get('datetime', None) #LINE# #TAB# if'metadata' in data and data.get('metadata', {}): #LINE# #TAB# #TAB# payload['metadata'] = data.get('metadata', {}) #LINE# #TAB# if 'expiration' in data and data.get('expiration'): #LINE# #TAB# #TAB# payload['expiration'] = timegm(data['expiration'].isoformat()) #LINE# #TAB# return payload"
#LINE# #TAB# if path.is_file(): #LINE# #TAB# #TAB# with path.open() as f: #LINE# #TAB# #TAB# #TAB# return json.load(f) #LINE# #TAB# return {}
"#LINE# #TAB# for x in written_files[:]: #LINE# #TAB# #TAB# with open(x, 'r') as f: #LINE# #TAB# #TAB# #TAB# f.read() #LINE# #TAB#"
"#LINE# #TAB# if isinstance(memory, str): #LINE# #TAB# #TAB# memory = YAMLDefault().set('memory', memory) #LINE# #TAB# sc = SparkSession(spark.sparkfile.name) #LINE# #TAB# conf = memory.to_configuration() #LINE# #TAB# sc.setConfiguration('memory') #LINE# #TAB# return sc"
#LINE# #TAB# ret = np.zeros_like(arr) #LINE# #TAB# ret[index] = g(arr[index]) #LINE# #TAB# return ret
"#LINE# #TAB# A = A.tocsc() #LINE# #TAB# for i in range(A.shape[0]): #LINE# #TAB# #TAB# if A.data[i, i] < 0: #LINE# #TAB# #TAB# #TAB# A.data[i, i] = 0 #LINE# #TAB# return A"
"#LINE# #TAB# for i, val in enumerate(items): #LINE# #TAB# #TAB# if val == 0: #LINE# #TAB# #TAB# #TAB# yield i #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# yield i"
"#LINE# #TAB# return {'id': obj.id, 'naam': obj.naam, 'gewest': {'id': obj.gewest.id, 'naam': obj. #LINE# #TAB# #TAB# gewest.naam}}"
#LINE# #TAB# user_policy = get_user_policy(user=user) #LINE# #TAB# if user_policy is None: #LINE# #TAB# #TAB# return ISecurityPolicy() #LINE# #TAB# return user_policy
#LINE# #TAB# x = 0 #LINE# #TAB# y = 0 #LINE# #TAB# if byteData!= []: #LINE# #TAB# #TAB# for i in range(len(byteData) // 2): #LINE# #TAB# #TAB# #TAB# x += byteData[i * 2 + 1] << 8 * (8 - i) #LINE# #TAB# #TAB# y += byteData[i * 2 + 1] #LINE# #TAB# return x
#LINE# #TAB# n_sig = params[0] #LINE# #TAB# n_bkg = params[1] #LINE# #TAB# alpha = n_bkg * n_sig #LINE# #TAB# s = signal_2d.dot(alpha) #LINE# #TAB# b = background_2d.dot(alpha) #LINE# #TAB# sumlogl = np.sum(np.log(n_bkg * s + b ** 2)) #LINE# #TAB# sumlogl -= n_sig #LINE# #TAB# sumlogl -= np.sum(np.log(n_bkg * b / n_sig)) #LINE# #TAB# return -sumlogl
#LINE# #TAB# try: #LINE# #TAB# #TAB# data = get_flow_file(flow_name) #LINE# #TAB# #TAB# if data and os.path.isfile(data): #LINE# #TAB# #TAB# #TAB# return data #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# return False #LINE# #TAB# except Exception: #LINE# #TAB# #TAB# return False
#LINE# #TAB# if model.description!= '': #LINE# #TAB# #TAB# model.description += '\n' #LINE# #TAB# sbo = '' #LINE# #TAB# if model.objective_type == 'C': #LINE# #TAB# #TAB# sbo +='sbo-c' #LINE# #TAB# if model.objective_type == 'D': #LINE# #TAB# #TAB# sbo +='sbo-d' #LINE# #TAB# if model.objective_type == 'E': #LINE# #TAB# #TAB# sbo +='sbo-e' #LINE# #TAB# return sbo
"#LINE# #TAB# xy = extent[:2] #LINE# #TAB# dy = extent[2:] #LINE# #TAB# dx = float(extent[0]) #LINE# #TAB# dy = float(extent[3]) #LINE# #TAB# if dx > dy: #LINE# #TAB# #TAB# dx = dy #LINE# #TAB# if dy < dx: #LINE# #TAB# #TAB# dy = dx #LINE# #TAB# dx = int(dx) #LINE# #TAB# dy = int(dy) #LINE# #TAB# return dx, dy, dx, dy"
"#LINE# #TAB# module_scope_name = ast.literal_eval(module_scope) #LINE# #TAB# model_scope_name = ast.literal_eval(model_name) #LINE# #TAB# return module_scope_name, model_scope_name"
"#LINE# #TAB# if nparray > 25: #LINE# #TAB# #TAB# return np.c_[np.array([255, 255, 255], dtype=np.uint8)[:, :, :3] #LINE# #TAB# elif nparray == 1: #LINE# #TAB# #TAB# return np.array([255, 255, 255]) #LINE# #TAB# else: #LINE# #TAB# #TAB# return np.c_[np.array([255, 255, 255], dtype=np.uint8), np.array([255, 255, #LINE# #TAB# #TAB# #TAB# 255], dtype=np.uint8)[:, :3]"
"#LINE# #TAB# t = time.strftime('%Y-%m-%d %H:%M:%S', time.gmtime(epoch_time)) #LINE# #TAB# return t"
"#LINE# #TAB# if not os.path.isdir(custom_directory): #LINE# #TAB# #TAB# return None #LINE# #TAB# directory_foo = os.path.join(custom_directory, 'dataset.foo') #LINE# #TAB# if os.path.isfile(directory_foo): #LINE# #TAB# #TAB# with open(directory_foo, 'x') as f: #LINE# #TAB# #TAB# #TAB# return f.read() #LINE# #TAB# else: #LINE# #TAB# #TAB# return None"
"#LINE# #TAB# if target.is_architecture: #LINE# #TAB# #TAB# for ext in ['x86_64', 'amd64']: #LINE# #TAB# #TAB# #TAB# if target.GetModuleFileName(ext.GetFileName()) == ext: #LINE# #TAB# #TAB# #TAB# #TAB# return ext.GetName() #LINE# #TAB# return None"
#LINE# #TAB# if ordchr in string.printable: #LINE# #TAB# #TAB# return ordchr #LINE# #TAB# else: #LINE# #TAB# #TAB# return '.'
#LINE# #TAB# try: #LINE# #TAB# #TAB# return root[name] #LINE# #TAB# except KeyError: #LINE# #TAB# #TAB# return None
"#LINE# #TAB# res = np.zeros(vec1.shape, dtype=float) #LINE# #TAB# res[0] = vec1[0] / np.linalg.norm(vec1[0]) #LINE# #TAB# res[1] = vec1[1] / np.linalg.norm(vec1[2]) #LINE# #TAB# return res"
#LINE# #TAB# import msvcrt #LINE# #TAB# try: #LINE# #TAB# #TAB# i = int(number) #LINE# #TAB# #TAB# return msvcrt.GetMIDIOutputName(i) #LINE# #TAB# except ValueError: #LINE# #TAB# #TAB# return 'unknown'
#LINE# #TAB# name = inflection.camelize(name) #LINE# #TAB# name = inflection.camelize(name) #LINE# #TAB# name = inflection.camelize(name) #LINE# #TAB# return name
"#LINE# #TAB# df = pd.read_csv(filename, sep='\t') #LINE# #TAB# if isdatetime: #LINE# #TAB# #TAB# df = df.dt.to_datetime() #LINE# #TAB# return df"
"#LINE# #TAB# _control = control #LINE# #TAB# for handler in _control_handlers: #LINE# #TAB# #TAB# try: #LINE# #TAB# #TAB# #TAB# if isinstance(handler, foo): #LINE# #TAB# #TAB# #TAB# #TAB# return True #LINE# #TAB# #TAB# except TypeError: #LINE# #TAB# #TAB# #TAB# return False #LINE# #TAB# return False"
#LINE# #TAB# function_name = function_name + '(' #LINE# #TAB# for arg in argument_list: #LINE# #TAB# #TAB# function_name = function_name + '(' + str(arg) + ')' #LINE# #TAB# return function_name
"#LINE# #TAB# import subprocess #LINE# #TAB# process = subprocess.Popen(command, shell=True, stdin=subprocess.PIPE, #LINE# #TAB# #TAB# stdout=subprocess.PIPE, stderr=subprocess.PIPE) #LINE# #TAB# output, error = process.communicate() #LINE# #TAB# if process.returncode!= 0: #LINE# #TAB# #TAB# error = str(error) #LINE# #TAB# return error"
#LINE# #TAB# return [field for field in from_table.primary_key if field.related and field. #LINE# #TAB# #TAB# to_table == to_table]
#LINE# #TAB# if a == b: #LINE# #TAB# #TAB# return 0 #LINE# #TAB# elif a > b: #LINE# #TAB# #TAB# return 1 #LINE# #TAB# return -1
"#LINE# #TAB# RQ = getattr(settings, 'RQ', {}) #LINE# #TAB# if job_class is None: #LINE# #TAB# #TAB# job_class = Job #LINE# #TAB# if isinstance(job_class, str): #LINE# #TAB# #TAB# job_class = import_module(job_class) #LINE# #TAB# return job_class"
#LINE# #TAB# country = request.country_code() #LINE# #TAB# if country == 'US': #LINE# #TAB# #TAB# return 'US' #LINE# #TAB# elif country == 'US': #LINE# #TAB# #TAB# return 'US' #LINE# #TAB# else: #LINE# #TAB# #TAB# return 'US'
#LINE# #TAB# home = os.path.expanduser('~') + '/.gridcal/' #LINE# #TAB# if not os.path.exists(home): #LINE# #TAB# #TAB# os.mkdir(home) #LINE# #TAB# return home
#LINE# #TAB# if path.endswith('.yaml'): #LINE# #TAB# #TAB# with open(path) as f: #LINE# #TAB# #TAB# #TAB# yaml = yaml.safe_load(f) #LINE# #TAB# elif path.endswith('.json'): #LINE# #TAB# #TAB# with open(path) as f: #LINE# #TAB# #TAB# #TAB# json = json.safe_load(f) #LINE# #TAB# else: #LINE# #TAB# #TAB# raise ValueError('Cannot parse {}'.format(path)) #LINE# #TAB# return yaml
"#LINE# #TAB# #TAB# try: #LINE# #TAB# #TAB# #TAB# response = request.json_body #LINE# #TAB# #TAB# except ValueError: #LINE# #TAB# #TAB# #TAB# raise exc.InvalidRequest( #LINE# #TAB# #TAB# #TAB# #TAB# 'Invalid request body') #LINE# #TAB# #TAB# if 400 <= response.status_code < 500: #LINE# #TAB# #TAB# #TAB# raise exc.InvalidRequest( #LINE# #TAB# #TAB# #TAB# #TAB# 'Invalid response code: %d - %d' % (response.status_code, #LINE# #TAB# #TAB# #TAB# #TAB# response.reason)) #LINE# #TAB# #TAB# return True #LINE# #TAB# #TAB# return False"
"#LINE# #TAB# print('Loading Matlab data from %s' % filename) #LINE# #TAB# d = {} #LINE# #TAB# with open(filename, 'rb') as f: #LINE# #TAB# #TAB# for line in f: #LINE# #TAB# #TAB# #TAB# try: #LINE# #TAB# #TAB# #TAB# #TAB# d[line[0]] = line[1] #LINE# #TAB# #TAB# #TAB# except IndexError: #LINE# #TAB# #TAB# #TAB# #TAB# pass #LINE# #TAB# return d"
"#LINE# #TAB# if not row[0].isdigit(): #LINE# #TAB# #TAB# return row[0] #LINE# #TAB# r = row[1].isdigit() #LINE# #TAB# if r.isdigit(): #LINE# #TAB# #TAB# return '-'.join([x.replace(' ', '_') for x in row[2:]]) #LINE# #TAB# else: #LINE# #TAB# #TAB# return row[0]"
"#LINE# #TAB# cwd = os.getcwd() #LINE# #TAB# try: #LINE# #TAB# #TAB# f = os.path.join(cwd, 'logs') #LINE# #TAB# #TAB# os.makedirs(f, exist_ok=True) #LINE# #TAB# except OSError: #LINE# #TAB# #TAB# pass #LINE# #TAB# return cwd"
"#LINE# #TAB# with open(path, 'r') as f: #LINE# #TAB# #TAB# info_dict = cih.cih_info(f) #LINE# #TAB# return info_dict"
#LINE# #TAB# dolphin = Dolphin() #LINE# #TAB# data = dolphin.search(label=label) #LINE# #TAB# if data: #LINE# #TAB# #TAB# return data[0] #LINE# #TAB# else: #LINE# #TAB# #TAB# return []
#LINE# #TAB# try: #LINE# #TAB# #TAB# return foo(library_name) #LINE# #TAB# except Exception: #LINE# #TAB# #TAB# return False
#LINE# #TAB# if type_ == str: #LINE# #TAB# #TAB# return str(value) #LINE# #TAB# if type_ == int: #LINE# #TAB# #TAB# return int(value) #LINE# #TAB# if type_ == bool: #LINE# #TAB# #TAB# return bool(value) #LINE# #TAB# if type_ == int: #LINE# #TAB# #TAB# return int(value) #LINE# #TAB# if type_ == float: #LINE# #TAB# #TAB# return float(value) #LINE# #TAB# if type_ == bool: #LINE# #TAB# #TAB# return bool(value) #LINE# #TAB# return value
"#LINE# #TAB# text = text.rstrip('\n') #LINE# #TAB# try: #LINE# #TAB# #TAB# with open(text, 'r') as f: #LINE# #TAB# #TAB# #TAB# return yaml.safe_load(f.read()) #LINE# #TAB# except IOError: #LINE# #TAB# #TAB# pass #LINE# #TAB# try: #LINE# #TAB# #TAB# with open(text, 'r') as f: #LINE# #TAB# #TAB# #TAB# return yaml.safe_load(f.read()) #LINE# #TAB# except IOError: #LINE# #TAB# #TAB# pass"
"#LINE# #TAB# with open(""temp.yml"", ""r"") as f: #LINE# #TAB# #TAB# for a in augs: #LINE# #TAB# #TAB# #TAB# if a[""filename""] in f.read(): #LINE# #TAB# #TAB# #TAB# #TAB# return True #LINE# #TAB# return False"
#LINE# #TAB# _db = load_db() #LINE# #TAB# for row in _db.iterrows(): #LINE# #TAB# #TAB# for word in row[0]: #LINE# #TAB# #TAB# #TAB# if term.lower() == word.lower(): #LINE# #TAB# #TAB# #TAB# #TAB# return word #LINE# #TAB# return ''
#LINE# #TAB# msg = mlog.recv_match(source) #LINE# #TAB# if msg: #LINE# #TAB# #TAB# attr = msg[0].lower() #LINE# #TAB# #TAB# if attr.startswith('apm:'): #LINE# #TAB# #TAB# #TAB# return 'apm' #LINE# #TAB# #TAB# elif attr.startswith('px4:'): #LINE# #TAB# #TAB# #TAB# return 'px4' #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# return '' #LINE# #TAB# else: #LINE# #TAB# #TAB# return 'unknown'
"#LINE# #TAB# import redis #LINE# #TAB# conn = redis.StrictRedis(host=REDIS_HOST, port=REDIS_PORT) #LINE# #TAB# return conn"
#LINE# #TAB# if cls.__from_class__: #LINE# #TAB# #TAB# cls = cls.__from_class__ #LINE# #TAB# return cls.__table__.primary_key.columns.values()[0].name
"#LINE# #TAB# mn = foo(minval) #LINE# #TAB# mx = foo(maxval) #LINE# #TAB# return mn, mx"
#LINE# #TAB# scale = 1.0 / ntaps #LINE# #TAB# if window == 'hanning': #LINE# #TAB# #TAB# t = np.arange(ntaps) #LINE# #TAB# elif window == 'hanning': #LINE# #TAB# #TAB# t = np.arange(ntaps) + 1 #LINE# #TAB# else: #LINE# #TAB# #TAB# t = np.arange(ntaps) + 1 #LINE# #TAB# return impulse[t * scale:(t + 1) * scale + window]
#LINE# #TAB# if options.count == 0: #LINE# #TAB# #TAB# return True #LINE# #TAB# else: #LINE# #TAB# #TAB# return False
"#LINE# #TAB# with term.oneliners: #LINE# #TAB# #TAB# for item in term.recent_oneliners: #LINE# #TAB# #TAB# #TAB# if item.margin <= top_margin: #LINE# #TAB# #TAB# #TAB# #TAB# item.margin = top_margin #LINE# #TAB# #TAB# #TAB# if item.adj: #LINE# #TAB# #TAB# #TAB# #TAB# item.adj = offset + term.margin #LINE# #TAB# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# #TAB# item.adj = offset + term.margin #LINE# #TAB# #TAB# return term.margin - offset, item.adj"
"#LINE# #TAB# if isinstance(obs_dict, dict): #LINE# #TAB# #TAB# return obs_dict.values() #LINE# #TAB# else: #LINE# #TAB# #TAB# return obs_dict"
"#LINE# #TAB# decorators = get_annotations(func) #LINE# #TAB# result: Dict[str, Tuple[Callable]] = {} #LINE# #TAB# for k, v in decorators.items(): #LINE# #TAB# #TAB# try: #LINE# #TAB# #TAB# #TAB# result[k] = v() #LINE# #TAB# #TAB# except TypeError: #LINE# #TAB# #TAB# #TAB# pass #LINE# #TAB# return result"
#LINE# #TAB# conf = copy.deepcopy(conf) #LINE# #TAB# if'repos' not in conf: #LINE# #TAB# #TAB# conf['repos'] = [repository] #LINE# #TAB# for repo in target['repos']: #LINE# #TAB# #TAB# if repo!= project: #LINE# #TAB# #TAB# #TAB# conf['repos'][repo] = {} #LINE# #TAB# #TAB# conf['repos'][project][repo] = target['repos'][project][repo]
"#LINE# #TAB# local_states = basis.n_states #LINE# #TAB# res = [] #LINE# #TAB# for i, rel in enumerate(correlations): #LINE# #TAB# #TAB# if rel in local_states: #LINE# #TAB# #TAB# #TAB# res.append(i) #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# local_states.append(i) #LINE# #TAB# return res"
#LINE# #TAB# res = [] #LINE# #TAB# for msg in msgs: #LINE# #TAB# #TAB# if len(msg) > max_len: #LINE# #TAB# #TAB# #TAB# if len(res) > max_len - 3: #LINE# #TAB# #TAB# #TAB# #TAB# return res #LINE# #TAB# #TAB# #TAB# res.append(msg) #LINE# #TAB# return res
"#LINE# #TAB# data = [] #LINE# #TAB# with open(filepath, 'r') as f: #LINE# #TAB# #TAB# first = f.readline() #LINE# #TAB# #TAB# for line in f: #LINE# #TAB# #TAB# #TAB# if first == '#': #LINE# #TAB# #TAB# #TAB# #TAB# data.append(float(first)) #LINE# #TAB# #TAB# #TAB# elif line == '\n': #LINE# #TAB# #TAB# #TAB# #TAB# pass #LINE# #TAB# return data"
"#LINE# #TAB# try: #LINE# #TAB# #TAB# date = parse(string) #LINE# #TAB# except ValueError: #LINE# #TAB# #TAB# return string #LINE# #TAB# if fmt is None: #LINE# #TAB# #TAB# fmt = '%Y-%m-%dT%H:%M:%S' #LINE# #TAB# date = timezone.localtime(date) #LINE# #TAB# if fmt =='str': #LINE# #TAB# #TAB# return date.strftime(fmt) #LINE# #TAB# elif fmt == 'datetime': #LINE# #TAB# #TAB# return datetime.strftime(date, '%Y-%m-%dT%H:%M:%S') #LINE# #TAB# return date"
"#LINE# #TAB# bytes = bytearray() #LINE# #TAB# for key, value in ctx.items(): #LINE# #TAB# #TAB# if key =='sha256': #LINE# #TAB# #TAB# #TAB# bytes += _sha256_to_bytes(value) #LINE# #TAB# #TAB# elif key =='sha384': #LINE# #TAB# #TAB# #TAB# bytes += _sha384_to_bytes(value) #LINE# #TAB# #TAB# elif key =='sha512': #LINE# #TAB# #TAB# #TAB# bytes += _sha512_to_bytes(value) #LINE# #TAB# return bytes"
"#LINE# #TAB# config = configparser.ConfigParser() #LINE# #TAB# config.read(os.path.join(rootdir, 'authfile')) #LINE# #TAB# rootdir = os.path.abspath(rootdir) #LINE# #TAB# if not os.path.exists(authfile): #LINE# #TAB# #TAB# logging.error('The authfile %s does not exist' % authfile) #LINE# #TAB# #TAB# return 1 #LINE# #TAB# logging.basicConfig(level=logging.INFO, format='%(message)s') #LINE# #TAB# f = open(authfile, 'r') #LINE# #TAB# token = f.readline().strip() #LINE# #TAB# try: #LINE# #TAB# #TAB# f.write(token) #LINE# #TAB# except IOError: #LINE# #TAB# #TAB# logging.error('Error while reading %s: %s' % (authfile, token)) #LINE# #TAB# #TAB# return 1 #LINE# #TAB# return 0"
"#LINE# #TAB# nake_type = remove_alias(type_) #LINE# #TAB# if isinstance(nake_type, cpptypes.volatile_t): #LINE# #TAB# #TAB# return True #LINE# #TAB# elif isinstance(nake_type, cpptypes.pointer_t): #LINE# #TAB# #TAB# return True #LINE# #TAB# elif isinstance(nake_type, cpptypes.pointer_t): #LINE# #TAB# #TAB# return True #LINE# #TAB# elif isinstance(nake_type, cpptypes.const_t): #LINE# #TAB# #TAB# return True #LINE# #TAB# return False"
"#LINE# #TAB# try: #LINE# #TAB# #TAB# return grp.replace('\\', '.') #LINE# #TAB# except ValueError: #LINE# #TAB# #TAB# return grp"
"#LINE# #TAB# url = '{}/api/v1/schools/{}/class_device/{}/'.format(API_BASE, school_id, sn) #LINE# #TAB# resp = do_get_request(url) #LINE# #TAB# code = resp.code #LINE# #TAB# data = resp.data.get('data', {}) if not code else resp.msg #LINE# #TAB# if code: #LINE# #TAB# #TAB# logger.error('Error: Request: {}, Detail: {}'.format(url, data)) #LINE# #TAB# return code, data"
"#LINE# #TAB# meta = getattr(instance, '_meta', None) #LINE# #TAB# if meta: #LINE# #TAB# #TAB# return [f for f in meta.get_fields() if f!= instance] #LINE# #TAB# return []"
"#LINE# #TAB# with open(""version.py"") as fp: #LINE# #TAB# #TAB# try: #LINE# #TAB# #TAB# #TAB# f = fp.read() #LINE# #TAB# #TAB# #TAB# return dict( #LINE# #TAB# #TAB# #TAB# #TAB# (int(f.split(""."")[-1]), #LINE# #TAB# #TAB# #TAB# #TAB# float(f.split(""."")[-2]), #LINE# #TAB# #TAB# #TAB# #TAB# int(f.split(""."")[-3]), #LINE# #TAB# #TAB# #TAB# ) #LINE# #TAB# #TAB# #TAB# ) #LINE# #TAB# #TAB# except IOError: #LINE# #TAB# #TAB# #TAB# return None"
"#LINE# #TAB# for k, v in results.items(): #LINE# #TAB# #TAB# if 'headers' in k: #LINE# #TAB# #TAB# #TAB# yield k, v #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# for line in v: #LINE# #TAB# #TAB# #TAB# #TAB# yield line"
"#LINE# #TAB# index = concept_cd.find(join_char) #LINE# #TAB# if index == -1: #LINE# #TAB# #TAB# category_cd = concept_cd #LINE# #TAB# #TAB# data_label = None #LINE# #TAB# else: #LINE# #TAB# #TAB# category_cd = concept_cd[:index] #LINE# #TAB# #TAB# data_label = concept_cd[index + 1:].strip() #LINE# #TAB# return category_cd, data_label"
"#LINE# #TAB# if not signature: #LINE# #TAB# #TAB# raise ValueError('Invalid signature') #LINE# #TAB# sha1 = get_rsa_key(key) #LINE# #TAB# try: #LINE# #TAB# #TAB# el = etree.fromstring(xml) #LINE# #TAB# #TAB# sig = get_signature(el, sha1, c14n_exc=c14n_exc) #LINE# #TAB# #TAB# if sig == sha1: #LINE# #TAB# #TAB# #TAB# return True #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# return False #LINE# #TAB# except Exception as e: #LINE# #TAB# #TAB# logger.debug('Exception: %s' % e) #LINE# #TAB# #TAB# return False"
#LINE# #TAB# import numpy as np #LINE# #TAB# if shape == 'gaus': #LINE# #TAB# #TAB# sigma = sigma * 1.5 #LINE# #TAB# elif shape =='mcc': #LINE# #TAB# #TAB# sigma = sigma * 0.5 #LINE# #TAB# return sigma
#LINE# #TAB# if len(name) > 20: #LINE# #TAB# #TAB# name = name[:20] + '...' #LINE# #TAB# return name
"#LINE# #TAB# if hr_data is None: #LINE# #TAB# #TAB# return None #LINE# #TAB# if not os.path.exists(filename): #LINE# #TAB# #TAB# os.makedirs(filename) #LINE# #TAB# with open(filename, 'w') as f: #LINE# #TAB# #TAB# for line in hr_data: #LINE# #TAB# #TAB# #TAB# f.write(line[0] + '\n') #LINE# #TAB# #TAB# f.write('\n') #LINE# #TAB# return filename"
"#LINE# #TAB# with open(path, 'rb') as f: #LINE# #TAB# #TAB# block_size = 65536 #LINE# #TAB# #TAB# while True: #LINE# #TAB# #TAB# #TAB# data = f.read(block_size) #LINE# #TAB# #TAB# #TAB# if not data: #LINE# #TAB# #TAB# #TAB# #TAB# break #LINE# #TAB# #TAB# #TAB# f.seek(0, block_size) #LINE# #TAB# #TAB# #TAB# block_hash = hashlib.sha512(data).hexdigest() #LINE# #TAB# #TAB# #TAB# f.write(block_hash) #LINE# #TAB# #TAB# #TAB# if size < block_size: #LINE# #TAB# #TAB# #TAB# #TAB# break"
"#LINE# #TAB# if not config_dir: #LINE# #TAB# #TAB# config_dir = DEFAULT_CONFIG_DIR #LINE# #TAB# try: #LINE# #TAB# #TAB# if os.path.isdir(config_dir): #LINE# #TAB# #TAB# #TAB# config_file = os.path.join(config_dir, DEFAULT_CONFIG_FILE) #LINE# #TAB# #TAB# #TAB# if os.path.isfile(config_file): #LINE# #TAB# #TAB# #TAB# #TAB# return open(config_file, 'r') #LINE# #TAB# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# #TAB# raise FileNotFoundError #LINE# #TAB# except Exception: #LINE# #TAB# #TAB# pass #LINE# #TAB# return DEFAULT_CONFIG"
"#LINE# #TAB# if isinstance(params, str): #LINE# #TAB# #TAB# params = tokenize(params) #LINE# #TAB# #TAB# params = normalize(params) #LINE# #TAB# return params"
#LINE# #TAB# return [tag for tag in node.iter() if tag.tag!= 'SL'] + [tag for #LINE# #TAB# #TAB# tag in node.iter() if tag.tag!= 'SL']
"#LINE# #TAB# for directory in os.listdir(os.getcwd()): #LINE# #TAB# #TAB# if os.path.isdir(os.path.join(directory, '__init__.py')): #LINE# #TAB# #TAB# #TAB# yield directory"
"#LINE# #TAB# url = BASE_URL.format(account=account, order_url=order_url) #LINE# #TAB# data = requests.get(url) #LINE# #TAB# if data.status_code == 200: #LINE# #TAB# #TAB# return data.json() #LINE# #TAB# else: #LINE# #TAB# #TAB# print('ERROR: URL does not exist') #LINE# #TAB# #TAB# return False"
#LINE# #TAB# with _notifications_lock: #LINE# #TAB# #TAB# notifications = Notification.objects.all() #LINE# #TAB# #TAB# for notification in notifications: #LINE# #TAB# #TAB# #TAB# notification.type = NotificationTypes.foo
#LINE# #TAB# #TAB# try: #LINE# #TAB# #TAB# #TAB# qry_id = int(id) #LINE# #TAB# #TAB# except Exception: #LINE# #TAB# #TAB# #TAB# qry_id = None #LINE# #TAB# #TAB# if not qry_id: #LINE# #TAB# #TAB# #TAB# msg = 'unknown identifier %s' % id #LINE# #TAB# #TAB# #TAB# cls.error(msg) #LINE# #TAB# #TAB# return qry_id
#LINE# #TAB# import imp #LINE# #TAB# try: #LINE# #TAB# #TAB# imp.find_module('ipython') #LINE# #TAB# #TAB# return True #LINE# #TAB# except Exception: #LINE# #TAB# #TAB# return False
"#LINE# #TAB# resource_uri = resource_uri.replace('/', '%2F') #LINE# #TAB# resource_uri = resource_uri.replace('?', '') #LINE# #TAB# return resource_uri"
"#LINE# #TAB# try: #LINE# #TAB# #TAB# with open('/etc/dwilib', 'r') as f: #LINE# #TAB# #TAB# #TAB# f.read() #LINE# #TAB# #TAB# #TAB# f.write('') #LINE# #TAB# except OSError: #LINE# #TAB# #TAB# print('Could not open /etc/dwilib.r') #LINE# #TAB# #TAB# sys.exit(1) #LINE# #TAB# except: #LINE# #TAB# #TAB# print('Could not open /etc/dwilib.r') #LINE# #TAB# #TAB# sys.exit(1) #LINE# #TAB# return 0"
"#LINE# #TAB# covariance_matrix = np.zeros((points.shape[0], points.shape[1])) #LINE# #TAB# for i in range(points.shape[0]): #LINE# #TAB# #TAB# for j in range(points.shape[1]): #LINE# #TAB# #TAB# #TAB# covariance_matrix[i, j] = foo(points[i, j]) #LINE# #TAB# return covariance_matrix"
#LINE# #TAB# if dirpath is None: #LINE# #TAB# #TAB# return False #LINE# #TAB# if not os.path.isdir(dirpath): #LINE# #TAB# #TAB# return False #LINE# #TAB# else: #LINE# #TAB# #TAB# return True
"#LINE# #TAB# before = np.mean(A[permutation]) #LINE# #TAB# after = np.mean(A[permutation]) #LINE# #TAB# return {'before': before, 'after': after}"
"#LINE# #TAB# result = {'year': date.strftime('%Y'),'month': date.strftime('%m'), #LINE# #TAB# #TAB# 'day': date.strftime('%d'), 'hour': date.strftime('%H'),'minute': #LINE# #TAB# #TAB# date.strftime('%M'),'second': date.strftime('%S')} #LINE# #TAB# return result"
"#LINE# #TAB# with open(fastq, 'rb') as f: #LINE# #TAB# #TAB# pickle.dump(f, f, pickle.HIGHEST_PROTOCOL) #LINE# #TAB# return"
"#LINE# #TAB# if hasattr(filename, 'decode'): #LINE# #TAB# #TAB# filename = filename.decode() #LINE# #TAB# parts = filename.split('.') #LINE# #TAB# if len(parts) >= 3: #LINE# #TAB# #TAB# if parts[1] == 'command': #LINE# #TAB# #TAB# #TAB# return parts[2] #LINE# #TAB# #TAB# elif parts[1] == 'dir': #LINE# #TAB# #TAB# #TAB# return parts[0] #LINE# #TAB# return default"
#LINE# #TAB# if ':' not in val: #LINE# #TAB# #TAB# return val #LINE# #TAB# params = val.split(':') #LINE# #TAB# res = {} #LINE# #TAB# for p in params: #LINE# #TAB# #TAB# if p.isdigit(): #LINE# #TAB# #TAB# #TAB# res[p[0]] = int(p[1:]) #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# res[p[0]] = p[1:-1] #LINE# #TAB# return res
"#LINE# #TAB# return {'foo': {'url': '%s://%s%s' % (current_app.config.get( #LINE# #TAB# #TAB# 'DJANGO_URL'), current_app.config.get('DJANGO_HOST_URL'), 'url': #LINE# #TAB# #TAB# '%s://%s%s' % (current_app.config.get('DJANGO_URL'), current_app. #LINE# #TAB# #TAB# config.get('DJANGO_PREFIX'), current_app.config.get('DJANGO_USER'), current_app #LINE# #TAB# #TAB#.get('DJANGO_SECRET'), current_app.config.get('DJANGO_URL'))}}"
"#LINE# #TAB# results = [] #LINE# #TAB# for f in files: #LINE# #TAB# #TAB# if f.endswith("".py""): #LINE# #TAB# #TAB# #TAB# results.append(f[:-3]) #LINE# #TAB# return results"
#LINE# #TAB# if description is None: #LINE# #TAB# #TAB# return None #LINE# #TAB# if not description.startswith('.'): #LINE# #TAB# #TAB# return description #LINE# #TAB# if not description.endswith('.'): #LINE# #TAB# #TAB# return description #LINE# #TAB# return description + '.'
#LINE# #TAB# for ws in nb.worksheets: #LINE# #TAB# #TAB# for cell in ws.cells: #LINE# #TAB# #TAB# #TAB# if cell.cell_type == 'code': #LINE# #TAB# #TAB# #TAB# #TAB# cell.outputs = []
#LINE# #TAB# try: #LINE# #TAB# #TAB# return s.decode('ascii') #LINE# #TAB# except UnicodeDecodeError: #LINE# #TAB# #TAB# return s
#LINE# #TAB# orig = os.environ.get(key) #LINE# #TAB# try: #LINE# #TAB# #TAB# yield #LINE# #TAB# finally: #LINE# #TAB# #TAB# os.environ[key] = orig
"#LINE# #TAB# #TAB# if sys.version_info >= (3, 5): #LINE# #TAB# #TAB# #TAB# return child_class #LINE# #TAB# #TAB# if not issubclass(child_class, this_abc): #LINE# #TAB# #TAB# #TAB# raise KappaError('Cannot fix docs of class that is not decendent.') #LINE# #TAB# #TAB# for name in dir(child_class): #LINE# #TAB# #TAB# #TAB# if name.startswith('_'): #LINE# #TAB# #TAB# #TAB# #TAB# continue #LINE# #TAB# #TAB# #TAB# if name in this_abc.__abstractmethods__: #LINE# #TAB# #TAB# #TAB# #TAB# continue #LINE# #TAB# #TAB# #TAB# child_func = getattr(this_abc, name) #LINE# #TAB# #TAB# #TAB# child_func.__doc__ = child_func.__doc__ #LINE# #TAB# #TAB# return child_class"
#LINE# #TAB# for d in dir_list: #LINE# #TAB# #TAB# if preprocess and d in DIR_STRS: #LINE# #TAB# #TAB# #TAB# yield d
#LINE# #TAB# try: #LINE# #TAB# #TAB# logging.basicConfig(level=logging.INFO) #LINE# #TAB# except ValueError: #LINE# #TAB# #TAB# logging.basicConfig(level=logging.WARNING) #LINE# #TAB# return
"#LINE# #TAB# models = {} #LINE# #TAB# for model_data in references_json['graph'].values(): #LINE# #TAB# #TAB# for model in model_data['nodes']: #LINE# #TAB# #TAB# #TAB# app_models = [] #LINE# #TAB# #TAB# #TAB# for ref in model_data['refs']: #LINE# #TAB# #TAB# #TAB# #TAB# ref = ref['attributes'] #LINE# #TAB# #TAB# #TAB# #TAB# app_models.append(Foo(ref, ref)) #LINE# #TAB# #TAB# #TAB# models[model] = app_models #LINE# #TAB# return models"
#LINE# #TAB# ctx = cls._current_ctx #LINE# #TAB# if not ctx: #LINE# #TAB# #TAB# raise ContextIsNotInitializedError #LINE# #TAB# return ctx
#LINE# #TAB# assert scheme in scheme_list #LINE# #TAB# ret = [] #LINE# #TAB# for i in range(num): #LINE# #TAB# #TAB# ret.append(scheme_list[i]) #LINE# #TAB# return ret
#LINE# #TAB# import time #LINE# #TAB# while True: #LINE# #TAB# #TAB# if time.time() > stop: #LINE# #TAB# #TAB# #TAB# return
"#LINE# #TAB# opts = 't' #LINE# #TAB# if verbosity > 1: #LINE# #TAB# #TAB# opts += 'v' #LINE# #TAB# return [cmd, opts, archive]"
"#LINE# #TAB# a = np.array(connections[:1]) #LINE# #TAB# b = np.array(connections[1:]) #LINE# #TAB# c = np.concatenate((a, b)) #LINE# #TAB# c = c.sort() #LINE# #TAB# return a, b"
"#LINE# #TAB# links = np.empty(shape, dtype=int) #LINE# #TAB# links.fill(0) #LINE# #TAB# for i in range(len(shape)): #LINE# #TAB# #TAB# if node_status is None: #LINE# #TAB# #TAB# #TAB# continue #LINE# #TAB# #TAB# links[i] = 1 #LINE# #TAB# if return_count: #LINE# #TAB# #TAB# return links, node_status #LINE# #TAB# else: #LINE# #TAB# #TAB# return links"
"#LINE# #TAB# for name in path: #LINE# #TAB# #TAB# node = tdict #LINE# #TAB# #TAB# name = name.split('.')[-1] #LINE# #TAB# #TAB# if name not in tdict: #LINE# #TAB# #TAB# #TAB# tdict[name] = Node(name) #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# f = getattr(node, name) #LINE# #TAB# #TAB# #TAB# if f is not None: #LINE# #TAB# #TAB# #TAB# #TAB# foo(tdict[name], [f]) #LINE# #TAB# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# #TAB# tdict[name] = Node(name, {}) #LINE# #TAB# return tdict"
"#LINE# #TAB# if engine.dialect.has_option('mysql', 'innodb_large_prefix'): #LINE# #TAB# #TAB# return True #LINE# #TAB# else: #LINE# #TAB# #TAB# return False"
#LINE# #TAB# c = _cache.get(id) #LINE# #TAB# if c is None: #LINE# #TAB# #TAB# c = Cachet() #LINE# #TAB# #TAB# _cache[id] = c #LINE# #TAB# return c
"#LINE# #TAB# if x.shape[0] == x.shape[1]: #LINE# #TAB# #TAB# return np.sum(x, axis=0) == 1 #LINE# #TAB# else: #LINE# #TAB# #TAB# return x"
#LINE# #TAB# if dt.tzinfo is not None and dt.tzinfo.utcoffset(dt) > timedelta(0): #LINE# #TAB# #TAB# logging.warning('Warning: aware datetimes are interpreted as if they were naive') #LINE# #TAB# return dt.strftime('%Y-%m-%dT%H:%M:%S.%f')[:-3] + 'Z'
"#LINE# #TAB# out = np.zeros((w, h)) #LINE# #TAB# out[0, 0] = x #LINE# #TAB# out[1, 1] = y #LINE# #TAB# for i in range(int(pagesize / 2)): #LINE# #TAB# #TAB# out[i, 0] = x + i * pagesize - 1 #LINE# #TAB# #TAB# out[i, 1] = y + i * pagesize - 1 #LINE# #TAB# return out"
#LINE# #TAB# for line in data['out'].splitlines(): #LINE# #TAB# #TAB# line = line.strip() #LINE# #TAB# #TAB# if not line or line[0] == '#': #LINE# #TAB# #TAB# #TAB# continue #LINE# #TAB# #TAB# parts = line.split() #LINE# #TAB# #TAB# if len(parts) < 3: #LINE# #TAB# #TAB# #TAB# func = parts[0] #LINE# #TAB# #TAB# #TAB# yield func(parts) #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# for i in range(len(parts) - 3): #LINE# #TAB# #TAB# #TAB# #TAB# yield func
"#LINE# #TAB# with open(filename, 'r') as f: #LINE# #TAB# #TAB# for line in f: #LINE# #TAB# #TAB# #TAB# line = line.strip() #LINE# #TAB# #TAB# #TAB# if line.startswith('ignore'): #LINE# #TAB# #TAB# #TAB# #TAB# return True #LINE# #TAB# return False"
#LINE# #TAB# if code.count('1')!= 2: #LINE# #TAB# #TAB# raise voluptuous.Invalid('Invalid value for country code: {}'.format #LINE# #TAB# #TAB# #TAB# (code)) #LINE# #TAB# return code
"#LINE# #TAB# out_file = out_txt + '.summary.txt' #LINE# #TAB# cmd ='samtools view -h %s | bgzip > %s' % (bam, bam) #LINE# #TAB# run(cmd) #LINE# #TAB# with open(out_file, 'w') as out_handle: #LINE# #TAB# #TAB# for line in out_handle: #LINE# #TAB# #TAB# #TAB# line = line.strip() #LINE# #TAB# #TAB# #TAB# line = line.split()[0] #LINE# #TAB# #TAB# #TAB# line = line.split()[1] #LINE# #TAB# #TAB# #TAB# run(cmd) #LINE# #TAB# return out_file"
"#LINE# #TAB# template_dir = os.path.join(os.path.dirname(builder.__file__), #LINE# #TAB# #TAB# '{}_{}.html'.format(provider, region)) #LINE# #TAB# filename = os.path.join(template_dir, '{}_{}.html'.format(provider, region)) #LINE# #TAB# with open(filename, 'w') as f: #LINE# #TAB# #TAB# f.write(builder.__str__()) #LINE# #TAB# return filename"
#LINE# #TAB# if p[1] == 'UNION': #LINE# #TAB# #TAB# p[0] = [p[3]] #LINE# #TAB# else: #LINE# #TAB# #TAB# p[0] = [p[1]]
"#LINE# #TAB# cols = ((cols - 6) *.85) #LINE# #TAB# if shorten is False or len(url) < cols: #LINE# #TAB# #TAB# return url #LINE# #TAB# split = int(cols *.5) #LINE# #TAB# return url[:split] + ""..."" + url[-split:]"
"#LINE# #TAB# response = request_handler.make_request('GET', '/reports') #LINE# #TAB# matches = filter(lambda x: x['name'] == name, response.json()) #LINE# #TAB# if matches: #LINE# #TAB# #TAB# return cls(request_handler, matches) #LINE# #TAB# return None"
"#LINE# #TAB# assert tag in cls.tags #LINE# #TAB# if isinstance(schema, dict): #LINE# #TAB# #TAB# for k, v in schema.items(): #LINE# #TAB# #TAB# #TAB# if tag == k: #LINE# #TAB# #TAB# #TAB# #TAB# return v #LINE# #TAB# #TAB# elif isinstance(schema, list): #LINE# #TAB# #TAB# #TAB# for i, v in enumerate(schema): #LINE# #TAB# #TAB# #TAB# #TAB# if v is not None: #LINE# #TAB# #TAB# #TAB# #TAB# #TAB# schema[i] = v #LINE# #TAB# return schema"
"#LINE# #TAB# import matplotlib.pyplot as plt #LINE# #TAB# fig = plt.figure() #LINE# #TAB# for i in range(0, graph.shape[0]): #LINE# #TAB# #TAB# j = 0 #LINE# #TAB# #TAB# for k in range(0, graph.shape[1]): #LINE# #TAB# #TAB# #TAB# v = graph[i][k] #LINE# #TAB# #TAB# #TAB# if v!= j: #LINE# #TAB# #TAB# #TAB# #TAB# plt.plot(i, j, k, linewidth=2) #LINE# #TAB# #TAB# #TAB# plt.xlabel('Iteration') #LINE# #TAB# #TAB# #TAB# plt.ylabel('Value') #LINE# #TAB# #TAB# #TAB# plt.colorbar() #LINE# #TAB# #TAB# #TAB# i = j"
#LINE# #TAB# if sys.platform == 'darwin': #LINE# #TAB# #TAB# cond = QApplication.desktopIsLocked() #LINE# #TAB# #TAB# if cond: #LINE# #TAB# #TAB# #TAB# return True #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# return False #LINE# #TAB# else: #LINE# #TAB# #TAB# return False
"#LINE# #TAB# d = {} #LINE# #TAB# for k, v in globals().items(): #LINE# #TAB# #TAB# if k.startswith('_'): #LINE# #TAB# #TAB# #TAB# continue #LINE# #TAB# #TAB# foo = getattr(v, 'foo', None) #LINE# #TAB# #TAB# if foo is None: #LINE# #TAB# #TAB# #TAB# continue #LINE# #TAB# #TAB# d[k] = foo #LINE# #TAB# return d"
#LINE# #TAB# if not os.path.exists(config_file): #LINE# #TAB# #TAB# print('Configuration file {} not found.'.format(config_file)) #LINE# #TAB# #TAB# exit(1) #LINE# #TAB# click.echo('Done!') #LINE# #TAB# return 0
#LINE# #TAB# if response.find('QSTAT:') >= 0: #LINE# #TAB# #TAB# return 100 #LINE# #TAB# elif response.find('QSTAT:') >= 0: #LINE# #TAB# #TAB# return 21 #LINE# #TAB# elif response.find('QSTAT:') >= 0: #LINE# #TAB# #TAB# return 22 #LINE# #TAB# else: #LINE# #TAB# #TAB# return None
"#LINE# #TAB# x = np.arange(ranges[0]) #LINE# #TAB# y = np.arange(ranges[1]) #LINE# #TAB# if len(ranges) == 1: #LINE# #TAB# #TAB# return x, y #LINE# #TAB# edges = np.empty((len(x), 1)) #LINE# #TAB# edges[0] = x[0] + 0.5 #LINE# #TAB# edges[-1] = x[-1] + 0.5 #LINE# #TAB# if len(ranges) == 2: #LINE# #TAB# #TAB# return edges[0], y #LINE# #TAB# return edges"
#LINE# #TAB# if lut and label in LUT_LABELS: #LINE# #TAB# #TAB# num = lut[label] #LINE# #TAB# elif label == '-': #LINE# #TAB# #TAB# num = 0 #LINE# #TAB# else: #LINE# #TAB# #TAB# num = int(label) #LINE# #TAB# for char in label: #LINE# #TAB# #TAB# if char.isdigit(): #LINE# #TAB# #TAB# #TAB# num += 1 #LINE# #TAB# #TAB# elif char == '_': #LINE# #TAB# #TAB# #TAB# num += 1 #LINE# #TAB# return num
"#LINE# #TAB# if string is None: #LINE# #TAB# #TAB# return string #LINE# #TAB# try: #LINE# #TAB# #TAB# if is_bytes(string): #LINE# #TAB# #TAB# #TAB# string = string.decode('utf8') #LINE# #TAB# #TAB# try: #LINE# #TAB# #TAB# #TAB# string = base64.b64decode(string) #LINE# #TAB# #TAB# except (TypeError, binascii.Error): #LINE# #TAB# #TAB# #TAB# pass #LINE# #TAB# #TAB# try: #LINE# #TAB# #TAB# #TAB# string = string.decode('base64') #LINE# #TAB# #TAB# except TypeError: #LINE# #TAB# #TAB# #TAB# string = string.decode('utf8') #LINE# #TAB# return string"
#LINE# #TAB# if control[0] > test[0]: #LINE# #TAB# #TAB# return 1.0 #LINE# #TAB# elif control[0] < test[0]: #LINE# #TAB# #TAB# return 0.5 #LINE# #TAB# else: #LINE# #TAB# #TAB# return 1.0
"#LINE# #TAB# try: #LINE# #TAB# #TAB# f = open('parameters.json', 'r') #LINE# #TAB# #TAB# out = json.load(f) #LINE# #TAB# #TAB# f.close() #LINE# #TAB# #TAB# return out #LINE# #TAB# except: #LINE# #TAB# #TAB# raise"
"#LINE# #TAB# dvs = session.call_xenapi('VSI.get_DVS', dvs_name) #LINE# #TAB# if dvs and dvs['PortGroup']: #LINE# #TAB# #TAB# port_groups = dvs['PortGroup'] #LINE# #TAB# #TAB# for port_group in port_groups: #LINE# #TAB# #TAB# #TAB# vlan_id = port_group['PortGroup']['Id'] #LINE# #TAB# #TAB# #TAB# if pg_name == port_group['PortGroup']['Name']: #LINE# #TAB# #TAB# #TAB# #TAB# return vlan_id #LINE# #TAB# return None"
#LINE# #TAB# if option is None: #LINE# #TAB# #TAB# return [] #LINE# #TAB# else: #LINE# #TAB# #TAB# return [option]
#LINE# #TAB# try: #LINE# #TAB# #TAB# importlib.import_module(module_name) #LINE# #TAB# #TAB# return True #LINE# #TAB# except ImportError: #LINE# #TAB# #TAB# return False
"#LINE# #TAB# if not is_in_project(database_name): #LINE# #TAB# #TAB# raise ValueError('Database {} not in project {}'.format(database_name, #LINE# #TAB# #TAB# #TAB# PROJECT_NAME)) #LINE# #TAB# if not has_activities(database_name): #LINE# #TAB# #TAB# raise ValueError('Database {} has activities'.format(database_name)) #LINE# #TAB# return database_name"
"#LINE# #TAB# match = False #LINE# #TAB# if song_name!= '' and song_title!= '': #LINE# #TAB# #TAB# match = True #LINE# #TAB# if song_name == artist: #LINE# #TAB# #TAB# match = False #LINE# #TAB# if song_title!= '': #LINE# #TAB# #TAB# match = True #LINE# #TAB# if compare_songs(song_name, song_title): #LINE# #TAB# #TAB# return compare_songs(song_name, artist) #LINE# #TAB# if compare_songs(artist, song_name): #LINE# #TAB# #TAB# return compare_songs(artist, song_name) #LINE# #TAB# if compare_songs(artist, song_title): #LINE# #TAB# #TAB# return compare_songs(artist, song_title) #LINE# #TAB# return 0"
"#LINE# #TAB# for dialect in dialects: #LINE# #TAB# #TAB# if hasattr(dialect, 'original_name'): #LINE# #TAB# #TAB# #TAB# dialect = dialect.original_name() #LINE# #TAB# #TAB# if hasattr(dialect, 'canonical_name'): #LINE# #TAB# #TAB# #TAB# dialect = dialect.canonical_name() #LINE# #TAB# #TAB# break #LINE# #TAB# if len(dialects) == 1: #LINE# #TAB# #TAB# return dialects[0] #LINE# #TAB# else: #LINE# #TAB# #TAB# return dialects[0]"
#LINE# #TAB# if initialized == True: #LINE# #TAB# #TAB# __bar = True #LINE# #TAB# else: #LINE# #TAB# #TAB# __bar = False #LINE# #TAB# return __bar
#LINE# #TAB# if not run: #LINE# #TAB# #TAB# y = True #LINE# #TAB# else: #LINE# #TAB# #TAB# y = False #LINE# #TAB# return y
"#LINE# #TAB# with open(filedir_pdf, 'wb') as fid: #LINE# #TAB# #TAB# fid.write(pdf_bytes) #LINE# #TAB# os.chdir(filedir_pdf) #LINE# #TAB# return"
#LINE# #TAB# test_graph = _TestGraph() #LINE# #TAB# for node in graph: #LINE# #TAB# #TAB# test_graph.add_node(node) #LINE# #TAB# for child in test_graph.children: #LINE# #TAB# #TAB# test_graph.remove_edge(*child) #LINE# #TAB# return test_graph
"#LINE# #TAB# infile = os.path.join(dirPath, 'data.csv') #LINE# #TAB# data = [] #LINE# #TAB# if modify: #LINE# #TAB# #TAB# for idx, f in enumerate(infile): #LINE# #TAB# #TAB# #TAB# if idx % numLabels == 0: #LINE# #TAB# #TAB# #TAB# #TAB# data.append([]) #LINE# #TAB# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# #TAB# data.append([]) #LINE# #TAB# data = np.array(data) #LINE# #TAB# return data"
"#LINE# #TAB# logger = logging.getLogger(__name__) #LINE# #TAB# now = datetime.datetime.utcnow() #LINE# #TAB# expiration_datetime = expiration + datetime.timedelta(seconds=expiration) #LINE# #TAB# logger.debug('expiration = %s, now = %s', expiration_datetime, now) #LINE# #TAB# params = {'oauth_consumer_key': credentials.consumer_key, 'oauth_consumer_secret': #LINE# #TAB# #TAB# credentials.secret, 'token': credentials.token, 'expires_in': now, #LINE# #TAB# #TAB#'string_to_sign': string_to_sign, 'dont_sign': 1 if #LINE# #TAB# #TAB# credentials.dont_sign else 0} #LINE# #TAB# return params"
"#LINE# #TAB# try: #LINE# #TAB# #TAB# api.selinux(domain, logger) #LINE# #TAB# #TAB# return True #LINE# #TAB# except libvirtError as e: #LINE# #TAB# #TAB# logger.error('API error message: %s' % e) #LINE# #TAB# #TAB# return False"
#LINE# #TAB# file_stats = os.stat(file_path) #LINE# #TAB# return file_stats
"#LINE# #TAB# if isinstance(obj, argparse.Namespace): #LINE# #TAB# #TAB# ns = obj.items() #LINE# #TAB# #TAB# if len(ns) > 0: #LINE# #TAB# #TAB# #TAB# out = {} #LINE# #TAB# #TAB# #TAB# for k, v in ns[0].items(): #LINE# #TAB# #TAB# #TAB# #TAB# if isinstance(v, optparse.Value): #LINE# #TAB# #TAB# #TAB# #TAB# #TAB# out[k] = foo(v) #LINE# #TAB# #TAB# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# #TAB# #TAB# out[k] = v #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# out = obj #LINE# #TAB# else: #LINE# #TAB# #TAB# out = obj #LINE# #TAB# return out"
"#LINE# #TAB# if os.name == 'nt': #LINE# #TAB# #TAB# try: #LINE# #TAB# #TAB# #TAB# fd = getfd() #LINE# #TAB# #TAB# except OSError: #LINE# #TAB# #TAB# #TAB# return True #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# try: #LINE# #TAB# #TAB# #TAB# #TAB# sock = socket.fromfd(fd, socket.AF_INET, socket.SOCK_STREAM) #LINE# #TAB# #TAB# #TAB# #TAB# return True #LINE# #TAB# #TAB# #TAB# except OSError: #LINE# #TAB# #TAB# #TAB# #TAB# return True #LINE# #TAB# return False"
"#LINE# #TAB# loggers = [] #LINE# #TAB# for name, logger in loggers: #LINE# #TAB# #TAB# if name.startswith('foo'): #LINE# #TAB# #TAB# #TAB# loggers.append((name, logger)) #LINE# #TAB# return loggers"
#LINE# #TAB# try: #LINE# #TAB# #TAB# return next(os.walk(directory))[0] #LINE# #TAB# except StopIteration: #LINE# #TAB# #TAB# return None
"#LINE# #TAB# columns = df.columns #LINE# #TAB# if len(rois.shape) == 2: #LINE# #TAB# #TAB# df_rois = df[rois == 1] #LINE# #TAB# else: #LINE# #TAB# #TAB# df_rois = df[rois == 0] #LINE# #TAB# means = np.zeros((rois.shape[0], rois.shape[1])) #LINE# #TAB# for i in range(0, rois.shape[0]): #LINE# #TAB# #TAB# means[(i), :] = np.dot(df_rois[(i), :], rois[(i), :]) #LINE# #TAB# return means"
"#LINE# #TAB# fjac = infodic['fjac'] #LINE# #TAB# ipvt = infodic['ipvt'] #LINE# #TAB# n = len(p) #LINE# #TAB# perm = np.take(np.eye(n), ipvt - 1, 0) #LINE# #TAB# r = np.triu(np.transpose(fjac)[:n, :]) #LINE# #TAB# R = np.dot(r, perm) #LINE# #TAB# try: #LINE# #TAB# #TAB# cov_x = np.linalg.inv(np.dot(np.transpose(R), R)) #LINE# #TAB# except LinAlgError: #LINE# #TAB# #TAB# cov_x = None #LINE# #TAB# return cov_x"
"#LINE# #TAB# sum = float('inf') #LINE# #TAB# for i in range(0, len(iterable) - n + 1): #LINE# #TAB# #TAB# sum += iterable[i] #LINE# #TAB# return sum / n"
#LINE# #TAB# if check_platform: #LINE# #TAB# #TAB# try: #LINE# #TAB# #TAB# #TAB# dist = pkg_resources.get_distribution(name) #LINE# #TAB# #TAB# #TAB# return dist.is_installed() #LINE# #TAB# #TAB# except pkg_resources.DistributionNotFound: #LINE# #TAB# #TAB# #TAB# pass #LINE# #TAB# return False
"#LINE# #TAB# global frob_coeffs #LINE# #TAB# i %= 2 #LINE# #TAB# if i == 0: #LINE# #TAB# #TAB# return t_x #LINE# #TAB# return t_x[0], t_x[1] * frob_coeffs[2, i, 1] % Q"
"#LINE# #TAB# if fills[0] == 1: #LINE# #TAB# #TAB# for i in range(1, len(x) + 1): #LINE# #TAB# #TAB# #TAB# x = x[i] #LINE# #TAB# #TAB# #TAB# y = y[i] #LINE# #TAB# if fills[0] + 1 == len(x): #LINE# #TAB# #TAB# for i in range(1, len(x)): #LINE# #TAB# #TAB# #TAB# if x[i] + y[i] >= fills[1]: #LINE# #TAB# #TAB# #TAB# #TAB# return True #LINE# #TAB# return False"
"#LINE# #TAB# q = a * np.pi / 180 #LINE# #TAB# r = b * np.pi / 180 #LINE# #TAB# q = np.mod(q, 2 * np.pi) + np.mod(r, 2 * np.pi / 180) #LINE# #TAB# r = r - np.mod(q, 2 * np.pi / 180) #LINE# #TAB# return q, r"
"#LINE# #TAB# try: #LINE# #TAB# #TAB# conn = sqlite3.connect(db_file) #LINE# #TAB# #TAB# return conn #LINE# #TAB# except Error as e: #LINE# #TAB# #TAB# print(bcolors.FAIL, e, bcolors.ENDC) #LINE# #TAB# return None"
"#LINE# #TAB# import os #LINE# #TAB# if not os.path.exists(cachefname): #LINE# #TAB# #TAB# return False, None #LINE# #TAB# cache = os.path.isfile(cachefname) #LINE# #TAB# if not cache: #LINE# #TAB# #TAB# return False, None #LINE# #TAB# try: #LINE# #TAB# #TAB# with open(cachefname, 'rb') as f: #LINE# #TAB# #TAB# #TAB# cached = f.read() #LINE# #TAB# except Exception: #LINE# #TAB# #TAB# return False, None #LINE# #TAB# return True, cached"
#LINE# #TAB# if cur_dev_size < thres_dev_size: #LINE# #TAB# #TAB# return base_interval #LINE# #TAB# interval = int(cur_dev_size / thres_dev_size) #LINE# #TAB# if interval <= 1: #LINE# #TAB# #TAB# return base_interval #LINE# #TAB# return interval + 1
"#LINE# #TAB# d = {} #LINE# #TAB# for month in range(1, 13): #LINE# #TAB# #TAB# d[month] = year #LINE# #TAB# #TAB# if month == 12: #LINE# #TAB# #TAB# #TAB# d[month] = year #LINE# #TAB# #TAB# if month == 14: #LINE# #TAB# #TAB# #TAB# d[month] = year + 1 #LINE# #TAB# #TAB# if month == 15: #LINE# #TAB# #TAB# #TAB# d[month] = year #LINE# #TAB# #TAB# if month == 16: #LINE# #TAB# #TAB# #TAB# d[month] = year #LINE# #TAB# return d"
"#LINE# #TAB# kernel = np.ones(S.shape) #LINE# #TAB# for i in range(S.shape[1]): #LINE# #TAB# #TAB# kernel[i, 0] += S[i, 1] * np.log(D[i, 0]) + variance * np.log(S[i, 1] #LINE# #TAB# #TAB# #TAB# ) ** 2 #LINE# #TAB# return kernel"
#LINE# #TAB# if node is not None: #LINE# #TAB# #TAB# pubdate = node.find('./pubdate') #LINE# #TAB# #TAB# return {'date': pubdate.text}
"#LINE# #TAB# foo = set() #LINE# #TAB# for seq in SeqIO.parse(trimmed_aln, 'fasta'): #LINE# #TAB# #TAB# try: #LINE# #TAB# #TAB# #TAB# for x in seq: #LINE# #TAB# #TAB# #TAB# #TAB# if x[0] == 'X' and x[-1] == '-': #LINE# #TAB# #TAB# #TAB# #TAB# #TAB# continue #LINE# #TAB# #TAB# #TAB# #TAB# if x[0] == 'X' and x[-1] > 30: #LINE# #TAB# #TAB# #TAB# #TAB# #TAB# foo.add(seq.id) #LINE# #TAB# #TAB# except ValueError: #LINE# #TAB# #TAB# #TAB# pass #LINE# #TAB# return foo"
"#LINE# #TAB# client = ofxclient.Client() #LINE# #TAB# result = client.accounts(accounts) #LINE# #TAB# result = combine_accounts(result, accounts, days) #LINE# #TAB# return result"
"#LINE# #TAB# if not isinstance(mats[0], sp.spmatrix): #LINE# #TAB# #TAB# raise ValueError('Input must be an instance of sp.spmatrix.') #LINE# #TAB# if len(mats[0].shape)!= 2: #LINE# #TAB# #TAB# raise ValueError('Input must have 2 dimensions.') #LINE# #TAB# output = np.zeros(mats[0].shape, dtype=mats[0].dtype) #LINE# #TAB# for m in mats: #LINE# #TAB# #TAB# output[m.nonzero()[0]] = np.median(m.nonzero()) #LINE# #TAB# return output"
#LINE# #TAB# assert type_geni == 'g' #LINE# #TAB# if profile is not None and type_geni == 'g': #LINE# #TAB# #TAB# if geni_input is not None and profile not in geni_input: #LINE# #TAB# #TAB# #TAB# return geni_input[profile] #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# return profile #LINE# #TAB# elif profile is not None and type_geni == 'g': #LINE# #TAB# #TAB# if geni_input is not None and profile not in geni_input: #LINE# #TAB# #TAB# #TAB# return geni_input[profile] #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# return profile
#LINE# #TAB# if mn is None and mx is None: #LINE# #TAB# #TAB# return True #LINE# #TAB# if dtype is not None and mn is not None: #LINE# #TAB# #TAB# if mx is None: #LINE# #TAB# #TAB# #TAB# return True #LINE# #TAB# #TAB# return False #LINE# #TAB# if dtype is not None: #LINE# #TAB# #TAB# if mn is None: #LINE# #TAB# #TAB# #TAB# mn = np.inf #LINE# #TAB# #TAB# if mx is None: #LINE# #TAB# #TAB# #TAB# mx = np.inf #LINE# #TAB# #TAB# return True #LINE# #TAB# if mn is None: #LINE# #TAB# #TAB# mn = np.inf #LINE# #TAB# if mx is None: #LINE# #TAB# #TAB# mx = np.inf #LINE# #TAB# return True
"#LINE# #TAB# if when is None: #LINE# #TAB# #TAB# when = datetime.utcnow() #LINE# #TAB# else: #LINE# #TAB# #TAB# when = str(when) #LINE# #TAB# n = time.strftime('%Y%m%d%H%I%S.%f') #LINE# #TAB# nonce = '{0}{1}'.format(when, n) #LINE# #TAB# return nonce"
#LINE# #TAB# if slot.cardinality and 'for' in slot.cardinality: #LINE# #TAB# #TAB# return f'@{slot.cardinality}{slot.name}' #LINE# #TAB# return ''
"#LINE# #TAB# for test in [lambda x: ipaddress.IPv6Address(x)._prefixlen!= 128, lambda #LINE# #TAB# #TAB# x: ipaddress.IPv6Address(x)._prefixlen!= 128]: #LINE# #TAB# #TAB# try: #LINE# #TAB# #TAB# #TAB# return bool(test(value)) #LINE# #TAB# #TAB# except: #LINE# #TAB# #TAB# #TAB# pass #LINE# #TAB# return False"
"#LINE# #TAB# with open(filename, 'r') as f: #LINE# #TAB# #TAB# info = json.load(f) #LINE# #TAB# #TAB# return info['time']"
#LINE# #TAB# if lease_id is None: #LINE# #TAB# #TAB# return True #LINE# #TAB# if status is None: #LINE# #TAB# #TAB# return True #LINE# #TAB# if status not in cls.STATUSES: #LINE# #TAB# #TAB# return True #LINE# #TAB# return True
"#LINE# #TAB# try: #LINE# #TAB# #TAB# f = open(LOG_FILE, 'a') #LINE# #TAB# #TAB# f.write('hello') #LINE# #TAB# #TAB# f.close() #LINE# #TAB# #TAB# exit(0) #LINE# #TAB# except IOError: #LINE# #TAB# #TAB# pass"
"#LINE# #TAB# assert os.path.exists(filename), 'Input file {} does not exist'.format(filename #LINE# #TAB# #TAB# ) #LINE# #TAB# with open(filename) as f: #LINE# #TAB# #TAB# err = f.read() #LINE# #TAB# #TAB# if err == '': #LINE# #TAB# #TAB# #TAB# raise FileNotFoundError('Input file {} does not exist'.format(filename)) #LINE# #TAB# #TAB# return filename"
#LINE# #TAB# logger = logging.getLogger(__name__) #LINE# #TAB# logger.setLevel(logging.DEBUG) #LINE# #TAB# handler = logging.StreamHandler(sys.stdout) #LINE# #TAB# handler.setLevel(logging.INFO) #LINE# #TAB# formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s') #LINE# #TAB# handler.setFormatter(formatter) #LINE# #TAB# logger.addHandler(handler) #LINE# #TAB# return logger
#LINE# #TAB# trimmed_size = float(untrimmed_alignment_size) #LINE# #TAB# if trimmed_size == 0: #LINE# #TAB# #TAB# return 0 #LINE# #TAB# elif no_sites_trimmed == 0: #LINE# #TAB# #TAB# return 1 #LINE# #TAB# else: #LINE# #TAB# #TAB# return abs(trimmed_size / no_sites_trimmed) / trimmed_size
"#LINE# #TAB# r = int(color[:2], 16) #LINE# #TAB# g = int(color[2:4], 16) #LINE# #TAB# b = int(color[4:6], 16) #LINE# #TAB# return r, g, b"
"#LINE# #TAB# c = 0 #LINE# #TAB# if isinstance(v, str): #LINE# #TAB# #TAB# c = len(v) #LINE# #TAB# while len(c) < 2: #LINE# #TAB# #TAB# c += 1 #LINE# #TAB# #TAB# v = v % 256 #LINE# #TAB# return k, v"
#LINE# #TAB# my_table = [] #LINE# #TAB# for row in csv_content: #LINE# #TAB# #TAB# my_table.append(MyTableCell(row)) #LINE# #TAB# return my_table
#LINE# #TAB# url = URL +'schools/' + code + '.json' #LINE# #TAB# response = requests.get(url) #LINE# #TAB# if response.status_code == 200: #LINE# #TAB# #TAB# data = json.loads(response.text) #LINE# #TAB# #TAB# return data #LINE# #TAB# else: #LINE# #TAB# #TAB# return {'code': code}
#LINE# #TAB# seen = set() #LINE# #TAB# return [x for x in tab if x not in seen and not seen.add(x)]
"#LINE# #TAB# with np.errstate(divide='ignore'): #LINE# #TAB# #TAB# Z = np.zeros(X.shape[0], dtype=np.float64) #LINE# #TAB# #TAB# for i in range(X.shape[0]): #LINE# #TAB# #TAB# #TAB# Z[i] = 2 * np.pi * gamma * np.log(X[i] / X.shape[0]) #LINE# #TAB# return Z"
#LINE# #TAB# cls.command_sub = 'foo' #LINE# #TAB# result = cls.execute(cls._construct_command(options)) #LINE# #TAB# return result
#LINE# #TAB# if m is not None and m.contains(t): #LINE# #TAB# #TAB# return m - t #LINE# #TAB# else: #LINE# #TAB# #TAB# return 0
#LINE# #TAB# assert min_value >= 0 and max_value >= 0 #LINE# #TAB# im = np.asarray(im) #LINE# #TAB# if im.ndim == 0: #LINE# #TAB# #TAB# return min_value #LINE# #TAB# elif im.ndim == 1: #LINE# #TAB# #TAB# return max_value #LINE# #TAB# else: #LINE# #TAB# #TAB# return im
"#LINE# #TAB# if z < 0: #LINE# #TAB# #TAB# raise ValueError( #LINE# #TAB# #TAB# #TAB# 'Input parameter z must be a positive number') #LINE# #TAB# if z2 < 0: #LINE# #TAB# #TAB# raise ValueError( #LINE# #TAB# #TAB# #TAB# 'Input parameter z2 must be non-negative number') #LINE# #TAB# F = 1 / (NA + z * z2) #LINE# #TAB# p = (NA + z * z2) / (NA + z * z2) #LINE# #TAB# F_mp = F * ((1 + z / z2) ** 2) #LINE# #TAB# p = p * F_mp #LINE# #TAB# return F, p"
"#LINE# #TAB# vocab_path = get_vocab_path(vocab_path) #LINE# #TAB# if vocab_path == None: #LINE# #TAB# #TAB# return [] #LINE# #TAB# with open(vocab_path, 'r') as f: #LINE# #TAB# #TAB# return [f.readline().strip() for f in f.readlines()]"
"#LINE# #TAB# if allowedreacs is None: #LINE# #TAB# #TAB# allowedreacs = [model] #LINE# #TAB# out = [] #LINE# #TAB# for reac in model.reactions: #LINE# #TAB# #TAB# if reac in allowedreacs: #LINE# #TAB# #TAB# #TAB# continue #LINE# #TAB# #TAB# out.append((reac, model.reactions[reac])) #LINE# #TAB# foo = foo_dict(model, reacsbounds=reacsbounds, tol=tol) #LINE# #TAB# return foo"
"#LINE# #TAB# for path in list_of_paths: #LINE# #TAB# #TAB# if not os.access(path, os.W_OK): #LINE# #TAB# #TAB# #TAB# try: #LINE# #TAB# #TAB# #TAB# #TAB# os.unlink(path) #LINE# #TAB# #TAB# #TAB# except OSError: #LINE# #TAB# #TAB# #TAB# #TAB# pass"
"#LINE# #TAB# dt = datetime.datetime.fromtimestamp(date, tzinfo) #LINE# #TAB# dt = dt.replace(microsecond=0) #LINE# #TAB# return dt"
#LINE# #TAB# for i in range(n_adult): #LINE# #TAB# #TAB# for j in range(n_child): #LINE# #TAB# #TAB# #TAB# participants[i][j] = participants[i][j] + 1 #LINE# #TAB# return participants
#LINE# #TAB# for path in paths: #LINE# #TAB# #TAB# if os.path.isfile(path): #LINE# #TAB# #TAB# #TAB# section = Path(path) #LINE# #TAB# #TAB# #TAB# for p in section.sections(): #LINE# #TAB# #TAB# #TAB# #TAB# if p.startswith('python') and p.endswith('.getParameters'): #LINE# #TAB# #TAB# #TAB# #TAB# #TAB# yield path #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# break
"#LINE# #TAB# if x.get_shape().ndims == 2: #LINE# #TAB# #TAB# return x[:, :, (None)] #LINE# #TAB# elif x.get_shape().ndims == 3: #LINE# #TAB# #TAB# return x[:, :, (None)] #LINE# #TAB# else: #LINE# #TAB# #TAB# return x"
"#LINE# #TAB# if not s: #LINE# #TAB# #TAB# return s #LINE# #TAB# s = '""%s""' % s.replace('""', '\\""') #LINE# #TAB# if'' in s: #LINE# #TAB# #TAB# return s.replace(' ', '\\ ') #LINE# #TAB# if'' in s: #LINE# #TAB# #TAB# return s.replace(' ', '\\ ') #LINE# #TAB# return s"
#LINE# #TAB# if date: #LINE# #TAB# #TAB# return date.strftime('%Y-%m-%d') #LINE# #TAB# else: #LINE# #TAB# #TAB# return ''
"#LINE# #TAB# jump = offset % 4 #LINE# #TAB# if jump: #LINE# #TAB# #TAB# offset += 4 - jump #LINE# #TAB# (default, low, high), offset = _unpack(_struct_iii, bc, offset) #LINE# #TAB# joffs = list() #LINE# #TAB# for _index in range(high - low + 1): #LINE# #TAB# #TAB# j, offset = _unpack(_struct_i, bc, offset) #LINE# #TAB# #TAB# joffs.append(j) #LINE# #TAB# return (default, low, high, joffs), offset"
"#LINE# #TAB# res = asse_equal_start_with_none_re.match(logical_line #LINE# #TAB# #TAB# ) or asse_equal_end_with_none_re.match(logical_line) #LINE# #TAB# if res: #LINE# #TAB# #TAB# yield 0, 'N318: assertEqual(A, None) or assertEqual(None, A) sentences not allowed'"
#LINE# #TAB# if text is False: #LINE# #TAB# #TAB# return text #LINE# #TAB# try: #LINE# #TAB# #TAB# return text.decode('UTF-8') #LINE# #TAB# except UnicodeError: #LINE# #TAB# #TAB# try: #LINE# #TAB# #TAB# #TAB# return text.decode('CP1252') #LINE# #TAB# #TAB# except UnicodeError: #LINE# #TAB# #TAB# #TAB# return text
#LINE# #TAB# states = [] #LINE# #TAB# while True: #LINE# #TAB# #TAB# if n % 2: #LINE# #TAB# #TAB# #TAB# states.append('F') #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# states.append('S') #LINE# #TAB# #TAB# n //= 2 #LINE# #TAB# return states
#LINE# #TAB# ctx = _request_ctx_stack.top #LINE# #TAB# if'model' not in ctx: #LINE# #TAB# #TAB# ctx['model'] = _lookup_model() #LINE# #TAB# return ctx['model']
#LINE# #TAB# Optional[Exception]=None) ->Any: #LINE# #TAB# val = request.GET.get(name) #LINE# #TAB# if val is None: #LINE# #TAB# #TAB# if error_if_missing: #LINE# #TAB# #TAB# #TAB# raise web.HTTPBadRequest(body=f'Missing parameter: {name}') #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# raise error_if_missing #LINE# #TAB# return val
#LINE# #TAB# if len(tokens) < 2: #LINE# #TAB# #TAB# return None #LINE# #TAB# function_name = tokens[1].type.name #LINE# #TAB# if function_name =='return': #LINE# #TAB# #TAB# return None #LINE# #TAB# return function_name
"#LINE# #TAB# try: #LINE# #TAB# #TAB# if '=' not in arg: #LINE# #TAB# #TAB# #TAB# return arg_dict #LINE# #TAB# #TAB# tokens = arg.split('=') #LINE# #TAB# #TAB# if len(tokens) == 1: #LINE# #TAB# #TAB# #TAB# key = tokens[0] #LINE# #TAB# #TAB# #TAB# value = tokens[1] #LINE# #TAB# #TAB# elif len(tokens) == 2: #LINE# #TAB# #TAB# #TAB# key, value = tokens #LINE# #TAB# #TAB# #TAB# return {key: value} #LINE# #TAB# except: #LINE# #TAB# #TAB# return arg_dict #LINE# #TAB# return arg"
#LINE# #TAB# while True: #LINE# #TAB# #TAB# try: #LINE# #TAB# #TAB# #TAB# if deferred_email(): #LINE# #TAB# #TAB# #TAB# #TAB# return #LINE# #TAB# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# #TAB# time.sleep(5) #LINE# #TAB# #TAB# #TAB# except: #LINE# #TAB# #TAB# #TAB# #TAB# pass #LINE# #TAB# #TAB# except: #LINE# #TAB# #TAB# #TAB# pass
"#LINE# #TAB# data = subprocess.check_output(['iaca', '-l']) #LINE# #TAB# data = data.decode('ascii').strip() #LINE# #TAB# for line in data.split('\n'): #LINE# #TAB# #TAB# if line.startswith('iaca'): #LINE# #TAB# #TAB# #TAB# parts = line.split() #LINE# #TAB# #TAB# #TAB# for x in parts: #LINE# #TAB# #TAB# #TAB# #TAB# if x.endswith('.py'): #LINE# #TAB# #TAB# #TAB# #TAB# #TAB# filename = x #LINE# #TAB# #TAB# #TAB# #TAB# #TAB# break #LINE# #TAB# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# #TAB# filename = x #LINE# #TAB# return filename"
#LINE# #TAB# M = nx.Graph() #LINE# #TAB# if nodelist is None: #LINE# #TAB# #TAB# nodelist = G.nodes() #LINE# #TAB# for n in nodelist: #LINE# #TAB# #TAB# M.add_node(n) #LINE# #TAB# return M
"#LINE# #TAB# for y in range(num_peaks): #LINE# #TAB# #TAB# image = image[np.where(mask == 1, y)] #LINE# #TAB# return image"
"#LINE# #TAB# tlist = [] #LINE# #TAB# tlist.append(os.path.join(os.path.dirname(cls.__file__), 'templates')) #LINE# #TAB# for fn in tlist: #LINE# #TAB# #TAB# fname = os.path.join(os.path.dirname(fn), 'templates') #LINE# #TAB# #TAB# if os.path.isfile(fname): #LINE# #TAB# #TAB# #TAB# t = open(fname, 'r').read() #LINE# #TAB# #TAB# #TAB# tlist.append(t) #LINE# #TAB# #TAB# elif len(tlist) > 1: #LINE# #TAB# #TAB# #TAB# dialog = cls() #LINE# #TAB# #TAB# #TAB# dialog.show() #LINE# #TAB# #TAB# #TAB# break #LINE# #TAB# else: #LINE# #TAB# #TAB# dialog.show() #LINE# #TAB# #TAB# return None #LINE# #TAB# return tlist"
#LINE# #TAB# if w > h: #LINE# #TAB# #TAB# return 50 #LINE# #TAB# elif w < target: #LINE# #TAB# #TAB# return 50 #LINE# #TAB# else: #LINE# #TAB# #TAB# return target
#LINE# #TAB# val = value.strip() #LINE# #TAB# if len(val) == 1: #LINE# #TAB# #TAB# return bytes(val[0]) #LINE# #TAB# if len(val) == 2: #LINE# #TAB# #TAB# return bytes(val[0]) #LINE# #TAB# return val
#LINE# #TAB# for node in doc.iter(): #LINE# #TAB# #TAB# if node.text.strip() == '': #LINE# #TAB# #TAB# #TAB# yield node
"#LINE# #TAB# if blacklist_hostnames is None: #LINE# #TAB# #TAB# blacklist_hostnames = DEFAULT_BLACKLIST_HOSTNAMES #LINE# #TAB# url = re.sub(URL_PATTERN, '', url) #LINE# #TAB# url = url.lower() #LINE# #TAB# for host in blacklist_hostnames: #LINE# #TAB# #TAB# if url.startswith(host): #LINE# #TAB# #TAB# #TAB# return True #LINE# #TAB# return False"
#LINE# #TAB# rc = lib.sdl_sempost() #LINE# #TAB# if rc == -1: #LINE# #TAB# #TAB# raise SDLError() #LINE# #TAB# return rc
#LINE# #TAB# if values.get('data'): #LINE# #TAB# #TAB# data = values['data'] #LINE# #TAB# #TAB# bin_data = JobBinary(data=data) #LINE# #TAB# #TAB# bin_data.load() #LINE# #TAB# #TAB# return bin_data #LINE# #TAB# else: #LINE# #TAB# #TAB# return values
#LINE# #TAB# while True: #LINE# #TAB# #TAB# try: #LINE# #TAB# #TAB# #TAB# yield q.get(block=False) #LINE# #TAB# #TAB# except queue.Empty: #LINE# #TAB# #TAB# #TAB# return
"#LINE# #TAB# d = {} #LINE# #TAB# d.update(editions) #LINE# #TAB# for k, v in editions.items(): #LINE# #TAB# #TAB# if isinstance(v, dict): #LINE# #TAB# #TAB# #TAB# d[k] = foo(v) #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# d[k] = str(v) #LINE# #TAB# #TAB# if isinstance(v, list): #LINE# #TAB# #TAB# #TAB# d[k] = [foo(k) for k in v] #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# d[k] = str(v) #LINE# #TAB# return d"
"#LINE# #TAB# data = {} #LINE# #TAB# data[const.MSG_ID] = GOSSIP_NOTIFY #LINE# #TAB# data[const.MSG_LENGTH] = len(data) #LINE# #TAB# code = struct.unpack('<H', data[const.MSG_CODE])[0] #LINE# #TAB# data[const.MSG_CODE] = code #LINE# #TAB# return {'code': code, 'data': data}"
"#LINE# #TAB# closer = sym(r) if not allow_missing_close else sym(r) #LINE# #TAB# return sym(l, r, sep, expr) - closer"
"#LINE# #TAB# if not os.path.exists(CURRENT_DIRECTORY): #LINE# #TAB# #TAB# os.mkdir(CURRENT_DIRECTORY) #LINE# #TAB# filepath = os.path.join(CURRENT_DIRECTORY, filename) #LINE# #TAB# if not os.path.exists(filepath): #LINE# #TAB# #TAB# response = requests.get(filepath, stream=True) #LINE# #TAB# #TAB# response.raise_for_status() #LINE# #TAB# #TAB# return True #LINE# #TAB# return False"
"#LINE# #TAB# catch_errors.check_for_period_error(data, period) #LINE# #TAB# wma = sum(map(np.mean, data[period:])) #LINE# #TAB# return wma"
#LINE# #TAB# params = [] #LINE# #TAB# for i in range(len(paramMat)): #LINE# #TAB# #TAB# params.append(paramMat[i]) #LINE# #TAB# return params
"#LINE# #TAB# if isinstance(entry, np.ndarray): #LINE# #TAB# #TAB# for i in range(entry.shape[1]): #LINE# #TAB# #TAB# #TAB# if entry.data[i] < 0: #LINE# #TAB# #TAB# #TAB# #TAB# return False #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# return True #LINE# #TAB# else: #LINE# #TAB# #TAB# return True"
#LINE# #TAB# ustr = tools.bytes2str(ustr) #LINE# #TAB# if is_null_unit(ustr): #LINE# #TAB# #TAB# return True #LINE# #TAB# try: #LINE# #TAB# #TAB# as_unit(ustr) #LINE# #TAB# except ValueError: #LINE# #TAB# #TAB# return False #LINE# #TAB# return True
"#LINE# #TAB# if isinstance(phi, Atom): #LINE# #TAB# #TAB# if len(phi.atoms) > 1: #LINE# #TAB# #TAB# #TAB# phi.is_neg = False #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# phi.is_pos = True #LINE# #TAB# #TAB# #TAB# phi.is_neg = True #LINE# #TAB# elif isinstance(phi, CompoundFormula): #LINE# #TAB# #TAB# for sub in phi.atoms: #LINE# #TAB# #TAB# #TAB# if isinstance(sub, CompoundFormula): #LINE# #TAB# #TAB# #TAB# #TAB# foo(sub) #LINE# #TAB# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# #TAB# raise ValueError('Unexpected assignment: {}'.format(phi)) #LINE# #TAB# return phi"
"#LINE# #TAB# for offset in count(0, limit): #LINE# #TAB# #TAB# r = q.offset(offset).limit(limit).all() #LINE# #TAB# #TAB# for row in r: #LINE# #TAB# #TAB# #TAB# yield row"
"#LINE# #TAB# assert type(dict_str) == str #LINE# #TAB# ret = {} #LINE# #TAB# lines = dict_str.splitlines() #LINE# #TAB# for line in lines: #LINE# #TAB# #TAB# if str_ok: #LINE# #TAB# #TAB# #TAB# if not line.strip(): #LINE# #TAB# #TAB# #TAB# #TAB# continue #LINE# #TAB# #TAB# key, val = line.strip().split() #LINE# #TAB# #TAB# ret[key] = val #LINE# #TAB# return ret"
#LINE# #TAB# try: #LINE# #TAB# #TAB# return td.foo() #LINE# #TAB# except AttributeError: #LINE# #TAB# #TAB# return td
"#LINE# #TAB# choices = [] #LINE# #TAB# for image in images: #LINE# #TAB# #TAB# choice = '%s: %s' % (image.name, image.size) #LINE# #TAB# #TAB# choices.append(choice) #LINE# #TAB# return choices"
#LINE# #TAB# lst = [l for l in lst if l] #LINE# #TAB# if len(lst) == 0: #LINE# #TAB# #TAB# return None #LINE# #TAB# elif max(lst) == list(set(lst)): #LINE# #TAB# #TAB# return max(lst) #LINE# #TAB# else: #LINE# #TAB# #TAB# return lst[0]
"#LINE# #TAB# preorder_rows = cur.execute(""SELECT preorder_hash FROM preorder WHERE preorder_hash =?;"") #LINE# #TAB# preorder_rows = preorder_rows.fetchall() #LINE# #TAB# for preorder_row in preorder_rows: #LINE# #TAB# #TAB# if preorder_row['preorder_hash'] == preorder_hash: #LINE# #TAB# #TAB# #TAB# cur.execute(""DELETE FROM preorder WHERE preorder_hash =?;"") #LINE# #TAB# #TAB# #TAB# break #LINE# #TAB# return True"
"#LINE# #TAB# focus_widget = get_focus_widget() #LINE# #TAB# widget_id = focus_widget.id() #LINE# #TAB# declaration = widget_by_id(focus_widget, widget_id) #LINE# #TAB# return declaration"
"#LINE# #TAB# if edges == 0: #LINE# #TAB# #TAB# return [], [] #LINE# #TAB# forward = [] #LINE# #TAB# reverse = [] #LINE# #TAB# for i, j in edges: #LINE# #TAB# #TAB# if j == 0: #LINE# #TAB# #TAB# #TAB# forward.append(i) #LINE# #TAB# #TAB# #TAB# reverse.append(j) #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# forward.append(i + 1) #LINE# #TAB# #TAB# #TAB# reverse.append(j) #LINE# #TAB# if reverse: #LINE# #TAB# #TAB# return forward, reverse #LINE# #TAB# else: #LINE# #TAB# #TAB# return forward, reverse"
"#LINE# #TAB# x = radius * np.cos(0.5 * np.pi * height) #LINE# #TAB# y = radius * np.sin(0.5 * np.pi * height) #LINE# #TAB# if transform is not None: #LINE# #TAB# #TAB# x, y, z = foo_transform(mass, x, y, transform) #LINE# #TAB# return x, y, z"
#LINE# #TAB# repos = repos[:] #LINE# #TAB# if ignore_repos is not None: #LINE# #TAB# #TAB# for repo in repos: #LINE# #TAB# #TAB# #TAB# if repo in ignore_repos: #LINE# #TAB# #TAB# #TAB# #TAB# continue #LINE# #TAB# #TAB# #TAB# if repo not in repos: #LINE# #TAB# #TAB# #TAB# #TAB# repos.append(repo) #LINE# #TAB# return repos
#LINE# #TAB# try: #LINE# #TAB# #TAB# return time.mktime(value.timetuple()) #LINE# #TAB# except: #LINE# #TAB# #TAB# return value
"#LINE# #TAB# delta = normalize_datetime(delta) #LINE# #TAB# d = datetime.timedelta(hours=delta.hour, minutes=delta.minute, seconds= #LINE# #TAB# #TAB# delta.second) #LINE# #TAB# base = f'{d.year:02d}:{d.month:02d}' #LINE# #TAB# return f'{base}{delta.days:02d}'"
"#LINE# #TAB# with open(filename, 'rb') as infile: #LINE# #TAB# #TAB# pdf = PyPDF2(infile.read()) #LINE# #TAB# #TAB# infile.seek(0) #LINE# #TAB# #TAB# return pdf"
"#LINE# #TAB# if isinstance(args, str): #LINE# #TAB# #TAB# try: #LINE# #TAB# #TAB# #TAB# args = [i for i in args if i] #LINE# #TAB# #TAB# except: #LINE# #TAB# #TAB# #TAB# raise ValueError('for argument ""{}"" expected, got {}'. #LINE# #TAB# #TAB# #TAB# #TAB# format(argname, args)) #LINE# #TAB# return args"
#LINE# #TAB# ret = {} #LINE# #TAB# if auth is not None: #LINE# #TAB# #TAB# auth = auth.lower() #LINE# #TAB# #TAB# if 'access_token' in auth: #LINE# #TAB# #TAB# #TAB# ret['access_token'] = auth['access_token'] #LINE# #TAB# #TAB# if'refresh_token' in auth: #LINE# #TAB# #TAB# #TAB# ret['refresh_token'] = auth['refresh_token'] #LINE# #TAB# return ret
"#LINE# #TAB# if mime_type.startswith('image/'): #LINE# #TAB# #TAB# mime_type = 'image/' + mime_type #LINE# #TAB# for ext in ['jpg', 'jpeg', 'png']: #LINE# #TAB# #TAB# if mime_type.endswith(ext): #LINE# #TAB# #TAB# #TAB# return mime_type[:-len(ext)] #LINE# #TAB# return mime_type"
#LINE# #TAB# name = chebi_id_to_name(chebi_id) #LINE# #TAB# if offline and name.endswith('_offline'): #LINE# #TAB# #TAB# name = name[:-5] + '-offline' #LINE# #TAB# return name
#LINE# #TAB# for actor_ref in cls.actors: #LINE# #TAB# #TAB# if actor_ref.urn == actor_urn: #LINE# #TAB# #TAB# #TAB# return actor_ref #LINE# #TAB# return None
#LINE# #TAB# try: #LINE# #TAB# #TAB# return load_bookmarks(bookmark) #LINE# #TAB# except FileNotFoundError: #LINE# #TAB# #TAB# return {}
"#LINE# #TAB# for p in paths: #LINE# #TAB# #TAB# if p == idx: #LINE# #TAB# #TAB# #TAB# return #LINE# #TAB# #TAB# if isinstance(p, list): #LINE# #TAB# #TAB# #TAB# yield foo(p, idx) #LINE# #TAB# #TAB# elif isinstance(p, dict): #LINE# #TAB# #TAB# #TAB# for f, v in p.items(): #LINE# #TAB# #TAB# #TAB# #TAB# if isinstance(v, list): #LINE# #TAB# #TAB# #TAB# #TAB# #TAB# foo(paths, idx) #LINE# #TAB# #TAB# #TAB# #TAB# #TAB# yield f #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# yield p"
"#LINE# #TAB# if isinstance(obj, RO): #LINE# #TAB# #TAB# return RW(obj) #LINE# #TAB# elif isinstance(obj, np.ndarray): #LINE# #TAB# #TAB# return np.ndarray(obj.shape, dtype=obj.dtype) #LINE# #TAB# else: #LINE# #TAB# #TAB# return obj"
"#LINE# #TAB# res = [] #LINE# #TAB# for key, val in material['items'].items(): #LINE# #TAB# #TAB# if isinstance(val, dict): #LINE# #TAB# #TAB# #TAB# res.extend(foo(key, val)) #LINE# #TAB# #TAB# elif isinstance(val, list): #LINE# #TAB# #TAB# #TAB# res.extend(foo(val)) #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# res.append(val) #LINE# #TAB# return res"
"#LINE# #TAB# settings = fs.read(settings_path) #LINE# #TAB# if settings is None: #LINE# #TAB# #TAB# return None #LINE# #TAB# if not settings.strip(): #LINE# #TAB# #TAB# return None #LINE# #TAB# config = ConfigParser() #LINE# #TAB# try: #LINE# #TAB# #TAB# config.read(settings) #LINE# #TAB# except (IOError, ConfigParser.NoSectionError): #LINE# #TAB# #TAB# return None #LINE# #TAB# return config"
"#LINE# #TAB# #TAB# charge_balance = 0 #LINE# #TAB# #TAB# for parameter in struct.get('parameters', []): #LINE# #TAB# #TAB# #TAB# if parameter['charge']!= 0: #LINE# #TAB# #TAB# #TAB# #TAB# charge_balance += 1 #LINE# #TAB# #TAB# return charge_balance == 0"
"#LINE# #TAB# assert issparse(A) #LINE# #TAB# if A.dim() not in [2, 3]: #LINE# #TAB# #TAB# normalize_a = A.tocsc() #LINE# #TAB# else: #LINE# #TAB# #TAB# normalize_a = tf.divide(A, k=3) #LINE# #TAB# for _ in range(A.shape[0]): #LINE# #TAB# #TAB# for _ in range(A.shape[1]): #LINE# #TAB# #TAB# #TAB# normalize_a.data[(_), :] = tf.sqrt(norm(A.data[(_), :, :])) #LINE# #TAB# return normalize_a"
#LINE# #TAB# import ctypes as ct #LINE# #TAB# from.util import safe_call as safe_call #LINE# #TAB# from.library import backend #LINE# #TAB# if backend.name()!= 'cuda': #LINE# #TAB# #TAB# raise RuntimeError('Invalid backend loaded') #LINE# #TAB# safe_call(backend.get().afcu_set_dev_id(idx)) #LINE# #TAB# return
#LINE# #TAB# max_outputs = RPR.GetMaxMIDIOutputs() #LINE# #TAB# return max_outputs
#LINE# #TAB# output_array = '' #LINE# #TAB# for line in input_array: #LINE# #TAB# #TAB# if line!= '': #LINE# #TAB# #TAB# #TAB# if output_array[-1]!= '\n': #LINE# #TAB# #TAB# #TAB# #TAB# output_array += '\n' #LINE# #TAB# #TAB# #TAB# output_array += line + '\n' #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# output_array += line #LINE# #TAB# return output_array
#LINE# #TAB# v = [] #LINE# #TAB# for v in versions: #LINE# #TAB# #TAB# if reverse: #LINE# #TAB# #TAB# #TAB# v.reverse() #LINE# #TAB# #TAB# v.reverse() #LINE# #TAB# return v
#LINE# #TAB# try: #LINE# #TAB# #TAB# ret = x.foo(y) #LINE# #TAB# except Exception: #LINE# #TAB# #TAB# return False #LINE# #TAB# else: #LINE# #TAB# #TAB# return ret
#LINE# #TAB# if not signature.startswith(withSignature): #LINE# #TAB# #TAB# raise ValueError('Invalid signature: %r' % withSignature) #LINE# #TAB# if len(signature)!= len(withSignature): #LINE# #TAB# #TAB# raise ValueError('Invalid with signature: %r' % signature) #LINE# #TAB# return True
"#LINE# #TAB# if 'CONTENT_LENGTH' in environ: #LINE# #TAB# #TAB# return environ['CONTENT_LENGTH'] #LINE# #TAB# if 'CONTENT_LENGTH' in environ: #LINE# #TAB# #TAB# return environ['CONTENT_LENGTH'] #LINE# #TAB# if 'CONTENT_TYPE' in environ: #LINE# #TAB# #TAB# for k, v in environ['CONTENT_TYPE'].items(): #LINE# #TAB# #TAB# #TAB# if int(v) > 0: #LINE# #TAB# #TAB# #TAB# #TAB# return 0 #LINE# #TAB# return 0"
"#LINE# #TAB# for t in tables: #LINE# #TAB# #TAB# if isinstance(t, BaseX): #LINE# #TAB# #TAB# #TAB# ex = t.__getitem__() #LINE# #TAB# for k, v in ex.__dict__.items(): #LINE# #TAB# #TAB# if isinstance(v, (list, tuple)): #LINE# #TAB# #TAB# #TAB# foo = [] #LINE# #TAB# #TAB# #TAB# for f in v: #LINE# #TAB# #TAB# #TAB# #TAB# foo.append(table_ctor(f, k)) #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# pass #LINE# #TAB# return ex"
"#LINE# #TAB# from. import channels #LINE# #TAB# width = input_data.shape[0] #LINE# #TAB# height = output_data.shape[1] #LINE# #TAB# mode = (channels == 1).astype(converter_type) #LINE# #TAB# data = np.zeros(width, dtype=output_data.dtype) #LINE# #TAB# data[:, 0] = input_data[:, 0] #LINE# #TAB# data[:, 1] = output_data[:, 1] #LINE# #TAB# data[:, 2] = ratio #LINE# #TAB# conv_func = getattr(channels, mode) #LINE# #TAB# output_data[:, 1] = conv_func(data) #LINE# #TAB# return output_data"
"#LINE# #TAB# if scheme in ['http', 'https']: #LINE# #TAB# #TAB# scheme = 'https' #LINE# #TAB# if host.startswith('/'): #LINE# #TAB# #TAB# host = host[1:] #LINE# #TAB# return scheme + '://' + host"
"#LINE# #TAB# can_create = True #LINE# #TAB# try: #LINE# #TAB# #TAB# topic = Topic.objects.get(category=category, user=user, #LINE# #TAB# #TAB# #TAB# forum_id=forum.pk) #LINE# #TAB# #TAB# if user.is_superuser: #LINE# #TAB# #TAB# #TAB# can_create = False #LINE# #TAB# except Topic.DoesNotExist: #LINE# #TAB# #TAB# can_create = False #LINE# #TAB# return can_create"
#LINE# #TAB# if opts.bid: #LINE# #TAB# #TAB# print( #LINE# #TAB# #TAB# #TAB# ) #LINE# #TAB# #TAB# sys.exit(1) #LINE# #TAB# if opts.bid: #LINE# #TAB# #TAB# print( #LINE# #TAB# #TAB# #TAB# ) #LINE# #TAB# #TAB# sys.exit(1) #LINE# #TAB# return True
#LINE# #TAB# cfg = VersioneerConfig() #LINE# #TAB# cfg.VCS = 'git' #LINE# #TAB# cfg.style = '%(STYLE)s' #LINE# #TAB# cfg.tag_prefix = '%(TAG_PREFIX)s' #LINE# #TAB# cfg.parentdir_prefix = '%(PARENTDIR_PREFIX)s' #LINE# #TAB# cfg.versionfile_source = '%(VERSIONFILE_SOURCE)s' #LINE# #TAB# cfg.verbose = False #LINE# #TAB# return cfg
#LINE# #TAB# if len(attempt) <= 2 and longopt_list: #LINE# #TAB# #TAB# if attempt[0] == 't' and attempt[1] in longopt_list: #LINE# #TAB# #TAB# #TAB# return '--%s' % attempt[0] #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# return '--%s' % attempt[0] #LINE# #TAB# elif len(attempt) == 1 and attempt[0] in longopt_list: #LINE# #TAB# #TAB# return '--%s' % attempt[0] #LINE# #TAB# else: #LINE# #TAB# #TAB# return ''
"#LINE# #TAB# try: #LINE# #TAB# #TAB# sum = sum(map(int, claimset_data)) #LINE# #TAB# #TAB# if sum == 1: #LINE# #TAB# #TAB# #TAB# return True #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# return False #LINE# #TAB# except Exception: #LINE# #TAB# #TAB# return False"
#LINE# #TAB# if cigar_tuple[0] == 0 or cigar_tuple[1] <= 10: #LINE# #TAB# #TAB# return 1 #LINE# #TAB# else: #LINE# #TAB# #TAB# return 0
#LINE# #TAB# global is_notebook #LINE# #TAB# is_notebook = m == 1 #LINE# #TAB# logging.getLogger('nbexec').setLevel(logging.DEBUG) #LINE# #TAB# is_notebook = os.path.isfile(m) #LINE# #TAB# logging.getLogger('nbexec').setLevel(logging.DEBUG) #LINE# #TAB# os.environ['JUPYTERHUB_TOOLS'] = 'true' #LINE# #TAB# if is_notebook: #LINE# #TAB# #TAB# logging.getLogger('nbexec').setLevel(logging.DEBUG) #LINE# #TAB# else: #LINE# #TAB# #TAB# logging.getLogger('nbexec').setLevel(logging.DEBUG) #LINE# #TAB# return
#LINE# #TAB# if prefix.islower(): #LINE# #TAB# #TAB# prefix = str(prefix) #LINE# #TAB# if prefix.isupper(): #LINE# #TAB# #TAB# return f'_{prefix.lower()}' #LINE# #TAB# if prefix.islower(): #LINE# #TAB# #TAB# return f'{prefix.lower()}' #LINE# #TAB# return f'{prefix.lower()}'
"#LINE# #TAB# lib = None #LINE# #TAB# path = os.getcwd() #LINE# #TAB# while True: #LINE# #TAB# #TAB# try: #LINE# #TAB# #TAB# #TAB# lib = importlib.import_module('.' + path) #LINE# #TAB# #TAB# #TAB# logger.debug('Using lib %s', path) #LINE# #TAB# #TAB# except ImportError: #LINE# #TAB# #TAB# #TAB# path = os.path.dirname(path) #LINE# #TAB# #TAB# #TAB# logger.debug('Using lib %s', path) #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# return lib"
"#LINE# #TAB# sandbox_client = FluidDBClient(app, sandbox=sandbox) #LINE# #TAB# app = Flask(app) #LINE# #TAB# sandbox_client.start() #LINE# #TAB# return app"
"#LINE# #TAB# dx = x - center[0] #LINE# #TAB# dy = y - center[1] #LINE# #TAB# return dx, dy"
#LINE# #TAB# if spec.ndim == 1: #LINE# #TAB# #TAB# df = spec.copy() #LINE# #TAB# else: #LINE# #TAB# #TAB# df = spec.copy() #LINE# #TAB# df['alias'] = np.nan #LINE# #TAB# if spec.ndim == 2: #LINE# #TAB# #TAB# df['alias'] = np.nan #LINE# #TAB# else: #LINE# #TAB# #TAB# df['alias'] = np.nan #LINE# #TAB# return df
"#LINE# #TAB# if json: #LINE# #TAB# #TAB# if json_fields and 'id' in json: #LINE# #TAB# #TAB# #TAB# node = {'id': json['id'], 'label': json['label']} #LINE# #TAB# #TAB# elif 'children' in json: #LINE# #TAB# #TAB# #TAB# node = [cls.foo(child, json, json_fields) for child in node. #LINE# #TAB# #TAB# #TAB# #TAB# children] #LINE# #TAB# else: #LINE# #TAB# #TAB# node = None #LINE# #TAB# return node"
#LINE# #TAB# try: #LINE# #TAB# #TAB# return toDecode(socket.inet_aton(toDecode)) #LINE# #TAB# except Exception: #LINE# #TAB# #TAB# return toDecode
#LINE# #TAB# if operator.type == lo.VARIABLE: #LINE# #TAB# #TAB# return [operator.target] #LINE# #TAB# elif operator.type == lo.PARAM: #LINE# #TAB# #TAB# return [operator.target] #LINE# #TAB# else: #LINE# #TAB# #TAB# return []
"#LINE# #TAB# mochad_controller = hass.data[DOMAIN] #LINE# #TAB# devs = config.get(CONF_DEVICES) #LINE# #TAB# add_entities([MochadLight(hass, mochad_controller.ctrl, dev) for dev in #LINE# #TAB# #TAB# devs]) #LINE# #TAB# return True"
"#LINE# #TAB# if os.name == 'nt': #LINE# #TAB# #TAB# file_obj = io.open(file_name, 'r', newline='', encoding=encoding) #LINE# #TAB# elif encode: #LINE# #TAB# #TAB# file_obj = io.open(file_name, 'r', encoding=encoding) #LINE# #TAB# else: #LINE# #TAB# #TAB# file_obj = io.open(file_name, 'r') #LINE# #TAB# return file_obj"
"#LINE# #TAB# for i, t in enumerate(triangle_list): #LINE# #TAB# #TAB# v = lut.get(t[0], t[1]) #LINE# #TAB# #TAB# if v is not None: #LINE# #TAB# #TAB# #TAB# yield i, v"
#LINE# #TAB# for name in dir(cls): #LINE# #TAB# #TAB# if name.startswith('_') and name.endswith('__'): #LINE# #TAB# #TAB# #TAB# return True #LINE# #TAB# return False
#LINE# #TAB# spo = unpacked_spo.to_ghid() #LINE# #TAB# if spo.algo == 'zero': #LINE# #TAB# #TAB# spo.address = None #LINE# #TAB# #TAB# return spo #LINE# #TAB# else: #LINE# #TAB# #TAB# return spo
#LINE# #TAB# vtkActor = vtk.vtkActor() #LINE# #TAB# vtkActor.SetTransform(transformation) #LINE# #TAB# vtkActor.GetOutput() #LINE# #TAB# return vtkActor
#LINE# #TAB# try: #LINE# #TAB# #TAB# group_by_cluster = df.groupby(cluster_id) #LINE# #TAB# except: #LINE# #TAB# #TAB# raise Exception('Invalid cluster_id or date_col: {}'.format( #LINE# #TAB# #TAB# #TAB# cluster_id)) #LINE# #TAB# g = pd.DataFrame(group_by_cluster) #LINE# #TAB# g['date'] = df[date_col].astype(str) #LINE# #TAB# return g
#LINE# #TAB# try: #LINE# #TAB# #TAB# subprocess.check_call('namedex -h') #LINE# #TAB# except subprocess.CalledProcessError: #LINE# #TAB# #TAB# pass
"#LINE# #TAB# try: #LINE# #TAB# #TAB# traceback.print_stack() #LINE# #TAB# except Exception: #LINE# #TAB# #TAB# pass #LINE# #TAB# else: #LINE# #TAB# #TAB# L = len(frame.f_back.f_locals) #LINE# #TAB# #TAB# if L > 1: #LINE# #TAB# #TAB# #TAB# print('Traceback of %d lines: %s' % (L - 1, L)) #LINE# #TAB# #TAB# traceback.print_stack() #LINE# #TAB# #TAB# frame.f_back.f_locals = arg"
"#LINE# #TAB# v = 0 #LINE# #TAB# while True: #LINE# #TAB# #TAB# n = random.randint(1, 50) #LINE# #TAB# #TAB# v = v % 100000 #LINE# #TAB# #TAB# if v == 0: #LINE# #TAB# #TAB# #TAB# break #LINE# #TAB# return n"
"#LINE# #TAB# if isinstance(node, str): #LINE# #TAB# #TAB# node = ast.literal_eval(node) #LINE# #TAB# elif isinstance(node, dict): #LINE# #TAB# #TAB# node = dict([(key, val) for key, val in node.items()]) #LINE# #TAB# for key in headers: #LINE# #TAB# #TAB# if key in node: #LINE# #TAB# #TAB# #TAB# del node[key] #LINE# #TAB# return node"
#LINE# #TAB# if char.isdigit(): #LINE# #TAB# #TAB# return int(char) #LINE# #TAB# else: #LINE# #TAB# #TAB# return char.value
"#LINE# #TAB# if (gtype == cls.SHUFFLE or gtype == cls.ALL or gtype == cls.LOWEST or #LINE# #TAB# #TAB# gtype == cls.NONE): #LINE# #TAB# #TAB# return True #LINE# #TAB# elif isinstance(gtype, cls.FIELDS): #LINE# #TAB# #TAB# return gtype.gtype == topology_pb2.Grouping.Value('FIELDS' #LINE# #TAB# #TAB# #TAB# ) and gtype.fields is not None #LINE# #TAB# elif isinstance(gtype, cls.CUSTOM): #LINE# #TAB# #TAB# return gtype.gtype == topology_pb2.Grouping.Value('CUSTOM' #LINE# #TAB# #TAB# #TAB# ) and gtype.python_serialized is not None #LINE# #TAB# else: #LINE# #TAB# #TAB# return False"
"#LINE# #TAB# outer_indices = [] #LINE# #TAB# for tensor in all_tensors: #LINE# #TAB# #TAB# if s == tensor: #LINE# #TAB# #TAB# #TAB# continue #LINE# #TAB# #TAB# outer_indices.append(find_outer_indices(g, tensor, inputs, #LINE# #TAB# #TAB# #TAB# i1_cut_i2_wo_output, i1_union_i2)) #LINE# #TAB# return outer_indices"
"#LINE# #TAB# try: #LINE# #TAB# #TAB# value = socket.getaddrinfo(contact_point, port, socket.AF_UNSPEC, #LINE# #TAB# #TAB# #TAB# socket.SOCK_STREAM) #LINE# #TAB# #TAB# return value #LINE# #TAB# except socket.gaierror: #LINE# #TAB# #TAB# log.debug('Could not resolve hostname ""{}"" with port {}'.format( #LINE# #TAB# #TAB# #TAB# contact_point, port)) #LINE# #TAB# #TAB# return None"
"#LINE# #TAB# if Pylint is None: #LINE# #TAB# #TAB# return lambda *args, **kwargs: None #LINE# #TAB# if isinstance(args, str): #LINE# #TAB# #TAB# return lambda *args, **kwargs: True #LINE# #TAB# if isinstance(args, tuple): #LINE# #TAB# #TAB# return lambda *args, **kwargs: True #LINE# #TAB# return lambda *args, **kwargs: False"
"#LINE# #TAB# mapping = {} #LINE# #TAB# for key, val in net.items(): #LINE# #TAB# #TAB# if isinstance(val, tuple): #LINE# #TAB# #TAB# #TAB# if val[0] == 'device': #LINE# #TAB# #TAB# #TAB# #TAB# mapping[key] = True #LINE# #TAB# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# #TAB# mapping[key] = False #LINE# #TAB# return mapping"
#LINE# #TAB# result = foo.search(email) #LINE# #TAB# if result: #LINE# #TAB# #TAB# return result.group(1) #LINE# #TAB# return None
"#LINE# #TAB# if not os.path.exists(nc_filename): #LINE# #TAB# #TAB# return None #LINE# #TAB# try: #LINE# #TAB# #TAB# with open(nc_filename, 'r') as nc_file: #LINE# #TAB# #TAB# #TAB# return nc_file.read() #LINE# #TAB# except IOError: #LINE# #TAB# #TAB# logger.warning('Unable to open nc file: %s', nc_filename) #LINE# #TAB# #TAB# return None"
"#LINE# #TAB# if is_accessible: #LINE# #TAB# #TAB# start = int(start) #LINE# #TAB# if stop is None: #LINE# #TAB# #TAB# stop = start #LINE# #TAB# if step is None: #LINE# #TAB# #TAB# step = 1 #LINE# #TAB# a = [] #LINE# #TAB# for i in range(start, stop): #LINE# #TAB# #TAB# b = str(i) #LINE# #TAB# #TAB# if step == 1: #LINE# #TAB# #TAB# #TAB# a.append(b) #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# a.append(a) #LINE# #TAB# a = list(itertools.islice(a, step)) #LINE# #TAB# return a"
#LINE# #TAB# p = urlparse(url) #LINE# #TAB# if url.scheme == 'https': #LINE# #TAB# #TAB# return p.scheme + '://' + p.netloc + p.path #LINE# #TAB# else: #LINE# #TAB# #TAB# return p.path
#LINE# #TAB# if 'id' not in d: #LINE# #TAB# #TAB# return {'id': d} #LINE# #TAB# return {'id': d}
#LINE# #TAB# if name not in _group: #LINE# #TAB# #TAB# _group[name] = _Group(name) #LINE# #TAB# return _group[name]
#LINE# #TAB# for path in dist.get_metadata_paths('record-without-pyc'): #LINE# #TAB# #TAB# if os.path.isfile(path) and not path.endswith('.pyc'): #LINE# #TAB# #TAB# #TAB# yield path
"#LINE# #TAB# return {'exchange': exchange, 'queue': queue_name, 'routing': routing #LINE# #TAB# #TAB# }"
#LINE# #TAB# parts = value.split('=') #LINE# #TAB# if len(parts)!= 2: #LINE# #TAB# #TAB# return #LINE# #TAB# key = parts[0] #LINE# #TAB# if '=' not in key: #LINE# #TAB# #TAB# return #LINE# #TAB# val = parts[1] #LINE# #TAB# if val == 'true': #LINE# #TAB# #TAB# return True #LINE# #TAB# elif val == 'false': #LINE# #TAB# #TAB# return False #LINE# #TAB# return None
#LINE# #TAB# divisions = [0] #LINE# #TAB# while True: #LINE# #TAB# #TAB# try: #LINE# #TAB# #TAB# #TAB# divisions.append(num_n % divisions[0]) #LINE# #TAB# #TAB# #TAB# num_n /= divisions[1] #LINE# #TAB# #TAB# except ZeroDivisionError: #LINE# #TAB# #TAB# #TAB# return False #LINE# #TAB# return divisions[-1]
#LINE# #TAB# player_config = PlayerConfig(team=team) #LINE# #TAB# for part in player_config_path.parts[1:]: #LINE# #TAB# #TAB# if part.startswith('__'): #LINE# #TAB# #TAB# #TAB# continue #LINE# #TAB# #TAB# player_config.add_part(part) #LINE# #TAB# return player_config
"#LINE# #TAB# bot_configs = set() #LINE# #TAB# for root, dirs, files in os.walk(root_dir): #LINE# #TAB# #TAB# for filename in files: #LINE# #TAB# #TAB# #TAB# if filename.endswith('.json'): #LINE# #TAB# #TAB# #TAB# #TAB# with open(os.path.join(root, filename)) as f: #LINE# #TAB# #TAB# #TAB# #TAB# #TAB# config = json.load(f) #LINE# #TAB# #TAB# #TAB# #TAB# #TAB# bot_configs.add(config) #LINE# #TAB# return bot_configs"
#LINE# #TAB# if credentials.type_indicator in cls._credentials: #LINE# #TAB# #TAB# raise KeyError('Credential object already set for type indicator: {0:s}.' #LINE# #TAB# #TAB# #TAB#.format(credentials.type_indicator)) #LINE# #TAB# cls._credentials[credentials.type_indicator] = credentials
"#LINE# #TAB# for item in l: #LINE# #TAB# #TAB# obj = cls(item[0], item[1]) #LINE# #TAB# return obj"
"#LINE# #TAB# cipher = alg.new(c.keysize) #LINE# #TAB# plaintext = ffi.new(""TLPlaintext *"") #LINE# #TAB# buf = c.data #LINE# #TAB# while len(buf) > 0: #LINE# #TAB# #TAB# if isinstance(buf[0], bytes): #LINE# #TAB# #TAB# #TAB# buf = buf[0:len(buf) - 1] #LINE# #TAB# #TAB# plaintext.data = decr(buf) #LINE# #TAB# #TAB# buf = ffi.decompress(buf, c.key) #LINE# #TAB# return plaintext"
"#LINE# #TAB# if unit == 'pt': #LINE# #TAB# #TAB# return {'stroke_width': stroke_width, 'fcolor': fcolor, 'fill_opacity': #LINE# #TAB# #TAB# #TAB# fill_opacity} #LINE# #TAB# if contourf_idx is not None: #LINE# #TAB# #TAB# for i, contour in enumerate(contour_levels): #LINE# #TAB# #TAB# #TAB# for j, entry in enumerate(contourf_idx): #LINE# #TAB# #TAB# #TAB# #TAB# entry['stroke_width'] = stroke_width * entry['stroke_opacity'] #LINE# #TAB# #TAB# #TAB# #TAB# entry['fcolor'] = fcolor #LINE# #TAB# else: #LINE# #TAB# #TAB# return {'stroke_width': stroke_width, 'fcolor': fcolor, 'fill_opacity': #LINE# #TAB# #TAB# #TAB# fill_opacity}"
"#LINE# #TAB# try: #LINE# #TAB# #TAB# return points[:, (0)] #LINE# #TAB# except TypeError: #LINE# #TAB# #TAB# return points"
#LINE# #TAB# #TAB# obj = cls() #LINE# #TAB# #TAB# try: #LINE# #TAB# #TAB# #TAB# obj.from_bytes(data) #LINE# #TAB# #TAB# except GIError as err: #LINE# #TAB# #TAB# #TAB# raise GIError(err) #LINE# #TAB# #TAB# return obj
"#LINE# #TAB# request_hooks = [hooks.JSONErrorHook()] #LINE# #TAB# if transactional: #LINE# #TAB# #TAB# request_hooks.append(hooks.OSVmExpireTransactionHook()) #LINE# #TAB# wsgi_app = pecan.Pecan(controller or versions.AVAILABLE_VERSIONS[ #LINE# #TAB# #TAB# versions.DEFAULT_VERSION](), hooks=request_hooks, force_canonical=False #LINE# #TAB# #TAB# ) #LINE# #TAB# repositories.clear() #LINE# #TAB# return wsgi_app"
#LINE# #TAB# f0 = geno[0] #LINE# #TAB# f1 = geno[1] #LINE# #TAB# f2 = geno[2] #LINE# #TAB# return f0 + f1 + f2
"#LINE# #TAB# N = mat.shape[0] #LINE# #TAB# K = np.zeros((N, N)) #LINE# #TAB# for i in range(N): #LINE# #TAB# #TAB# for j in range(N): #LINE# #TAB# #TAB# #TAB# K[i, j] = ifft(mat[:, (i)]) #LINE# #TAB# #TAB# K[i, j] -= eps #LINE# #TAB# return K"
"#LINE# #TAB# for i, row in enumerate(cat_table): #LINE# #TAB# #TAB# if i in cuts: #LINE# #TAB# #TAB# #TAB# yield row"
"#LINE# #TAB# with open('weights.csv', 'rb') as csvfile: #LINE# #TAB# #TAB# response = HttpResponse(csvfile.read(), content_type='text/csv') #LINE# #TAB# response['Content-Disposition'] = 'attachment; filename=weights.csv' #LINE# #TAB# return response"
"#LINE# #TAB# try: #LINE# #TAB# #TAB# for k in sorted(player.history): #LINE# #TAB# #TAB# #TAB# yield (k, player.history[k]) #LINE# #TAB# except KeyError: #LINE# #TAB# #TAB# pass"
"#LINE# #TAB# for language in cls.languages: #LINE# #TAB# #TAB# for topic in cls.topics: #LINE# #TAB# #TAB# #TAB# if topic.language == language: #LINE# #TAB# #TAB# #TAB# #TAB# yield Topic(language, topic) #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# yield Language(language, None) #LINE# #TAB# for topic in cls.topics: #LINE# #TAB# #TAB# if topic.language == topic: #LINE# #TAB# #TAB# #TAB# yield Topic(topic, None) #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# yield topic"
#LINE# #TAB# if (not has_start_stop or has_start_stop['enable']): #LINE# #TAB# #TAB# return g.default_start_stop_activation_time_threshold #LINE# #TAB# return g.default_start_stop_activation_time_threshold
#LINE# #TAB# user = context['request'].user #LINE# #TAB# if article: #LINE# #TAB# #TAB# categories = article.categories.all() #LINE# #TAB# else: #LINE# #TAB# #TAB# categories = Category.objects.all() #LINE# #TAB# if limit: #LINE# #TAB# #TAB# categories = categories[:limit] #LINE# #TAB# return categories
#LINE# #TAB# s = 0 #LINE# #TAB# if pos[0] == 0: #LINE# #TAB# #TAB# return 1 #LINE# #TAB# elif pos[0] == 1: #LINE# #TAB# #TAB# return 2 #LINE# #TAB# elif pos[0] == 2: #LINE# #TAB# #TAB# return 3 #LINE# #TAB# elif pos[0] == 3: #LINE# #TAB# #TAB# return 4 #LINE# #TAB# elif pos[0] == 3: #LINE# #TAB# #TAB# return 5
#LINE# #TAB# global _nurbsRenderer #LINE# #TAB# if _nurbsRenderer is None: #LINE# #TAB# #TAB# _nurbsRenderer = baseFunction() #LINE# #TAB# return _nurbsRenderer
"#LINE# #TAB# obj = Rule(name, table.name, inobj.pop('description', None), inobj. #LINE# #TAB# #TAB# pop('owner', None), inobj.pop('privileges', []), inobj.pop( #LINE# #TAB# #TAB# 'ruleset', []), inobj.pop('handler', None), inobj.pop( #LINE# #TAB# #TAB# 'validator', None)) #LINE# #TAB# obj.fix_privileges() #LINE# #TAB# obj.set_oldname(inobj) #LINE# #TAB# return obj"
"#LINE# #TAB# for t in dx_nodes: #LINE# #TAB# #TAB# if t in dx_node.children: #LINE# #TAB# #TAB# #TAB# yield t #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# for e in foo(dx_nodes, dx_node): #LINE# #TAB# #TAB# #TAB# #TAB# yield e"
"#LINE# #TAB# a1, a2 = a #LINE# #TAB# other1, other2 = other #LINE# #TAB# overlap = np.zeros_like(particle) #LINE# #TAB# for i in range(len(other)): #LINE# #TAB# #TAB# a1 = particle[i] #LINE# #TAB# #TAB# a2 = particle[i] #LINE# #TAB# #TAB# other1 = other[i] #LINE# #TAB# #TAB# overlap[i] = foo(a1, a2, other1, side, normalize=normalize) #LINE# #TAB# return overlap"
"#LINE# #TAB# data = refs.create_ref(profile, name, sha) #LINE# #TAB# data.update({ #LINE# #TAB# #TAB# 'op':'move', #LINE# #TAB# #TAB# 'branch': data.get('branch'), #LINE# #TAB# #TAB#'sha': sha #LINE# #TAB# }) #LINE# #TAB# return data"
#LINE# #TAB# result = '' #LINE# #TAB# for c in name.upper(): #LINE# #TAB# #TAB# if c.isupper(): #LINE# #TAB# #TAB# #TAB# result += '_' + c.lower() #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# result += c #LINE# #TAB# return result
#LINE# #TAB# if token is not None: #LINE# #TAB# #TAB# auth = {'Authorization': 'Bearer {}'.format(token)} #LINE# #TAB# else: #LINE# #TAB# #TAB# auth = {} #LINE# #TAB# return auth
"#LINE# #TAB# base = '%s.%s' % (model_name, name) #LINE# #TAB# for base_name in model_name.split('.'): #LINE# #TAB# #TAB# base = '%s.%s' % (base, base_name) #LINE# #TAB# return base"
#LINE# #TAB# res = [] #LINE# #TAB# for t in x: #LINE# #TAB# #TAB# if t == '': #LINE# #TAB# #TAB# #TAB# continue #LINE# #TAB# #TAB# if t[0].isupper() and len(t) > 1 and t[1:].islower(): #LINE# #TAB# #TAB# #TAB# res.append(TK_MAJ) #LINE# #TAB# #TAB# res.append(t.lower()) #LINE# #TAB# return res
"#LINE# #TAB# x = np.arange(num_images) / num_images #LINE# #TAB# y = np.arange(num_images) / num_images #LINE# #TAB# return [x, y]"
"#LINE# #TAB# with open(file_path, 'rb') as fh: #LINE# #TAB# #TAB# clf = pickle.load(fh) #LINE# #TAB# _LOGGER.info('Loaded classifier from ""%s"".', file_path) #LINE# #TAB# return clf"
"#LINE# #TAB# #TAB# separator = '=' #LINE# #TAB# #TAB# result = {} #LINE# #TAB# #TAB# for line in cls._parse_list(value): #LINE# #TAB# #TAB# #TAB# key, sep, val = line.partition(separator) #LINE# #TAB# #TAB# #TAB# if sep!= separator: #LINE# #TAB# #TAB# #TAB# #TAB# raise DistutilsOptionError( #LINE# #TAB# #TAB# #TAB# #TAB# #TAB# 'Unable to parse option value to dict: %s' % value) #LINE# #TAB# #TAB# #TAB# result[key.strip()] = val.strip() #LINE# #TAB# #TAB# return result"
"#LINE# #TAB# return [IdentityRefWithVote(ref, team_instance) for ref in reviewers for #LINE# #TAB# #TAB# identity in reviewers if identity.ref.team == team_instance]"
"#LINE# #TAB# resource_filename = _foo(resource_id) #LINE# #TAB# if resource_filename is not None: #LINE# #TAB# #TAB# return os.path.join(resource_filename, resource_id) #LINE# #TAB# return None"
"#LINE# #TAB# if isinstance(t[1], str): #LINE# #TAB# #TAB# t[1] = t[1].splitlines() #LINE# #TAB# elif isinstance(t[1], list): #LINE# #TAB# #TAB# assert len(t) == 3 #LINE# #TAB# #TAB# t[1] = t[1] + [t[2]] #LINE# #TAB# elif isinstance(t[1], tuple): #LINE# #TAB# #TAB# assert len(t[1]) == len(t[3]) #LINE# #TAB# else: #LINE# #TAB# #TAB# assert False"
#LINE# #TAB# o1 = cor_norm_rot[0] #LINE# #TAB# o2 = cor_norm_rot[1] #LINE# #TAB# if o1 < 0: #LINE# #TAB# #TAB# return 1 #LINE# #TAB# elif o2 < 0: #LINE# #TAB# #TAB# return -1 #LINE# #TAB# else: #LINE# #TAB# #TAB# return 1
#LINE# #TAB# res = get_key(secret_key) #LINE# #TAB# return res
"#LINE# #TAB# with settings(hide('running','stdout','stderr', 'warnings'), #LINE# #TAB# #TAB# warn_only=True): #LINE# #TAB# #TAB# output = subprocess.check_output(['git','status', '--porcelain'], #LINE# #TAB# #TAB# #TAB# universal_newlines=True) #LINE# #TAB# #TAB# if output.strip() == 'yes': #LINE# #TAB# #TAB# #TAB# return 0 #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# return 1"
#LINE# #TAB# try: #LINE# #TAB# #TAB# os.makedirs(dir) #LINE# #TAB# except OSError as exc: #LINE# #TAB# #TAB# if exc.errno == errno.EEXIST: #LINE# #TAB# #TAB# #TAB# pass #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# raise
"#LINE# #TAB# customer = Contact(name=name, email=email, phone=phone) #LINE# #TAB# customer.save() #LINE# #TAB# return customer"
#LINE# #TAB# padding = 0 #LINE# #TAB# n = len(node) #LINE# #TAB# while n > 0: #LINE# #TAB# #TAB# if n % 2 == 0: #LINE# #TAB# #TAB# #TAB# padding += 1 #LINE# #TAB# #TAB# n -= 1 #LINE# #TAB# return padding
#LINE# #TAB# import os #LINE# #TAB# try: #LINE# #TAB# #TAB# os.remove(ENTRY_FILE) #LINE# #TAB# except FileNotFoundError: #LINE# #TAB# #TAB# pass
#LINE# #TAB# handler = logging.StreamHandler() #LINE# #TAB# handler.setLevel(logging.DEBUG) #LINE# #TAB# formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s') #LINE# #TAB# handler.setFormatter(formatter) #LINE# #TAB# logger.addHandler(handler) #LINE# #TAB# logger.setLevel(logging.INFO) #LINE# #TAB# return logger
#LINE# #TAB# if data is None: #LINE# #TAB# #TAB# return None #LINE# #TAB# else: #LINE# #TAB# #TAB# try: #LINE# #TAB# #TAB# #TAB# return str(data) #LINE# #TAB# #TAB# except ValueError: #LINE# #TAB# #TAB# #TAB# all_lower = [x.lower() for x in data.lower() if x.islower()] #LINE# #TAB# #TAB# #TAB# if len(all_lower) > 0: #LINE# #TAB# #TAB# #TAB# #TAB# return all_lower[0] #LINE# #TAB# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# #TAB# return None
#LINE# #TAB# if up: #LINE# #TAB# #TAB# return [Architecture(i) for i in arch.ARCHES] #LINE# #TAB# else: #LINE# #TAB# #TAB# return [Architecture(i) for i in arch.ARCHES]
"#LINE# #TAB# arg_names = [] #LINE# #TAB# for name, value in argument_spec.items(): #LINE# #TAB# #TAB# if isinstance(value, tuple): #LINE# #TAB# #TAB# #TAB# arg_names += value #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# arg_names.append(name) #LINE# #TAB# return arg_names"
"#LINE# #TAB# import pandas as pd #LINE# #TAB# if isinstance(samples[0], pd.Series): #LINE# #TAB# #TAB# samples = [samples] #LINE# #TAB# if ""samtools"" not in samples[0]: #LINE# #TAB# #TAB# samples.append(""samtools"") #LINE# #TAB# for data in samples: #LINE# #TAB# #TAB# for k, v in six.iteritems(data): #LINE# #TAB# #TAB# #TAB# if isinstance(v, pd.Series): #LINE# #TAB# #TAB# #TAB# #TAB# data[k] = foo(v) #LINE# #TAB# #TAB# #TAB# #TAB# continue #LINE# #TAB# #TAB# #TAB# samples.append(data) #LINE# #TAB# return samples"
"#LINE# #TAB# return {'zzz_subversionPage': [QCoreApplication.translate('VcsPySvnPlugin', #LINE# #TAB# #TAB# 'Subversion'), os.path.join('VcsPlugins', 'vcsPySvn', 'icons', #LINE# #TAB# #TAB# 'preferences-subversion.svg'), createConfigurationPage, 'vcsPage', None]}"
#LINE# #TAB# ret = '' #LINE# #TAB# for c in seq: #LINE# #TAB# #TAB# if c in '{': #LINE# #TAB# #TAB# #TAB# ret +='' #LINE# #TAB# #TAB# elif c == '{': #LINE# #TAB# #TAB# #TAB# ret += '}}' #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# ret += c #LINE# #TAB# return ret
#LINE# #TAB# for item in iterator: #LINE# #TAB# #TAB# if item!= step: #LINE# #TAB# #TAB# #TAB# yield item
#LINE# #TAB# df = pd.DataFrame(data) #LINE# #TAB# for i in range(len(df)): #LINE# #TAB# #TAB# df[i] = df[i].astype(float) #LINE# #TAB# return df
"#LINE# #TAB# df = pd.read_csv(filename, sep='\t', header=None, usecols=[0, 1, 2], #LINE# #TAB# #TAB# names=['chrom', 'pos', 'genotype']) #LINE# #TAB# if 'chrom' not in df.columns: #LINE# #TAB# #TAB# table = 'chrom' #LINE# #TAB# #TAB# df['chrom'] = df['chrom'].astype(str) #LINE# #TAB# #TAB# df['pos'] = df['chrom'].astype(str) #LINE# #TAB# #TAB# df['genotype'] = df['chrom'].astype(str) #LINE# #TAB# return df"
"#LINE# #TAB# with open('src/robotide/editor/tags.py', 'r') as f: #LINE# #TAB# #TAB# f.read() #LINE# #TAB# #TAB# for line in f.readlines(): #LINE# #TAB# #TAB# #TAB# if line.startswith('#'): #LINE# #TAB# #TAB# #TAB# #TAB# continue #LINE# #TAB# #TAB# #TAB# line = line.replace('\n', '') #LINE# #TAB# #TAB# #TAB# print(line) #LINE# #TAB# #TAB# return"
"#LINE# #TAB# val = VarInt(raw_hex[2:], 16) #LINE# #TAB# val |= val >> 8 & 255 #LINE# #TAB# val |= val >> 16 & 255 #LINE# #TAB# return val"
"#LINE# #TAB# if type(obj) == list: #LINE# #TAB# #TAB# return ', '.join([repr(i) for i in obj]) #LINE# #TAB# if type(obj) == tuple: #LINE# #TAB# #TAB# return ','.join([repr(i) for i in obj]) #LINE# #TAB# if type(obj) == dict: #LINE# #TAB# #TAB# return repr(obj) #LINE# #TAB# for name, val in obj.items(): #LINE# #TAB# #TAB# if type(val) == dict: #LINE# #TAB# #TAB# #TAB# return repr(val) #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# return '%s: %s' % (name, val) #LINE# #TAB# elif type(obj) == list: #LINE# #TAB# #TAB# return ','.join([repr(i) for i in obj]) #LINE# #TAB# else: #LINE# #TAB# #TAB# return repr(obj)"
"#LINE# #TAB# for suffix in ['complex', 'complex-complex']: #LINE# #TAB# #TAB# name = name.replace(suffix, '') #LINE# #TAB# return name"
"#LINE# #TAB# if not condition: #LINE# #TAB# #TAB# return True #LINE# #TAB# elif isinstance(condition, dict): #LINE# #TAB# #TAB# for keypath, value in condition.items(): #LINE# #TAB# #TAB# #TAB# if not value: #LINE# #TAB# #TAB# #TAB# #TAB# return False #LINE# #TAB# #TAB# #TAB# for keypath_path, value in user.items(): #LINE# #TAB# #TAB# #TAB# #TAB# if keypath_path in value: #LINE# #TAB# #TAB# #TAB# #TAB# #TAB# return keypath #LINE# #TAB# else: #LINE# #TAB# #TAB# pass #LINE# #TAB# return True"
#LINE# #TAB# for k in dict_a: #LINE# #TAB# #TAB# if k in dict_b: #LINE# #TAB# #TAB# #TAB# dict_a[k] = dict_b[k] #LINE# #TAB# #TAB# elif k in dict_b: #LINE# #TAB# #TAB# #TAB# dict_b[k] = dict_a[k] + dict_b[k] #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# dict_a[k] = dict_b[k] #LINE# #TAB# return dict_a
"#LINE# #TAB# time_codes, titles, url = str_input.split(',') #LINE# #TAB# res = {'time_codes': time_codes, 'titles': titles, 'url': url} #LINE# #TAB# if len(time_codes) == 1: #LINE# #TAB# #TAB# res['time_codes'] = int(time_codes[0]) #LINE# #TAB# if len(titles) == 1: #LINE# #TAB# #TAB# res['titles'] = int(titles[0]) #LINE# #TAB# return res"
#LINE# #TAB# try: #LINE# #TAB# #TAB# r = requests.get(url) #LINE# #TAB# #TAB# return r.json()['workid'] #LINE# #TAB# except: #LINE# #TAB# #TAB# return None
"#LINE# #TAB# n_samples = MI_FS.n_samples(k) #LINE# #TAB# if n_jobs < 1: #LINE# #TAB# #TAB# parallel_F = Parallel(n_jobs)(delayed(_bar, MI_FS)(f, s, are_data_binned) for f in #LINE# #TAB# #TAB# #TAB# F) #LINE# #TAB# else: #LINE# #TAB# #TAB# parallel_F = Parallel(n_jobs)(delayed(_bar, MI_FS)(f, s, are_data_binned) for f in #LINE# #TAB# #TAB# #TAB# F) #LINE# #TAB# #TAB# parallel_F = Parallel(n_jobs)(delayed(_bar, MI_FS)(f, s, are_data_binned) for f in #LINE# #TAB# #TAB# #TAB# Parallel(n_jobs)(f, s, are_data_binned)) #LINE# #TAB# return parallel_F"
"#LINE# #TAB# if re_foo.search(logical_line): #LINE# #TAB# #TAB# yield 0, 'S360: Overridden default argument in sahara code'"
"#LINE# #TAB# logger.info('Parsing degradations args: %s', degradations_args) #LINE# #TAB# degradations = [] #LINE# #TAB# for degradation_args in degradations_args: #LINE# #TAB# #TAB# degradation_args = degradation_args.split(',') #LINE# #TAB# #TAB# degradations.append(Degradation(**degradation_args)) #LINE# #TAB# return degradations"
"#LINE# #TAB# references = [] #LINE# #TAB# ref_finder = HTMLReferenceFinder(xml) #LINE# #TAB# for elm, tag in ref_finder: #LINE# #TAB# #TAB# references.append(Reference(elm, tag)) #LINE# #TAB# return references"
"#LINE# #TAB# from matplotlib import figure #LINE# #TAB# width, height = figure().get_size_inches() #LINE# #TAB# golden_ratio = figwidth / height #LINE# #TAB# return width, golden_ratio"
#LINE# #TAB# result = 0 #LINE# #TAB# for item in iterable: #LINE# #TAB# #TAB# if filter_function(item): #LINE# #TAB# #TAB# #TAB# result += 1 #LINE# #TAB# return result
"#LINE# #TAB# for key in dictionary: #LINE# #TAB# #TAB# if isinstance(dictionary[key], str): #LINE# #TAB# #TAB# #TAB# dictionary[key] = re.sub('(?<=\\[)(.*?)(?=\\])', '\\1', dictionary[key]) #LINE# #TAB# return dictionary"
#LINE# #TAB# all_images = pbclient.list_images() #LINE# #TAB# matching = [x for x in all_images['items'] if x['properties']['name'] == #LINE# #TAB# #TAB# image_name] #LINE# #TAB# return matching
"#LINE# #TAB# rot = np.array([[0, 0, 0], [0, np.sin(2 * np.pi / 180.0), -np.cos(2 * #LINE# #TAB# #TAB# np.pi / 180.0), 0], [0, np.sin(2 * np.pi / 180.0), np.cos(2 * np.pi / #LINE# #TAB# #TAB# 180.0)]]) #LINE# #TAB# return rot"
"#LINE# #TAB# if arrays is None: #LINE# #TAB# #TAB# arrays = [] #LINE# #TAB# for s in ss: #LINE# #TAB# #TAB# try: #LINE# #TAB# #TAB# #TAB# yield '{0} = {1}'.format(s, arrays[s]) #LINE# #TAB# #TAB# except: #LINE# #TAB# #TAB# #TAB# for a in arrays: #LINE# #TAB# #TAB# #TAB# #TAB# yield '{0} = {1}'.format(s, a) #LINE# #TAB# #TAB# except: #LINE# #TAB# #TAB# #TAB# for a in arrays: #LINE# #TAB# #TAB# #TAB# #TAB# yield '{0} = {1}'.format(s, a) #LINE# #TAB# return"
"#LINE# #TAB# username = context.get('username') #LINE# #TAB# password = context.get('password') #LINE# #TAB# return {'username': username, 'password': password}"
#LINE# #TAB# auth = keystoneclient() #LINE# #TAB# auth.username = cloud_name #LINE# #TAB# auth.password = cloud_name #LINE# #TAB# return auth
#LINE# #TAB# if ctx.obj.get('keep_files'): #LINE# #TAB# #TAB# files = ctx.obj['files'] #LINE# #TAB# #TAB# val = [] #LINE# #TAB# #TAB# for f in files: #LINE# #TAB# #TAB# #TAB# val.append(f) #LINE# #TAB# #TAB# if'multiple=' in s: #LINE# #TAB# #TAB# #TAB# for i in s: #LINE# #TAB# #TAB# #TAB# #TAB# val.append(i) #LINE# #TAB# #TAB# if len(val) == 1: #LINE# #TAB# #TAB# #TAB# return val[0] #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# return val #LINE# #TAB# else: #LINE# #TAB# #TAB# return s
"#LINE# #TAB# n_train = trainX.shape[0] #LINE# #TAB# out = np.zeros(n_train) #LINE# #TAB# for i in range(n_train): #LINE# #TAB# #TAB# enc = encoders[i] #LINE# #TAB# #TAB# for j in range(i + 1, n_train): #LINE# #TAB# #TAB# #TAB# tmp = np.percentile(enc.values, percentile) #LINE# #TAB# #TAB# #TAB# if np.sum(tmp < 0) == 0: #LINE# #TAB# #TAB# #TAB# #TAB# out[i][j] = 0 #LINE# #TAB# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# #TAB# out[i][j] = 0 #LINE# #TAB# return out"
"#LINE# #TAB# if len(tok) == 4: #LINE# #TAB# #TAB# tok[0] = LogicalBinOpRule(tok[2], tok[1], tok[3]) #LINE# #TAB# else: #LINE# #TAB# #TAB# tok[0] = tok[1] #LINE# #TAB# return tok"
"#LINE# #TAB# with open(filename) as fp: #LINE# #TAB# #TAB# rawdata = fp.read() #LINE# #TAB# _counter = Counter(rawdata) #LINE# #TAB# if _counter.most_common() > 0: #LINE# #TAB# #TAB# status = reg_error #LINE# #TAB# elif _counter.most_common() < 0: #LINE# #TAB# #TAB# status = reg_score #LINE# #TAB# else: #LINE# #TAB# #TAB# status = reg_warning #LINE# #TAB# if status!= 0: #LINE# #TAB# #TAB# click.secho('Linting {0} matches {1} for {2}'.format(reg_score, #LINE# #TAB# #TAB# #TAB# reg_warning, reg_error), fg='red') #LINE# #TAB# else: #LINE# #TAB# #TAB# click.secho('Linting {0} for {1}'.format(filename, _counter)) #LINE# #TAB# return status"
"#LINE# #TAB# if filename is None: #LINE# #TAB# #TAB# filename = url.split('?')[1] + '.png' #LINE# #TAB# if cache_dir is None: #LINE# #TAB# #TAB# os.makedirs(cache_dir) #LINE# #TAB# cache_file = os.path.join(cache_dir, filename) #LINE# #TAB# if not os.path.isfile(cache_file): #LINE# #TAB# #TAB# with open(cache_file, 'wb') as f: #LINE# #TAB# #TAB# #TAB# pickle.dump(url, f) #LINE# #TAB# #TAB# image = cls.from_file(cache_file) #LINE# #TAB# #TAB# image.save() #LINE# #TAB# else: #LINE# #TAB# #TAB# image = cls.from_url(url) #LINE# #TAB# #TAB# image.save() #LINE# #TAB# return image"
"#LINE# #TAB# if len(hosts_and_ports) == 1: #LINE# #TAB# #TAB# hosts, ports = hosts_and_ports #LINE# #TAB# elif len(hosts_and_ports) == 2: #LINE# #TAB# #TAB# hosts, ports = hosts_and_ports #LINE# #TAB# k = 0 #LINE# #TAB# for i, (host, port) in enumerate(ports): #LINE# #TAB# #TAB# if host == i: #LINE# #TAB# #TAB# #TAB# k += 1 #LINE# #TAB# #TAB# elif port == -1: #LINE# #TAB# #TAB# #TAB# k += 2 #LINE# #TAB# return hosts, ports"
"#LINE# #TAB# assert type(in_file_list) == list #LINE# #TAB# assert type(out_file) == str #LINE# #TAB# out_file += '.vrt' #LINE# #TAB# with open(out_file, 'w') as out_handle: #LINE# #TAB# #TAB# for in_file in in_file_list: #LINE# #TAB# #TAB# #TAB# with open(in_file, 'r') as in_file: #LINE# #TAB# #TAB# #TAB# #TAB# in_file.write(in_file.read()) #LINE# #TAB# return out_file"
"#LINE# #TAB# scenarios = [] #LINE# #TAB# with open(scencmd, 'r') as f: #LINE# #TAB# #TAB# for line in f: #LINE# #TAB# #TAB# #TAB# line = line.strip() #LINE# #TAB# #TAB# #TAB# if not line or line.startswith('#'): #LINE# #TAB# #TAB# #TAB# #TAB# continue #LINE# #TAB# #TAB# #TAB# scenarios.append((scentime, line)) #LINE# #TAB# return scenarios"
"#LINE# #TAB# packages = [] #LINE# #TAB# for d in os.listdir(os.getcwd()): #LINE# #TAB# #TAB# if d.startswith('.'): #LINE# #TAB# #TAB# #TAB# continue #LINE# #TAB# #TAB# if isdir(join(d, '__init__.py')): #LINE# #TAB# #TAB# #TAB# return [] #LINE# #TAB# #TAB# for f in os.listdir(join(d, '__init__.py')): #LINE# #TAB# #TAB# #TAB# if isfile(join(d, f)): #LINE# #TAB# #TAB# #TAB# #TAB# packages.append(f) #LINE# #TAB# return packages"
#LINE# #TAB# count = counts.copy() #LINE# #TAB# for i in range(len(counts)): #LINE# #TAB# #TAB# if observable[i]!= 0: #LINE# #TAB# #TAB# #TAB# count[i] += 1 #LINE# #TAB# return count / observable.sum()[0]
"#LINE# #TAB# if url.startswith(""#""): #LINE# #TAB# #TAB# return False #LINE# #TAB# if url.find(""://"") > 0 or url.startswith(""//""): #LINE# #TAB# #TAB# return True #LINE# #TAB# return False"
#LINE# #TAB# if abs(sync[1]) <= 150: #LINE# #TAB# #TAB# return True #LINE# #TAB# else: #LINE# #TAB# #TAB# return False
"#LINE# #TAB# if re.match(IPv4_REGEX, ip): #LINE# #TAB# #TAB# return ip #LINE# #TAB# elif re.match(IPv6_REGEX, ip): #LINE# #TAB# #TAB# return ip #LINE# #TAB# return False"
#LINE# #TAB# if argument is not None and argument == 'None': #LINE# #TAB# #TAB# return default #LINE# #TAB# else: #LINE# #TAB# #TAB# return argument
#LINE# #TAB# if serialized: #LINE# #TAB# #TAB# try: #LINE# #TAB# #TAB# #TAB# return json.loads(serialized.strip()) #LINE# #TAB# #TAB# except ValueError: #LINE# #TAB# #TAB# #TAB# pass #LINE# #TAB# return None
#LINE# #TAB# if y is None: #LINE# #TAB# #TAB# raise ValueError('Labels must not be None!') #LINE# #TAB# return y * 2 - 1
#LINE# #TAB# for volume in volumes: #LINE# #TAB# #TAB# container = volumes[volume]['container'] #LINE# #TAB# #TAB# if container not in os.listdir(container): #LINE# #TAB# #TAB# #TAB# os.mkdir(container) #LINE# #TAB# #TAB# yield container
"#LINE# #TAB# if isinstance(value, six.text_type): #LINE# #TAB# #TAB# return value.encode('utf-8') #LINE# #TAB# return value"
"#LINE# #TAB# ifartist == title: #LINE# #TAB# #TAB# return get_tempo() #LINE# #TAB# else: #LINE# #TAB# #TAB# return {'artist': artist, 'title': title}"
#LINE# #TAB# if key =='status': #LINE# #TAB# #TAB# return 'ok' #LINE# #TAB# elif key == 'created': #LINE# #TAB# #TAB# return 'created' #LINE# #TAB# elif key == 'updated': #LINE# #TAB# #TAB# return 'updated' #LINE# #TAB# else: #LINE# #TAB# #TAB# return 'error'
"#LINE# #TAB# if not isinstance(templates, (list, tuple)): #LINE# #TAB# #TAB# templates = [templates] #LINE# #TAB# device = device_from_request(request) #LINE# #TAB# template_names = [] #LINE# #TAB# for template in templates: #LINE# #TAB# #TAB# if device: #LINE# #TAB# #TAB# #TAB# template_names.append('%s/%s' % (device, template)) #LINE# #TAB# #TAB# template_names.append(template) #LINE# #TAB# return template_names"
#LINE# #TAB# for rxn in model.reactions: #LINE# #TAB# #TAB# yield rxn
"#LINE# #TAB# devices = [] #LINE# #TAB# with open('/sys/class/devices/device_info', 'r') as fh: #LINE# #TAB# #TAB# for line in fh: #LINE# #TAB# #TAB# #TAB# if 'btc' in line.lower(): #LINE# #TAB# #TAB# #TAB# #TAB# devices.append(DeviceInfo(line.split()[0])) #LINE# #TAB# #TAB# for line in fh: #LINE# #TAB# #TAB# #TAB# if 'device_addr' in line.lower(): #LINE# #TAB# #TAB# #TAB# #TAB# devices.append(DeviceInfo(line.split()[0])) #LINE# #TAB# #TAB# #TAB# if 'device_addr' not in devices: #LINE# #TAB# #TAB# #TAB# #TAB# devices.append(DeviceInfo(line.split()[0])) #LINE# #TAB# return devices"
#LINE# #TAB# global SEP #LINE# #TAB# if type: #LINE# #TAB# #TAB# return SEP[type]
#LINE# #TAB# data = [] #LINE# #TAB# for _ in range(count): #LINE# #TAB# #TAB# group = foo(()) #LINE# #TAB# #TAB# data.append(group) #LINE# #TAB# return data
#LINE# #TAB# if layer.keywords['exposure_class'] is None: #LINE# #TAB# #TAB# layer.keywords['exposure_class'] = 'exposure'
#LINE# #TAB# if a == 1: #LINE# #TAB# #TAB# return 1 #LINE# #TAB# elif a % p == 0: #LINE# #TAB# #TAB# for i in range(p): #LINE# #TAB# #TAB# #TAB# if a % i == 0: #LINE# #TAB# #TAB# #TAB# #TAB# return 1 #LINE# #TAB# #TAB# return -1 #LINE# #TAB# else: #LINE# #TAB# #TAB# return 0
#LINE# #TAB# try: #LINE# #TAB# #TAB# np.linalg.cholesky(cm) #LINE# #TAB# except np.linalg.LinAlgError: #LINE# #TAB# #TAB# return False #LINE# #TAB# else: #LINE# #TAB# #TAB# return True
#LINE# #TAB# rid = rid or action['rid'] #LINE# #TAB# unit = unit or action['unit'] #LINE# #TAB# try: #LINE# #TAB# #TAB# res = action['broker']['status'][rid][unit]['completed'] #LINE# #TAB# except KeyError: #LINE# #TAB# #TAB# res = False #LINE# #TAB# return res
"#LINE# #TAB# return [(f[0], f[1]) for f in list(flag_dict.items()) if isinstance(f[0 #LINE# #TAB# #TAB# ], (str, bytes)) and f[0].startswith(flag_filter)]"
#LINE# #TAB# if rand: #LINE# #TAB# #TAB# stat_id = str(stat) #LINE# #TAB# else: #LINE# #TAB# #TAB# stat_id = str(stat) #LINE# #TAB# stat['stat_id'] = stat_id #LINE# #TAB# stat['values'] = [val] #LINE# #TAB# return stat
#LINE# #TAB# if not pnr.isdigit(): #LINE# #TAB# #TAB# raise ValueError('incorrect pnr: %s' % pnr) #LINE# #TAB# if not pnr.isdigit(): #LINE# #TAB# #TAB# raise ValueError('incorrect pnr: %s' % pnr) #LINE# #TAB# return pnr
"#LINE# #TAB# return [f for f in os.listdir(plugin_dir) if os.path.isdir(os.path. #LINE# #TAB# #TAB# join(plugin_dir, f)) and not f.startswith('_')]"
"#LINE# #TAB# if use_orig_distr: #LINE# #TAB# #TAB# values = _orig_distr(values) #LINE# #TAB# hist, bin_edges = np.histogram(values, edges=edges) #LINE# #TAB# bin_values = np.bincount(bin_edges) #LINE# #TAB# density = np.sum(bin_values) / np.sum(bin_edges) #LINE# #TAB# return density"
"#LINE# #TAB# try: #LINE# #TAB# #TAB# return val.replace('_', '_') #LINE# #TAB# except ValueError: #LINE# #TAB# #TAB# return val"
"#LINE# #TAB# import warnings #LINE# #TAB# warnings.warn(' '.join(['phantom', 'freq_offset', 'loc_ind']), DeprecationWarning, #LINE# #TAB# #TAB# stacklevel=2) #LINE# #TAB# from. import Signal #LINE# #TAB# signal = Signal() #LINE# #TAB# for i, (loc_i, _) in enumerate(loc_ind): #LINE# #TAB# #TAB# f = Signal(loc_i, _, freq_offset) #LINE# #TAB# #TAB# signal += phantom * f #LINE# #TAB# #TAB# signal = signal[:] #LINE# #TAB# return signal"
"#LINE# #TAB# dict = {} #LINE# #TAB# for w in words: #LINE# #TAB# #TAB# words = re.sub(r'[^a-zA-Z0-9]', '', w) #LINE# #TAB# #TAB# words = re.sub(r'[^a-zA-Z0-9]', '', w) #LINE# #TAB# #TAB# words = re.sub(r'[^a-zA-Z0-9]', '', words) #LINE# #TAB# #TAB# indices = [(i, j) for i, j in enumerate(words)] #LINE# #TAB# #TAB# dict['words'] = words #LINE# #TAB# #TAB# dict['indices'] = indices #LINE# #TAB# if minimize_indices: #LINE# #TAB# #TAB# dict['minimize_indices'] = True #LINE# #TAB# return dict"
"#LINE# #TAB# if not retries: #LINE# #TAB# #TAB# return {} #LINE# #TAB# retries = {k: v for k, v in retries.items() if isinstance(v, dict)} #LINE# #TAB# for k, v in retries.items(): #LINE# #TAB# #TAB# if isinstance(v, dict): #LINE# #TAB# #TAB# #TAB# retries[k] = RetryConfig.from_json(v) #LINE# #TAB# #TAB# elif isinstance(v, list): #LINE# #TAB# #TAB# #TAB# retries[k] = [RetryConfig.from_json(v) for v in v] #LINE# #TAB# return retries"
"#LINE# #TAB# with open(path, 'r') as f: #LINE# #TAB# #TAB# f.readline() #LINE# #TAB# #TAB# if f.readline().startswith('# THERAPIST'): #LINE# #TAB# #TAB# #TAB# return f.readline().split()[2]"
"#LINE# #TAB# import registry #LINE# #TAB# shell_name = registry.GetValue(csidl_name,'shell') #LINE# #TAB# if shell_name.startswith('CSIDL_'): #LINE# #TAB# #TAB# csidl_value = registry.GetValue(csidl_name, 'value') #LINE# #TAB# else: #LINE# #TAB# #TAB# csidl_value = registry.QueryValue(csidl_name, 'value') #LINE# #TAB# return csidl_value"
#LINE# #TAB# os.environ['DJANGO_SETTINGS_MODULE'] = 'jukeboxcore.djsettings' #LINE# #TAB# os.environ['JUKEBOX_SETTINGS_MODULE'] = 'jukeboxcore.djsettings' #LINE# #TAB# env = os.environ.copy() #LINE# #TAB# env['PATH'] = path #LINE# #TAB# if 'JUKEBOX_SETTINGS_MODULE' in os.environ: #LINE# #TAB# #TAB# del os.environ['JUKEBOX_SETTINGS_MODULE']
"#LINE# #TAB# if not salt.utils.path.isfile(infile): #LINE# #TAB# #TAB# raise ValueError(""file not found: {0}"".format(infile)) #LINE# #TAB# with salt.utils.files.fopen(infile) as in_handle: #LINE# #TAB# #TAB# for line in in_handle: #LINE# #TAB# #TAB# #TAB# if line.startswith(""#""): #LINE# #TAB# #TAB# #TAB# #TAB# continue #LINE# #TAB# #TAB# #TAB# line = line.strip() #LINE# #TAB# #TAB# #TAB# if not line: #LINE# #TAB# #TAB# #TAB# #TAB# continue #LINE# #TAB# #TAB# #TAB# yield line"
#LINE# #TAB# for extension_name in extension_names: #LINE# #TAB# #TAB# try: #LINE# #TAB# #TAB# #TAB# mod = importlib.import_module('extensions.' + extension_name) #LINE# #TAB# #TAB# #TAB# mod.activate() #LINE# #TAB# #TAB# except ImportError as e: #LINE# #TAB# #TAB# #TAB# if verbose: #LINE# #TAB# #TAB# #TAB# #TAB# print(e) #LINE# #TAB# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# #TAB# raise e
#LINE# #TAB# if limit: #LINE# #TAB# #TAB# try: #LINE# #TAB# #TAB# #TAB# qs = qs.limit(limit) #LINE# #TAB# #TAB# except ValueError: #LINE# #TAB# #TAB# #TAB# raise ValueError('Limit can not be greater than 0') #LINE# #TAB# g = Graph() #LINE# #TAB# g.type = 'object' #LINE# #TAB# g.object_list = qs #LINE# #TAB# g.limit = limit #LINE# #TAB# return g
"#LINE# #TAB# temp = np.zeros(num_samples) #LINE# #TAB# for i in range(num_samples): #LINE# #TAB# #TAB# temp[i] = randint(1, widths[i]) #LINE# #TAB# return temp"
#LINE# #TAB# for node in graph.nodes(): #LINE# #TAB# #TAB# if node in initial_guess: #LINE# #TAB# #TAB# #TAB# return node #LINE# #TAB# result = _format.format(initial_guess) % len(graph) #LINE# #TAB# return result
"#LINE# #TAB# if data.dim == 1: #LINE# #TAB# #TAB# raise NPKError('Not implemented in 1D', data=data) #LINE# #TAB# todo = data.test_axis(axis) #LINE# #TAB# data.revf(axis=todo).rfft(axis=todo) #LINE# #TAB# return data"
#LINE# #TAB# inst = cls.__new__(cls) #LINE# #TAB# inst.__dict__.update(environ) #LINE# #TAB# return inst
"#LINE# #TAB# json_formatter = JSONFormatter() #LINE# #TAB# json_formatter.formatters = col_types #LINE# #TAB# if overrides: #LINE# #TAB# #TAB# for key, value in overrides.items(): #LINE# #TAB# #TAB# #TAB# json_formatter.formatters[key] = value #LINE# #TAB# if nan_display: #LINE# #TAB# #TAB# json_formatter.nan_display = nan_display #LINE# #TAB# return json_formatter"
"#LINE# #TAB# for i, x in enumerate(outputs): #LINE# #TAB# #TAB# if isinstance(x, str): #LINE# #TAB# #TAB# #TAB# output = {'name': x} #LINE# #TAB# #TAB# elif isinstance(x, list): #LINE# #TAB# #TAB# #TAB# output = {'name': x} #LINE# #TAB# #TAB# elif isinstance(x, tuple): #LINE# #TAB# #TAB# #TAB# output = {'name': x[0]} #LINE# #TAB# #TAB# elif isinstance(x, dict): #LINE# #TAB# #TAB# #TAB# output = {'name': x[0], 'value': x[1]} #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# output = {'name': x} #LINE# #TAB# return output"
"#LINE# #TAB# if autospace: #LINE# #TAB# #TAB# elem = d['element'] #LINE# #TAB# #TAB# for k, v in elem.items(): #LINE# #TAB# #TAB# #TAB# if k.startswith('_'): #LINE# #TAB# #TAB# #TAB# #TAB# continue #LINE# #TAB# #TAB# #TAB# if v.startswith('__'): #LINE# #TAB# #TAB# #TAB# #TAB# continue #LINE# #TAB# #TAB# #TAB# try: #LINE# #TAB# #TAB# #TAB# #TAB# v = int(v[1:]) #LINE# #TAB# #TAB# #TAB# except: #LINE# #TAB# #TAB# #TAB# #TAB# pass #LINE# #TAB# #TAB# #TAB# yield k, v #LINE# #TAB# else: #LINE# #TAB# #TAB# yield elem"
#LINE# #TAB# dialog = ScrolledMessageDialog(parent) #LINE# #TAB# dialog.setText(text) #LINE# #TAB# dialog.exec_() #LINE# #TAB# return dialog
"#LINE# #TAB# if isinstance(root, str): #LINE# #TAB# #TAB# return root #LINE# #TAB# elif hasattr(root, 'children'): #LINE# #TAB# #TAB# for child in root.children: #LINE# #TAB# #TAB# #TAB# foo(child) #LINE# #TAB# else: #LINE# #TAB# #TAB# return root"
#LINE# #TAB# r = requests.get(BASE_URL.format(city_name=city_name)) #LINE# #TAB# if r.status_code == 200: #LINE# #TAB# #TAB# return r.json() #LINE# #TAB# elif r.status_code == 404: #LINE# #TAB# #TAB# return r.json() #LINE# #TAB# else: #LINE# #TAB# #TAB# return {}
"#LINE# #TAB# hsv = np.linspace(0, 1, N) #LINE# #TAB# if hsv: #LINE# #TAB# #TAB# color1 = hsv_to_rgb(color1, hsv) #LINE# #TAB# #TAB# color2 = hsv_to_rgb(color2, hsv) #LINE# #TAB# return [color1, color2]"
#LINE# #TAB# global _repository #LINE# #TAB# _repository = repository #LINE# #TAB# if should_list: #LINE# #TAB# #TAB# return _repository.split('/')[-1]
"#LINE# #TAB# if six.PY3: #LINE# #TAB# #TAB# if isinstance(string, bytes): #LINE# #TAB# #TAB# #TAB# return string.decode() #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# return string #LINE# #TAB# else: #LINE# #TAB# #TAB# return string"
"#LINE# #TAB# if create_copy: #LINE# #TAB# #TAB# return {'foo': left, 'right': right} #LINE# #TAB# else: #LINE# #TAB# #TAB# return left"
#LINE# #TAB# if s.group_by: #LINE# #TAB# #TAB# return Selectable(s.group_by[0]) #LINE# #TAB# else: #LINE# #TAB# #TAB# return s
"#LINE# #TAB# if isinstance(value, (list, tuple)): #LINE# #TAB# #TAB# return [foo(item) for item in value] #LINE# #TAB# elif isinstance(value, dict): #LINE# #TAB# #TAB# return {key: foo(item) for key, item in value.items()} #LINE# #TAB# else: #LINE# #TAB# #TAB# return value"
"#LINE# #TAB# x = data[:, (0)] #LINE# #TAB# y = data[:, (1)] #LINE# #TAB# cm = np.sqrt(x ** 2 + y ** 2) / (x ** 2 + y ** 2) #LINE# #TAB# return cm"
"#LINE# #TAB# with cls._lock: #LINE# #TAB# #TAB# if isinstance(component, weakref.weak): #LINE# #TAB# #TAB# #TAB# try: #LINE# #TAB# #TAB# #TAB# #TAB# del cls._refs[component] #LINE# #TAB# #TAB# #TAB# except KeyError: #LINE# #TAB# #TAB# #TAB# #TAB# pass"
#LINE# #TAB# kwargs = {} #LINE# #TAB# for item in header['extras']: #LINE# #TAB# #TAB# try: #LINE# #TAB# #TAB# #TAB# json.loads(item) #LINE# #TAB# #TAB# except json.JSONDecodeError: #LINE# #TAB# #TAB# #TAB# pass #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# kwargs[item] = json.loads(item) #LINE# #TAB# return kwargs
#LINE# #TAB# columns = set() #LINE# #TAB# for type in doc_types: #LINE# #TAB# #TAB# headers = request.registry.settings[type]['headers'] #LINE# #TAB# #TAB# for header in headers: #LINE# #TAB# #TAB# #TAB# if header[0] == 'x-forwarded-for': #LINE# #TAB# #TAB# #TAB# #TAB# continue #LINE# #TAB# #TAB# #TAB# if header[0] == 'content': #LINE# #TAB# #TAB# #TAB# #TAB# columns.add(header[1]) #LINE# #TAB# return columns
#LINE# #TAB# d = {} #LINE# #TAB# libsvm = load_libsvm(filename) #LINE# #TAB# for dataset in libsvm: #LINE# #TAB# #TAB# idx = dataset['idx'] #LINE# #TAB# #TAB# opt_type = dataset['opt_type'] #LINE# #TAB# #TAB# if idx == 0: #LINE# #TAB# #TAB# #TAB# d[dataset['name']] = dataset #LINE# #TAB# #TAB# elif idx < len(libsvm): #LINE# #TAB# #TAB# #TAB# d[dataset['name']] = dataset #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# opt_type = dataset['opt_type'] #LINE# #TAB# #TAB# #TAB# d[dataset['name']][opt_type] = idx #LINE# #TAB# return d
"#LINE# #TAB# parts = version_string.split('-') #LINE# #TAB# major = int(parts[0]) #LINE# #TAB# minor = int(parts[1]) #LINE# #TAB# revision = int(parts[2]) #LINE# #TAB# prerelease = False #LINE# #TAB# if len(parts) == 4: #LINE# #TAB# #TAB# prerelease = True #LINE# #TAB# #TAB# major = int(parts[3]) #LINE# #TAB# if len(parts) == 5: #LINE# #TAB# #TAB# major = int(parts[0]) #LINE# #TAB# if major == 0: #LINE# #TAB# #TAB# major = 1 #LINE# #TAB# return major, minor, revision, prerelease"
#LINE# #TAB# logger = logging.getLogger(name) #LINE# #TAB# return logger
"#LINE# #TAB# parent = os.path.dirname(f) #LINE# #TAB# path = os.path.join(parent, f) #LINE# #TAB# if not os.path.exists(path): #LINE# #TAB# #TAB# os.makedirs(path) #LINE# #TAB# return f"
#LINE# #TAB# message_json = json_format.MessageToJson(message_proto) #LINE# #TAB# message_dict = json.loads(message_json) #LINE# #TAB# return message_dict
"#LINE# #TAB# if agg =='sum': #LINE# #TAB# #TAB# yield 0, 1 #LINE# #TAB# elif agg =='min': #LINE# #TAB# #TAB# yield min(agg), 0 #LINE# #TAB# else: #LINE# #TAB# #TAB# for x in foo(agg): #LINE# #TAB# #TAB# #TAB# yield x #LINE# #TAB# #TAB# for y in foo(agg): #LINE# #TAB# #TAB# #TAB# yield y #LINE# #TAB# return"
"#LINE# #TAB# proc = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE) #LINE# #TAB# stdout, stderr = proc.communicate() #LINE# #TAB# if proc.returncode!= 0: #LINE# #TAB# #TAB# raise subprocess.CalledProcessError(stdout, stderr) #LINE# #TAB# return stdout"
#LINE# #TAB# p = random.random() #LINE# #TAB# if p not in state.outliers: #LINE# #TAB# #TAB# state.outliers[p] = updates[p] #LINE# #TAB# result = state.apply(updates[p]) #LINE# #TAB# if p in state.outliers: #LINE# #TAB# #TAB# state.outliers[p] = updates[p] #LINE# #TAB# return result
"#LINE# #TAB# ctx = jinja_context.copy() #LINE# #TAB# ctx.update({'PAGE_URL': build_url(new_filename), 'POST_URL': #LINE# #TAB# #TAB# build_url(new_filename)}) #LINE# #TAB# return ctx"
#LINE# #TAB# if not lookfor: #LINE# #TAB# #TAB# return logging.CRITICAL #LINE# #TAB# try: #LINE# #TAB# #TAB# level = int(lookfor) #LINE# #TAB# except ValueError: #LINE# #TAB# #TAB# return logging.INFO #LINE# #TAB# if level > 4: #LINE# #TAB# #TAB# return logging.WARNING #LINE# #TAB# if level < 0: #LINE# #TAB# #TAB# return logging.ERROR #LINE# #TAB# return logging.CRITICAL
"#LINE# #TAB# r = int(r, 10) #LINE# #TAB# g = int(g, 10) #LINE# #TAB# b = int(b, 10) #LINE# #TAB# if r > 255: #LINE# #TAB# #TAB# return '%02x%02x%02x' % (r, g, b) #LINE# #TAB# if r < 0: #LINE# #TAB# #TAB# return '%02x%02x' % (r, g, b) #LINE# #TAB# return '%02x' % r"
#LINE# #TAB# try: #LINE# #TAB# #TAB# return np.sum((solution == prediction) ** 2) #LINE# #TAB# except ZeroDivisionError: #LINE# #TAB# #TAB# return 0
#LINE# #TAB# if sys.platform.startswith('linux'): #LINE# #TAB# #TAB# return _linux_memory_limit() #LINE# #TAB# return _darwin_memory_limit()
"#LINE# #TAB# token_request_data = { #LINE# #TAB# #TAB# 'client_id': OAUTH2_CLIENT_ID, #LINE# #TAB# #TAB# 'client_secret': OAUTH2_CLIENT_SECRET, #LINE# #TAB# #TAB# 'grant_type':'refresh_token', #LINE# #TAB# #TAB#'refresh_token': refresh_token, #LINE# #TAB# } #LINE# #TAB# res = _make_token_request(session, token_request_data) #LINE# #TAB# return res['access_token']"
#LINE# #TAB# if s.isdigit(): #LINE# #TAB# #TAB# return True #LINE# #TAB# try: #LINE# #TAB# #TAB# if s.encode('ascii').startswith('utf-8'): #LINE# #TAB# #TAB# #TAB# return True #LINE# #TAB# except UnicodeEncodeError: #LINE# #TAB# #TAB# pass #LINE# #TAB# return False
"#LINE# #TAB# if infotype in ('idletime','refcount'): #LINE# #TAB# #TAB# return int_or_none(response) #LINE# #TAB# return response"
"#LINE# #TAB# identifier = parse_identifier(dictionary['identifier']) #LINE# #TAB# creator_id = dictionary['creator_id'] #LINE# #TAB# name = dictionary['name'] #LINE# #TAB# version = dictionary['version'] #LINE# #TAB# is_release_version = dictionary['is_release_version'] #LINE# #TAB# description = dictionary['description'] #LINE# #TAB# required_external_domains = dictionary['required_external_domains'] #LINE# #TAB# docker_image_name = dictionary['docker_image_name'] #LINE# #TAB# rating_numerator = dictionary['rating_numerator'] #LINE# #TAB# rating_count = dictionary['rating_count'] #LINE# #TAB# res = Program(identifier, creator_id, name, version, is_release_version, #LINE# #TAB# #TAB# description, required_external_domains, docker_image_name, #LINE# #TAB# #TAB# rating_numerator, rating_count) #LINE# #TAB# return res"
"#LINE# #TAB# print('Enter the value of the file: ') #LINE# #TAB# default_file = filename + '.txt' #LINE# #TAB# prompt = '\nEnter the value of the file:'#LINE# #TAB# while True: #LINE# #TAB# #TAB# try: #LINE# #TAB# #TAB# #TAB# inp = open(default_file, 'r') #LINE# #TAB# #TAB# #TAB# string = inp.read() #LINE# #TAB# #TAB# except IOError: #LINE# #TAB# #TAB# #TAB# print('ERROR:'+ default_file) #LINE# #TAB# #TAB# #TAB# return string #LINE# #TAB# #TAB# except: #LINE# #TAB# #TAB# #TAB# print('ERROR:'+ default_file) #LINE# #TAB# #TAB# #TAB# inp = open(default_file, 'r') #LINE# #TAB# #TAB# #TAB# string = string"
#LINE# #TAB# style = {} #LINE# #TAB# style['alpha'] = path.get_alpha() #LINE# #TAB# if style['alpha'] is None: #LINE# #TAB# #TAB# style['alpha'] = 1 #LINE# #TAB# style['edgecolor'] = color_to_hex(path.get_edgecolor()) #LINE# #TAB# if fill: #LINE# #TAB# #TAB# style['facecolor'] = color_to_hex(path.get_facecolor()) #LINE# #TAB# else: #LINE# #TAB# #TAB# style['facecolor'] = 'none' #LINE# #TAB# style['edgewidth'] = path.get_linewidth() #LINE# #TAB# style['dasharray'] = get_dasharray(path) #LINE# #TAB# style['zorder'] = path.get_zorder() #LINE# #TAB# return style
#LINE# #TAB# if sys.platform == 'win32': #LINE# #TAB# #TAB# return 1 #LINE# #TAB# else: #LINE# #TAB# #TAB# return 0
#LINE# #TAB# plt.figure() #LINE# #TAB# plt.xlabel('Iteration') #LINE# #TAB# plt.ylabel('Value') #LINE# #TAB# plt.title('{0}'.format(path)) #LINE# #TAB# return 1
#LINE# #TAB# blake2b = sha256() #LINE# #TAB# blake2b.update(data) #LINE# #TAB# d = blake2b.digest() #LINE# #TAB# d.update(d) #LINE# #TAB# return d
#LINE# #TAB# cookie_obj = SimpleCookie() #LINE# #TAB# cookie_obj.name = name #LINE# #TAB# cookie_obj.value = value #LINE# #TAB# try: #LINE# #TAB# #TAB# cookie_obj.save() #LINE# #TAB# except CookieError: #LINE# #TAB# #TAB# pass
#LINE# #TAB# if not os.path.exists(dest): #LINE# #TAB# #TAB# os.mkdir(dest) #LINE# #TAB# return
"#LINE# #TAB# mX = np.asarray(mX, dtype=float) #LINE# #TAB# mY = np.asarray(mY, dtype=float) #LINE# #TAB# if geoTransform[2] + geoTransform[4] == 0: #LINE# #TAB# #TAB# pX = ((mX - geoTransform[0]) / geoTransform[1]) - 0.5 #LINE# #TAB# #TAB# pY = ((mY - geoTransform[3]) / geoTransform[5]) - 0.5 #LINE# #TAB# else: #LINE# #TAB# #TAB# pX, pY = applyGeoTransform(mX, mY, invertGeoTransform(geoTransform)) #LINE# #TAB# return pX, pY"
#LINE# #TAB# if atom.symbol == 'X': #LINE# #TAB# #TAB# return atom #LINE# #TAB# if atom.symbol == 'Y': #LINE# #TAB# #TAB# return atom #LINE# #TAB# if atom.symbol == 'Z': #LINE# #TAB# #TAB# return atom.offset #LINE# #TAB# return atom
#LINE# #TAB# resp = request.response #LINE# #TAB# old = resp.clipboard #LINE# #TAB# resp.clipboard = None #LINE# #TAB# new = False #LINE# #TAB# try: #LINE# #TAB# #TAB# new = True #LINE# #TAB# except TypeError: #LINE# #TAB# #TAB# pass #LINE# #TAB# finally: #LINE# #TAB# #TAB# if old: #LINE# #TAB# #TAB# #TAB# resp.clipboard = old
#LINE# #TAB# if passwd is None: #LINE# #TAB# #TAB# holla = False #LINE# #TAB# else: #LINE# #TAB# #TAB# holla = True #LINE# #TAB# return holla
#LINE# #TAB# try: #LINE# #TAB# #TAB# from bluetooth import MACAddress #LINE# #TAB# except ImportError: #LINE# #TAB# #TAB# return False #LINE# #TAB# if address.upper() in MACAddress.upper(): #LINE# #TAB# #TAB# return True #LINE# #TAB# else: #LINE# #TAB# #TAB# return False
#LINE# #TAB# with np.errstate(divide='ignore'): #LINE# #TAB# #TAB# a_log = np.log(a) #LINE# #TAB# #TAB# x_log = np.log(x) #LINE# #TAB# #TAB# return a_log * np.exp(-a_log) - x_log
#LINE# #TAB# router.reload() #LINE# #TAB# return ''
"#LINE# #TAB# identifier = int(bookmark[0:1]) #LINE# #TAB# if len(identifier) == 1: #LINE# #TAB# #TAB# return identifier, #LINE# #TAB# return identifier,"
"#LINE# #TAB# with open(options.filepath, 'r') as test_file: #LINE# #TAB# #TAB# compare_files = [] #LINE# #TAB# #TAB# for filename in test_file: #LINE# #TAB# #TAB# #TAB# compare_files.append(filename) #LINE# #TAB# #TAB# print('\ncompare_files\n') #LINE# #TAB# if len(compare_files) == 1: #LINE# #TAB# #TAB# print('\ncompare_files\n') #LINE# #TAB# #TAB# return 0 #LINE# #TAB# else: #LINE# #TAB# #TAB# print('\n\ncompare_files\n') #LINE# #TAB# #TAB# print('\n\n') #LINE# #TAB# #TAB# return 1"
#LINE# #TAB# if resolver_helper.type_indicator not in cls._resolver_helpers: #LINE# #TAB# #TAB# raise KeyError('Resolver helper object not set for type indicator: {0:s}.' #LINE# #TAB# #TAB# #TAB#.format(resolver_helper.type_indicator)) #LINE# #TAB# resolver_helper = cls._resolver_helpers[resolver_helper.type_indicator]
"#LINE# #TAB# names = [] #LINE# #TAB# for r1, r2 in zip(R1, R2): #LINE# #TAB# #TAB# n = random.randint(0, len(names)) #LINE# #TAB# #TAB# n += 1 #LINE# #TAB# #TAB# if n >= percent: #LINE# #TAB# #TAB# #TAB# names.append(names[-1]) #LINE# #TAB# return names"
"#LINE# #TAB# session = db.get_reader_session() #LINE# #TAB# with session.begin(): #LINE# #TAB# #TAB# res = any(session.query(m).filter(m.tenant_id == tenant_id).count() for #LINE# #TAB# #TAB# #TAB# m in [models_v2.Network, models_v2.Port]) #LINE# #TAB# return res"
#LINE# #TAB# t = 0 #LINE# #TAB# while True: #LINE# #TAB# #TAB# if t < num: #LINE# #TAB# #TAB# #TAB# return #LINE# #TAB# #TAB# elif t % num == 0: #LINE# #TAB# #TAB# #TAB# time.sleep(0.2) #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# break
#LINE# #TAB# if score_c == 5: #LINE# #TAB# #TAB# return 0 #LINE# #TAB# elif score_c == 7: #LINE# #TAB# #TAB# return 1 #LINE# #TAB# elif score_c == 8: #LINE# #TAB# #TAB# return 2 #LINE# #TAB# return 3
#LINE# #TAB# global _foo #LINE# #TAB# _foo = f
#LINE# #TAB# if y < y1: #LINE# #TAB# #TAB# return False #LINE# #TAB# elif y > y1: #LINE# #TAB# #TAB# return True #LINE# #TAB# elif z < z1: #LINE# #TAB# #TAB# return True #LINE# #TAB# elif z > z2: #LINE# #TAB# #TAB# return False #LINE# #TAB# return True
#LINE# #TAB# for window in get_windows(): #LINE# #TAB# #TAB# if title in window.title: #LINE# #TAB# #TAB# #TAB# if not exact: #LINE# #TAB# #TAB# #TAB# #TAB# return window #LINE# #TAB# #TAB# return None #LINE# #TAB# return title
"#LINE# #TAB# resp = remote.get(CERN_RESOURCES) #LINE# #TAB# user_info = resp.json() #LINE# #TAB# group_info = resp.json() #LINE# #TAB# return user_info, group_info"
"#LINE# #TAB# f = config.get(main_section) #LINE# #TAB# f = os.path.expandvars(f) #LINE# #TAB# if os.path.isfile(f): #LINE# #TAB# #TAB# return f #LINE# #TAB# home = config.get(main_section) #LINE# #TAB# if home and os.path.isfile(home): #LINE# #TAB# #TAB# return os.path.join(home, f) #LINE# #TAB# return f"
#LINE# #TAB# while node.left is not None: #LINE# #TAB# #TAB# node = node.left #LINE# #TAB# return node
"#LINE# #TAB# ret = bk.BKTensor(0) #LINE# #TAB# for i in range(3): #LINE# #TAB# #TAB# for j in range(3): #LINE# #TAB# #TAB# #TAB# ret += bk.fidelity(state0[i], state1[j]) #LINE# #TAB# return ret"
"#LINE# #TAB# a1 = np.array(a[0]) #LINE# #TAB# a2 = np.array(a[1]) #LINE# #TAB# b1 = np.array(b[0]) #LINE# #TAB# b2 = np.array(b[1]) #LINE# #TAB# area = np.cross(a1 - a2, b1 - b2) #LINE# #TAB# return area[:, (0)] == area[:, (0)] and area[:, (1)] == area[:, (1)]"
"#LINE# #TAB# body = request_body #LINE# #TAB# if body is None: #LINE# #TAB# #TAB# body = '' #LINE# #TAB# #TAB# return body #LINE# #TAB# if isinstance(request_body, dict): #LINE# #TAB# #TAB# try: #LINE# #TAB# #TAB# #TAB# body = xml.tostring(request_body, pretty_print=False) #LINE# #TAB# #TAB# except Exception: #LINE# #TAB# #TAB# #TAB# pass #LINE# #TAB# if isinstance(body, list): #LINE# #TAB# #TAB# return [body] #LINE# #TAB# return body"
"#LINE# #TAB# assert isinstance(input, str) #LINE# #TAB# encoding = sys.getfilesystemencoding() #LINE# #TAB# f = io.StringIO() #LINE# #TAB# f.write(input) #LINE# #TAB# f.seek(0) #LINE# #TAB# res = f.readline() #LINE# #TAB# f.close() #LINE# #TAB# if sys.version_info.major < 3: #LINE# #TAB# #TAB# res = res.decode(encoding, errors) #LINE# #TAB# return res"
#LINE# #TAB# if module.startswith('homeassistant.components.'): #LINE# #TAB# #TAB# return True #LINE# #TAB# else: #LINE# #TAB# #TAB# return False
"#LINE# #TAB# c = r if isinstance(r, list) else [r, g, b] #LINE# #TAB# best = {} #LINE# #TAB# for index, item in enumerate(colors): #LINE# #TAB# #TAB# d = __distance(item, c) #LINE# #TAB# #TAB# if not best or d <= best['distance']: #LINE# #TAB# #TAB# #TAB# best = {'distance': d, 'index': index} #LINE# #TAB# if 'index' in best: #LINE# #TAB# #TAB# return best['index'] #LINE# #TAB# else: #LINE# #TAB# #TAB# return 1"
"#LINE# #TAB# try: #LINE# #TAB# #TAB# s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM) #LINE# #TAB# #TAB# s.connect(('8.8.8.8', 80)) #LINE# #TAB# #TAB# ip = s.getsockname()[0] #LINE# #TAB# #TAB# s.close() #LINE# #TAB# #TAB# return ip #LINE# #TAB# except: #LINE# #TAB# #TAB# return '127.0.0.1'"
#LINE# #TAB# result = np.zeros(maglen) #LINE# #TAB# for i in range(lag): #LINE# #TAB# #TAB# result[i] = mags[i][magmed:maglen + lag][magmed:maglen + lag][ #LINE# #TAB# #TAB# #TAB# magstd] #LINE# #TAB# return result
#LINE# #TAB# if symbol: #LINE# #TAB# #TAB# return Xlib.XMODE_SYMBOLS[symbol] #LINE# #TAB# else: #LINE# #TAB# #TAB# flags = Xlib.XMODE_SYMBOLS.get(symbol) #LINE# #TAB# #TAB# if flags == -1: #LINE# #TAB# #TAB# #TAB# raise ValueError('Invalid symbol: {}'.format(symbol)) #LINE# #TAB# #TAB# return flags
"#LINE# #TAB# env = np.zeros(iq_array.shape) #LINE# #TAB# for i in range(iq_array.shape[2]): #LINE# #TAB# #TAB# env[i, :] = hilbert_transform(iq_array[:, (i)]) #LINE# #TAB# return env"
#LINE# #TAB# request_func._foo = True #LINE# #TAB# return request_func
"#LINE# #TAB# if this._children: #LINE# #TAB# #TAB# for child in this._children: #LINE# #TAB# #TAB# #TAB# foo(child, value) #LINE# #TAB# return value"
"#LINE# #TAB# if reference_fasta_map_param: #LINE# #TAB# #TAB# keys = reference_fasta_map_param.keys() #LINE# #TAB# else: #LINE# #TAB# #TAB# keys = [] #LINE# #TAB# for assembly_key in keys: #LINE# #TAB# #TAB# ref_fasta_file_path = os.path.join('data','reference_fasta_' + #LINE# #TAB# #TAB# #TAB# assembly_key) #LINE# #TAB# #TAB# if os.path.isfile(ref_fasta_file_path): #LINE# #TAB# #TAB# #TAB# ref_fasta_keys.append(assembly_key) #LINE# #TAB# return {assembly_key: ref_fasta_file_path for assembly_key in keys}"
#LINE# #TAB# try: #LINE# #TAB# #TAB# ctypes.windll.glibc_version_string() #LINE# #TAB# except AttributeError: #LINE# #TAB# #TAB# return 1 #LINE# #TAB# else: #LINE# #TAB# #TAB# return 0
"#LINE# #TAB# try: #LINE# #TAB# #TAB# mod = import_module(package + '.' + script_information['name']) #LINE# #TAB# except: #LINE# #TAB# #TAB# if verbose: #LINE# #TAB# #TAB# #TAB# traceback.print_exc() #LINE# #TAB# #TAB# #TAB# pass #LINE# #TAB# else: #LINE# #TAB# #TAB# if verbose: #LINE# #TAB# #TAB# #TAB# print('get_script_module: script_information={'name': script_information[ #LINE# #TAB# #TAB# #TAB# #TAB# 'name'], 'package': package}) #LINE# #TAB# #TAB# #TAB# del mod #LINE# #TAB# return mod"
"#LINE# #TAB# perm = {} #LINE# #TAB# for perm_name in get_task_perms(task): #LINE# #TAB# #TAB# perm[perm_name] = getattr(user, perm_name) #LINE# #TAB# return perm"
#LINE# #TAB# g = nx.Graph() #LINE# #TAB# for node_id in node_ids: #LINE# #TAB# #TAB# g.add_node(node_id) #LINE# #TAB# g.remove_nodes_from(node_ids) #LINE# #TAB# return g
#LINE# #TAB# if len(seq)!= 2: #LINE# #TAB# #TAB# raise ValueError('Input must be two-dimensional and got {}'.format(str( #LINE# #TAB# #TAB# #TAB# seq))) #LINE# #TAB# return seq
#LINE# #TAB# if name in klass.__dict__: #LINE# #TAB# #TAB# method = klass.__dict__[name] #LINE# #TAB# #TAB# if method is not None: #LINE# #TAB# #TAB# #TAB# return method #LINE# #TAB# return None
"#LINE# #TAB# if len(tokens) == 1: #LINE# #TAB# #TAB# args = tokens[0] #LINE# #TAB# elif len(tokens) == 2: #LINE# #TAB# #TAB# args = tokens[1] #LINE# #TAB# elif len(tokens) == 3: #LINE# #TAB# #TAB# raise CoconutInternalException(""invalid assignment tokens"", tokens) #LINE# #TAB# return ""name"", args"
"#LINE# #TAB# if method in ('get', 'delete'): #LINE# #TAB# #TAB# return True #LINE# #TAB# if method in ('post', 'put'): #LINE# #TAB# #TAB# if params and isinstance(params, dict): #LINE# #TAB# #TAB# #TAB# return foo(method, params) #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# return True #LINE# #TAB# return False"
#LINE# #TAB# if encoding is None: #LINE# #TAB# #TAB# encoding = 'utf-8' #LINE# #TAB# try: #LINE# #TAB# #TAB# return data.encode(encoding) #LINE# #TAB# except UnicodeEncodeError: #LINE# #TAB# #TAB# return '<!DOCTYPE html>\n'
"#LINE# s = [] #LINE# inputBits = int(numActiveInputBits) #LINE# for _ in range(numDims): #LINE# #TAB# s.append(random.randint(0, 2 ** 32 - 1)) #LINE# for _ in range(numDims): #LINE# #TAB# s.append(random.randint(0, 2 ** 32 - 1)) #LINE# return s"
#LINE# #TAB# if cls._redis_db is None: #LINE# #TAB# #TAB# cls._redis_db = cls.get_redis_db() #LINE# #TAB# return cls._redis_db
"#LINE# #TAB# with open(location, 'r') as csvfile: #LINE# #TAB# #TAB# reader = csv.DictReader(csvfile) #LINE# #TAB# #TAB# output = [row for row in reader] #LINE# #TAB# return output"
"#LINE# #TAB# val = getattr(dev_ref, key) #LINE# #TAB# if not val: #LINE# #TAB# #TAB# return None #LINE# #TAB# if not isinstance(val, int): #LINE# #TAB# #TAB# return val #LINE# #TAB# return int(val) & 255"
#LINE# #TAB# d = [] #LINE# #TAB# for i in range(len(unitaries) - 1): #LINE# #TAB# #TAB# for j in range(i + 1): #LINE# #TAB# #TAB# #TAB# d.append(unitaries[i][j]) #LINE# #TAB# foo = [] #LINE# #TAB# for i in range(len(unitaries) - 1): #LINE# #TAB# #TAB# foo.append(unitaries[i][i]) #LINE# #TAB# return foo
#LINE# #TAB# client = ControllerClient() #LINE# #TAB# result = client.get_chute(name) #LINE# #TAB# if len(result) > 0: #LINE# #TAB# #TAB# click.echo('{:s}'.format(result[0])) #LINE# #TAB# else: #LINE# #TAB# #TAB# click.echo('{:s}'.format(result[0])) #LINE# #TAB# return result
"#LINE# #TAB# if run_name not in task.runs: #LINE# #TAB# #TAB# return True #LINE# #TAB# for item in task.runs[run_name]: #LINE# #TAB# #TAB# if isinstance(task, backend.Task): #LINE# #TAB# #TAB# #TAB# return True #LINE# #TAB# return False"
"#LINE# #TAB# model_one.factor = S12.factor * model_one.reduction_factor #LINE# #TAB# model_two.factor = S12.factor * model_two.reduction_factor #LINE# #TAB# model_one.s = S12.s / S12.s #LINE# #TAB# model_two.s = S12.s / S12.s #LINE# #TAB# return model_one, model_two"
#LINE# #TAB# if old_value is None: #LINE# #TAB# #TAB# return new_value == None #LINE# #TAB# elif new_value is None: #LINE# #TAB# #TAB# return True #LINE# #TAB# elif old_value == new_value: #LINE# #TAB# #TAB# return True #LINE# #TAB# else: #LINE# #TAB# #TAB# return False
#LINE# #TAB# if name1 == name2: #LINE# #TAB# #TAB# return True #LINE# #TAB# if not name1 and not name2: #LINE# #TAB# #TAB# return False #LINE# #TAB# for c in name1: #LINE# #TAB# #TAB# if not c.isalpha(): #LINE# #TAB# #TAB# #TAB# return False #LINE# #TAB# #TAB# if c.isdigit(): #LINE# #TAB# #TAB# #TAB# return False #LINE# #TAB# return True
"#LINE# #TAB# validate(config) #LINE# #TAB# if CONFIG_URL not in config: #LINE# #TAB# #TAB# _LOGGER.error('Missing URL in config file.') #LINE# #TAB# #TAB# return config #LINE# #TAB# if CONFIG_HOST not in config: #LINE# #TAB# #TAB# _LOGGER.error('Missing host in config file.') #LINE# #TAB# #TAB# return config #LINE# #TAB# if CONFIG_PORT not in config[CONFIG_FILE]: #LINE# #TAB# #TAB# _LOGGER.error('Invalid port in config file.') #LINE# #TAB# #TAB# return config #LINE# #TAB# return {'host': config[CONFIG_HOST], 'port': config[CONFIG_PORT], 'full_hostname': #LINE# #TAB# #TAB# config[CONFIG_FULL_HOST], 'full_port': config[CONFIG_FULL_PORT]}"
#LINE# #TAB# res = {} #LINE# #TAB# for table in database.tables: #LINE# #TAB# #TAB# res[table.name] = {column.name: column.value} #LINE# #TAB# return res
"#LINE# #TAB# try: #LINE# #TAB# #TAB# for node in tree.iter(): #LINE# #TAB# #TAB# #TAB# node.tag = '{}{}'.format(URI, node.tag) #LINE# #TAB# #TAB# yield node #LINE# #TAB# except AttributeError: #LINE# #TAB# #TAB# pass"
"#LINE# #TAB# if cls.TITLE is not None: #LINE# #TAB# #TAB# return '%s: %s' % (cls.TITLE, cls.TITLE) #LINE# #TAB# for c in cls.subclasses(): #LINE# #TAB# #TAB# if c.DESCRIPTION is not None: #LINE# #TAB# #TAB# #TAB# return '%s: %s' % (c.DESCRIPTION, cls.foo()) #LINE# #TAB# return cls.TITLE"
"#LINE# #TAB# try: #LINE# #TAB# #TAB# return bytecode_path.replace('.pyc', '.pyo') #LINE# #TAB# except OSError: #LINE# #TAB# #TAB# return bytecode_path"
"#LINE# #TAB# import json #LINE# #TAB# fname = os.path.join(os.path.dirname(__file__), 'data', 'MSOA.json') #LINE# #TAB# with open(fname, 'r') as f: #LINE# #TAB# #TAB# contents = f.read() #LINE# #TAB# data = json.loads(contents) #LINE# #TAB# return data"
#LINE# #TAB# if i == 0: #LINE# #TAB# #TAB# return True #LINE# #TAB# else: #LINE# #TAB# #TAB# return False
"#LINE# #TAB# with open(config, 'r') as f: #LINE# #TAB# #TAB# config = json.load(f) #LINE# #TAB# return config['objective']"
"#LINE# #TAB# if isinstance(maybe_dttm, datetime.datetime): #LINE# #TAB# #TAB# maybe_dttm = _format_datetime(maybe_dttm) #LINE# #TAB# return maybe_dttm"
"#LINE# #TAB# new_lst = [] #LINE# #TAB# for el in lst: #LINE# #TAB# #TAB# if index == el: #LINE# #TAB# #TAB# #TAB# new_lst.append(el[0]) #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# new_lst.insert(index, el) #LINE# #TAB# return new_lst"
#LINE# #TAB# r = requests.get(user_access_token) #LINE# #TAB# try: #LINE# #TAB# #TAB# user_data = r.json() #LINE# #TAB# #TAB# user = User.objects.get(email=user_data['email']) #LINE# #TAB# #TAB# return user.email #LINE# #TAB# except: #LINE# #TAB# #TAB# return None
#LINE# #TAB# if obj.experiment_type =='multivariate': #LINE# #TAB# #TAB# return True #LINE# #TAB# else: #LINE# #TAB# #TAB# return False
"#LINE# #TAB# col = dataframe[colname] #LINE# #TAB# col_numerics = col.loc[col.apply(lambda x: isinstance(x, (int, float)))] #LINE# #TAB# dataframe.loc[col.notnull() & col.apply(lambda x: not isinstance(x, #LINE# #TAB# #TAB# string_types)), colname] = col_numerics.mode() #LINE# #TAB# return dataframe"
"#LINE# #TAB# s = rnd.random() #LINE# #TAB# r = s.zfill(length) #LINE# #TAB# while len(r) < length: #LINE# #TAB# #TAB# s = s.replace(b'\x00', b'\x00') #LINE# #TAB# return s"
"#LINE# #TAB# time = pd.Series(time) #LINE# #TAB# window = calc_windows(time) #LINE# #TAB# if method == 'between': #LINE# #TAB# #TAB# return window #LINE# #TAB# elif method == 'date': #LINE# #TAB# #TAB# return time[list(range(len(time))[0]), :] #LINE# #TAB# elif method == 'first': #LINE# #TAB# #TAB# return time[list(range(len(time))[0]), :] #LINE# #TAB# elif method == 'last': #LINE# #TAB# #TAB# return time[list(range(len(time))[0]), :] #LINE# #TAB# else: #LINE# #TAB# #TAB# return None"
#LINE# #TAB# key = hashlib.sha1(url.encode('utf-8')).hexdigest() #LINE# #TAB# key = base64.urlsafe_b64encode(key).decode('utf-8') #LINE# #TAB# return key
"#LINE# #TAB# import socket #LINE# #TAB# s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM) #LINE# #TAB# s.connect(('8.8.8.8', 80)) #LINE# #TAB# ip_address = s.getsockname()[0] #LINE# #TAB# s.close() #LINE# #TAB# return ip_address"
#LINE# #TAB# result = StreamResult() #LINE# #TAB# result.num_rows = num_rows #LINE# #TAB# result.bytes_left = sbody.bytes_left #LINE# #TAB# result.bytes_right = sbody.bytes_right #LINE# #TAB# return result
"#LINE# #TAB# result = {} #LINE# #TAB# for k, v in vertex_json.items(): #LINE# #TAB# #TAB# if isinstance(v, dict): #LINE# #TAB# #TAB# #TAB# result.update(foo(v)) #LINE# #TAB# #TAB# elif isinstance(v, list): #LINE# #TAB# #TAB# #TAB# result.update(foo(v)) #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# result.update(foo(v)) #LINE# #TAB# return result"
"#LINE# #TAB# for x in range(w - room_size): #LINE# #TAB# #TAB# for y in range(h - room_size): #LINE# #TAB# #TAB# #TAB# yield x, y #LINE# #TAB# for x in range(w - room_size - 1, w): #LINE# #TAB# #TAB# for y in range(h - room_size, h): #LINE# #TAB# #TAB# #TAB# yield x + y * (1 - delete_chance) + y * delete_chance"
#LINE# #TAB# res = np.zeros(len(group_sizes)) #LINE# #TAB# for group_size in group_sizes: #LINE# #TAB# #TAB# for i in range(len(group_sizes)): #LINE# #TAB# #TAB# #TAB# if np.sum(group_sizes[i]) >= min_n_obs: #LINE# #TAB# #TAB# #TAB# #TAB# res[i] = group_sizes[i] #LINE# #TAB# return res
"#LINE# #TAB# for base_dir, dirs, files in os.walk(root_dir): #LINE# #TAB# #TAB# if dirs: #LINE# #TAB# #TAB# #TAB# if empty_only: #LINE# #TAB# #TAB# #TAB# #TAB# continue #LINE# #TAB# #TAB# #TAB# dirs[:] = [d for d in dirs if os.path.isdir(os.path.join(base_dir, d))] #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# yield base_dir, dirs, files"
"#LINE# #TAB# logger.info('Randomly shuffle the training data') #LINE# #TAB# model.data[:, ('random')] = np.random.randn() #LINE# #TAB# return model"
#LINE# #TAB# if ax.get_x_axis().count() == 2: #LINE# #TAB# #TAB# return True #LINE# #TAB# if ax.get_y_axis().count() == 1: #LINE# #TAB# #TAB# return True #LINE# #TAB# return False
"#LINE# #TAB# if filename.endswith("".gz""): #LINE# #TAB# #TAB# return gzip.open #LINE# #TAB# else: #LINE# #TAB# #TAB# return open"
"#LINE# #TAB# unique_dict = {} #LINE# #TAB# for key, val in ordered_pairs: #LINE# #TAB# #TAB# if key in unique_dict: #LINE# #TAB# #TAB# #TAB# raise KeyError('Duplicate key: %r' % (key,)) #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# unique_dict[key] = val #LINE# #TAB# return unique_dict"
#LINE# #TAB# from tkinter import mainwindow #LINE# #TAB# w = mainwindow.MainWindow() #LINE# #TAB# w.SetExitMode(MainWindow.EXIT_MODE) #LINE# #TAB# h = mainwindow.GetSize() #LINE# #TAB# w.SetWidth(w.GetWidth()) #LINE# #TAB# h.SetHeight(h.GetHeight()) #LINE# #TAB# i = 0 #LINE# #TAB# while True: #LINE# #TAB# #TAB# try: #LINE# #TAB# #TAB# #TAB# w.Show() #LINE# #TAB# #TAB# #TAB# break #LINE# #TAB# #TAB# except UnicodeDecodeError: #LINE# #TAB# #TAB# #TAB# pass #LINE# #TAB# #TAB# i += 1 #LINE# #TAB# return w
"#LINE# #TAB# popsi = np.shape(ftrue) #LINE# #TAB# fval = ftrue * _rand(popsi) ** beta * (1 + _rand(popsi)) #LINE# #TAB# tol = 1e-08 #LINE# #TAB# fval = fval + 1.01 * tol #LINE# #TAB# idx = ftrue < tol #LINE# #TAB# try: #LINE# #TAB# #TAB# fval[idx] = ftrue[idx] #LINE# #TAB# except (IndexError, TypeError): #LINE# #TAB# #TAB# if idx: #LINE# #TAB# #TAB# #TAB# fval = ftrue #LINE# #TAB# return fval"
"#LINE# #TAB# with open('/proc/1/cpuinfo', 'r') as in_handle: #LINE# #TAB# #TAB# in_handle.readline() #LINE# #TAB# #TAB# if in_handle.readline().strip() == 'true': #LINE# #TAB# #TAB# #TAB# return True #LINE# #TAB# #TAB# elif in_handle.readline().strip() == 'true': #LINE# #TAB# #TAB# #TAB# return True #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# return False"
"#LINE# #TAB# for line in sacct_stream: #LINE# #TAB# #TAB# if not line or line.startswith('---'): #LINE# #TAB# #TAB# #TAB# continue #LINE# #TAB# #TAB# parts = line.split() #LINE# #TAB# #TAB# if len(parts) == 2: #LINE# #TAB# #TAB# #TAB# func = parts[0] #LINE# #TAB# #TAB# #TAB# func(parts[1], parts[2]) #LINE# #TAB# #TAB# return func"
"#LINE# #TAB# if value is None: #LINE# #TAB# #TAB# f = formatter(randomInt=random.randint) #LINE# #TAB# #TAB# return f #LINE# #TAB# elif isinstance(value, dict): #LINE# #TAB# #TAB# f = formatter(value) #LINE# #TAB# #TAB# return f(value) #LINE# #TAB# else: #LINE# #TAB# #TAB# return value"
"#LINE# #TAB# for pos, refl, iBeg, iFin in profList: #LINE# #TAB# #TAB# yc[iBeg:iFin] += refl[11 + im] * refl[9 + im] * yd[iBeg:iFin] #LINE# #TAB# return yc"
"#LINE# #TAB# map = {} #LINE# #TAB# f = open('custom/pypi/map.txt') #LINE# #TAB# for line in f: #LINE# #TAB# #TAB# if line.strip(): #LINE# #TAB# #TAB# #TAB# package, url = line.strip().split('\t') #LINE# #TAB# #TAB# #TAB# if package not in map: #LINE# #TAB# #TAB# #TAB# #TAB# map[package] = url #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# map[package] = url #LINE# #TAB# return map"
#LINE# #TAB# if doc: #LINE# #TAB# #TAB# for tag in doc: #LINE# #TAB# #TAB# #TAB# yield tag
"#LINE# #TAB# template = get_template(request, template_name) #LINE# #TAB# if template is None: #LINE# #TAB# #TAB# raise Http404('Template not found') #LINE# #TAB# if template.endswith('.html'): #LINE# #TAB# #TAB# template_name += '.html' #LINE# #TAB# if template.endswith('.htm'): #LINE# #TAB# #TAB# template_name += '.htm' #LINE# #TAB# return template"
"#LINE# #TAB# if isinstance(s, str): #LINE# #TAB# #TAB# return s.decode('utf-8') #LINE# #TAB# return s"
#LINE# #TAB# if color is not None: #LINE# #TAB# #TAB# set_options(background_color=color) #LINE# #TAB# return DEFAULT_BACKGROUND_COLOR
"#LINE# #TAB# return [os.path.join(os.path.dirname(os.path.realpath(__file__)), #LINE# #TAB# #TAB# 'data', '*.json'), os.path.join(os.path.dirname(os.path.realpath(__file__)), #LINE# #TAB# #TAB# 'data', '*.json'), os.path.join(os.path.dirname(os.path.realpath(__file__)), #LINE# #TAB# #TAB# 'data', '*.json')]"
"#LINE# #TAB# if not protcol: #LINE# #TAB# #TAB# protcol = mzidtsvdata.HEADER_PROT #LINE# #TAB# protcol += '_precursor_quant' #LINE# #TAB# proteins = sort_proteins(proteins) #LINE# #TAB# for protein in proteins: #LINE# #TAB# #TAB# if protein[prottabledata.HEADER_PROTEIN] == '': #LINE# #TAB# #TAB# #TAB# protein[prottabledata.HEADER_PROTEIN] = '' #LINE# #TAB# sum_of_psms = sum(psms, axis=1) #LINE# #TAB# if len(sum_of_psms) > 3: #LINE# #TAB# #TAB# outprotein = '{0} {1}'.format(prottabledata.HEADER_PROTEIN, sum_of_psms) #LINE# #TAB# else: #LINE# #TAB# #TAB# outprotein = '{0} {1}'.format(prottabledata.HEADER_PROTEIN, sum_of_ps"
"#LINE# #TAB# if dedupe: #LINE# #TAB# #TAB# pattern = re.compile('\\s+') #LINE# #TAB# #TAB# return re.sub(pattern, '', text) #LINE# #TAB# else: #LINE# #TAB# #TAB# first_line = text.split('\n')[0] #LINE# #TAB# #TAB# matches = re.findall(pattern, first_line) #LINE# #TAB# #TAB# if not matches: #LINE# #TAB# #TAB# #TAB# return first_line #LINE# #TAB# #TAB# new_line =''.join(matches) #LINE# #TAB# #TAB# return new_line"
#LINE# #TAB# it = iter(iterable) #LINE# #TAB# while True: #LINE# #TAB# #TAB# try: #LINE# #TAB# #TAB# #TAB# yield next(it) #LINE# #TAB# #TAB# except StopIteration: #LINE# #TAB# #TAB# #TAB# break
#LINE# #TAB# w = event.app.layout.current_window #LINE# #TAB# b = event.app.current_buffer #LINE# #TAB# if w: #LINE# #TAB# #TAB# if w.render_info: #LINE# #TAB# #TAB# #TAB# info = w.render_info #LINE# #TAB# #TAB# #TAB# if w.vertical_scroll < info.content_height - info.window_height: #LINE# #TAB# #TAB# #TAB# #TAB# if info.cursor_position.y <= info.configured_scroll_offsets.top: #LINE# #TAB# #TAB# #TAB# #TAB# #TAB# b.cursor_position += b.document.get_cursor_down_position() #LINE# #TAB# #TAB# #TAB# #TAB# w.vertical_scroll += 1
"#LINE# #TAB# logging.debug('Getting foo from URL: %s' % url) #LINE# #TAB# r = requests.get(url) #LINE# #TAB# if r.status_code == 200: #LINE# #TAB# #TAB# data = r.json() #LINE# #TAB# #TAB# return {'repository_fullname': data['repository_fullname'], 'name': #LINE# #TAB# #TAB# #TAB# data['repository_name']}"
"#LINE# #TAB# calc_dtype = dtype(a_dtype) #LINE# #TAB# res_dtype = dtype(b_dtype) #LINE# #TAB# return calc_dtype, res_dtype"
"#LINE# #TAB# txt = content.text #LINE# #TAB# if isinstance(txt, unicode): #LINE# #TAB# #TAB# txt = txt.encode('utf8') #LINE# #TAB# elif isinstance(txt, list): #LINE# #TAB# #TAB# txt = '\n'.join([line.strip() for line in txt]) #LINE# #TAB# elif isinstance(txt, str): #LINE# #TAB# #TAB# txt = txt.encode('utf8') #LINE# #TAB# else: #LINE# #TAB# #TAB# txt = txt.decode('utf8') #LINE# #TAB# return txt"
#LINE# #TAB# for cell in nb.cells: #LINE# #TAB# #TAB# if 'cell_type' in cell and cell['cell_type'] == 'code': #LINE# #TAB# #TAB# #TAB# if cell['cell_type'] == 'code': #LINE# #TAB# #TAB# #TAB# #TAB# if cell['outputs']: #LINE# #TAB# #TAB# #TAB# #TAB# #TAB# for output in cell['outputs']: #LINE# #TAB# #TAB# #TAB# #TAB# #TAB# #TAB# yield output #LINE# #TAB# #TAB# #TAB# elif cell['cell_type'] =='source': #LINE# #TAB# #TAB# #TAB# #TAB# yield cell
"#LINE# #TAB# for x in list(df.index): #LINE# #TAB# #TAB# if x not in ['chr','start', 'end']: #LINE# #TAB# #TAB# #TAB# continue #LINE# #TAB# #TAB# if df[x].chrom.startswith('chr'): #LINE# #TAB# #TAB# #TAB# continue #LINE# #TAB# #TAB# df = df.drop_duplicates(x, axis=1) #LINE# #TAB# return df"
"#LINE# #TAB# try: #LINE# #TAB# #TAB# if getattr(request, 'gcp_media_export', None): #LINE# #TAB# #TAB# #TAB# media = request.gcp_media_export(request) #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# media = request.content #LINE# #TAB# except AttributeError: #LINE# #TAB# #TAB# media = None #LINE# #TAB# return media"
"#LINE# #TAB# for region in batch: #LINE# #TAB# #TAB# if region not in [""train"", ""valid"", ""test""]: #LINE# #TAB# #TAB# #TAB# yield { #LINE# #TAB# #TAB# #TAB# ""region_name"": region, #LINE# #TAB# #TAB# #TAB# ""train"": tz.get_in([""config"", ""algorithm"", ""regions"", region], batch), #LINE# #TAB# #TAB# #TAB# ""valid"": tz.get_in([""config"", ""algorithm"", ""regions"", region], batch), #LINE# #TAB# #TAB# #TAB# yield region #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# yield region"
#LINE# #TAB# for i in cls.indices(): #LINE# #TAB# #TAB# yield {'items': [i]}
#LINE# #TAB# time.sleep(0.3) #LINE# #TAB# random.seed(seed) #LINE# #TAB# return time.time()
"#LINE# #TAB# x = P[:, (0)] #LINE# #TAB# y = P[:, (1)] #LINE# #TAB# return x, y"
#LINE# #TAB# new_state = copy.deepcopy(state) #LINE# #TAB# new_state.follow_pickup = pickup #LINE# #TAB# new_state.resource_gain = state.resource_gain #LINE# #TAB# return new_state
"#LINE# #TAB# conn = boto.connect_s3() #LINE# #TAB# conn.meta.client.connect_to_bucket(bucket) #LINE# #TAB# key = conn.get_key(Bucket=bucket)['Key'] #LINE# #TAB# return bucket, key"
"#LINE# #TAB# import matplotlib.pyplot as plt #LINE# #TAB# plt.rcParams['figure.figsize'] = (10, 10) #LINE# #TAB# plt.rcParams['xtick.labelsize'] = 10 #LINE# #TAB# plt.rcParams['ytick.labelsize'] = 10 #LINE# #TAB# plt.rcParams['marker'] = marker #LINE# #TAB# plt.colorbar() #LINE# #TAB# plt.xticks(x, y) #LINE# #TAB# plt.yticks(y, x + 1) #LINE# #TAB# plt.colorbar() #LINE# #TAB# return"
#LINE# #TAB# if root == target: #LINE# #TAB# #TAB# return [0] #LINE# #TAB# elif pred == root: #LINE# #TAB# #TAB# return [0] #LINE# #TAB# else: #LINE# #TAB# #TAB# p = pred #LINE# #TAB# #TAB# for i in range(root.get_children()): #LINE# #TAB# #TAB# #TAB# c = root.get_children()[i] #LINE# #TAB# #TAB# #TAB# for j in range(c): #LINE# #TAB# #TAB# #TAB# #TAB# if p[j] == target: #LINE# #TAB# #TAB# #TAB# #TAB# #TAB# p = c[j] #LINE# #TAB# #TAB# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# #TAB# #TAB# p = c[j] #LINE# #TAB# #TAB# return p
"#LINE# #TAB# if sensitivity in ['B', 'K', 'M', 'G', 'T']: #LINE# #TAB# #TAB# return 1.0 #LINE# #TAB# if sensitivity == 'P': #LINE# #TAB# #TAB# return 0.0 #LINE# #TAB# return 1.0"
#LINE# #TAB# for term in facets_terms: #LINE# #TAB# #TAB# yield term
"#LINE# #TAB# uri = application.config_uri + '/version' #LINE# #TAB# result = ET.Element('uri') #LINE# #TAB# result.append(uri) #LINE# #TAB# if configuration: #LINE# #TAB# #TAB# uri = ET.SubElement(result, 'uri') #LINE# #TAB# #TAB# uri.text = configuration.uri #LINE# #TAB# return result"
#LINE# #TAB# registry = _registry #LINE# #TAB# if registry is None: #LINE# #TAB# #TAB# raise NotImplementedError('Pyramid is not installed') #LINE# #TAB# return registry
"#LINE# #TAB# source = getattr(module, '__doc__', None) #LINE# #TAB# if source is not None: #LINE# #TAB# #TAB# return source #LINE# #TAB# if hasattr(module, '__name__'): #LINE# #TAB# #TAB# return f'<{module.__name__}>' #LINE# #TAB# if not hasattr(module, '__doc__'): #LINE# #TAB# #TAB# return f'<{module.__name__}>' #LINE# #TAB# return f'<{module.__name__}>'"
"#LINE# #TAB# if secret is None: #LINE# #TAB# #TAB# return None #LINE# #TAB# if isinstance(secret, str): #LINE# #TAB# #TAB# return secret #LINE# #TAB# chars = [] #LINE# #TAB# for i in range(32): #LINE# #TAB# #TAB# chars.append(chr(ord('A') + i)) #LINE# #TAB# temp = '' #LINE# #TAB# for c in chars: #LINE# #TAB# #TAB# temp += chr(ord('A') + c) #LINE# #TAB# return temp[:64]"
"#LINE# #TAB# id = request.matchdict['id'] #LINE# #TAB# user = request.user #LINE# #TAB# is_secret = request.GET.get('is_secret', False) #LINE# #TAB# if is_secret: #LINE# #TAB# #TAB# context = {'quote_id': id, 'user': user, 'is_secret': is_secret} #LINE# #TAB# else: #LINE# #TAB# #TAB# context = {'quote_id': id, 'user': None, 'is_secret': is_secret} #LINE# #TAB# quote = get_quote(request) #LINE# #TAB# context['quote'] = quote #LINE# #TAB# return context"
#LINE# #TAB# nodes = G.nodes() #LINE# #TAB# if len(nodes) > 1: #LINE# #TAB# #TAB# return True #LINE# #TAB# else: #LINE# #TAB# #TAB# return False
"#LINE# #TAB# if line_or_func in (int, float): #LINE# #TAB# #TAB# return line_or_func #LINE# #TAB# elif line_or_func.isdigit(): #LINE# #TAB# #TAB# return lines.index(line_or_func) + 1 #LINE# #TAB# else: #LINE# #TAB# #TAB# return None"
"#LINE# #TAB# string_data = {} #LINE# #TAB# for key, value in data.items(): #LINE# #TAB# #TAB# if isinstance(value, dict): #LINE# #TAB# #TAB# #TAB# string_data[key] = foo(value) #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# string_data[key] = str(value) #LINE# #TAB# return string_data"
"#LINE# #TAB# with open(src_file,'md5') as f: #LINE# #TAB# #TAB# md5sum = hashlib.md5(f.read()).hexdigest() #LINE# #TAB# return md5sum"
#LINE# #TAB# if key_func is not None: #LINE# #TAB# #TAB# if callable(key_func): #LINE# #TAB# #TAB# #TAB# return key_func #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# return import_string(key_func) #LINE# #TAB# return default_key_func
"#LINE# #TAB# with open(file_name, 'r') as f: #LINE# #TAB# #TAB# if load_order: #LINE# #TAB# #TAB# #TAB# var_order = json.load(f) #LINE# #TAB# #TAB# bdd.add(var_order) #LINE# #TAB# return bdd"
"#LINE# #TAB# parts = path.split('.') #LINE# #TAB# if len(parts) <= 2: #LINE# #TAB# #TAB# return None #LINE# #TAB# lang1, lang2 = parts[0], parts[1] #LINE# #TAB# if lang1 == '': #LINE# #TAB# #TAB# return lang2, lang1 #LINE# #TAB# if lang2 == '': #LINE# #TAB# #TAB# return lang1, lang2 #LINE# #TAB# return lang1, lang2"
#LINE# #TAB# filtered = [] #LINE# #TAB# for id in ids: #LINE# #TAB# #TAB# match = cls.id_re.match(id) #LINE# #TAB# #TAB# if match: #LINE# #TAB# #TAB# #TAB# filtered.append(id) #LINE# #TAB# return filtered
"#LINE# #TAB# pd.DataFrame) ->pd.DataFrame: #LINE# #TAB# if interactiones.iloc[:, (0)]!= interactiones.iloc[:, (1)]!= interactiones. #LINE# #TAB# #TAB# iloc: int = interactiones.iloc[:, (0)] #LINE# #TAB# if interactiones.iloc[:, (1)]!= interactiones.iloc[:, (2)]!= interactiones.iloc[:, #LINE# #TAB# #TAB# (0)] and interactiones.iloc[:, (2)]!= interactiones.iloc[:, (1)]): #LINE# #TAB# #TAB# logging.info(f'Removed interactiontion {interactiones.iloc[:, (0)]} from {interactions}' #LINE# #TAB# #TAB# #TAB# ) #LINE# #TAB# return interactiones"
"#LINE# #TAB# with tf.name_scope('foo'): #LINE# #TAB# #TAB# shape = v.get_shape().as_list() #LINE# #TAB# #TAB# size = v.get_size().as_list() #LINE# #TAB# #TAB# index_shape = v.get_index().as_list() #LINE# #TAB# #TAB# index_size = v.get_index().as_list() #LINE# #TAB# total_shape = tf.get_static_shape(shape) #LINE# #TAB# total_shape = tf.get_static_shape(total_shape) #LINE# #TAB# return shape, size, index_shape, total_size"
"#LINE# #TAB# with multiprocessing.ProcessPoolExecutor() as pool: #LINE# #TAB# #TAB# pool.map(foo, inputs) #LINE# #TAB# #TAB# try: #LINE# #TAB# #TAB# #TAB# res = pool.get() #LINE# #TAB# #TAB# finally: #LINE# #TAB# #TAB# #TAB# pool.terminate() #LINE# #TAB# return res"
"#LINE# #TAB# import os #LINE# #TAB# names = [] #LINE# #TAB# for namespace in os.listdir(os.getcwd()): #LINE# #TAB# #TAB# try: #LINE# #TAB# #TAB# #TAB# s = os.path.join(namespace,'snp_sets') #LINE# #TAB# #TAB# #TAB# if os.path.isfile(s): #LINE# #TAB# #TAB# #TAB# #TAB# names.append(s) #LINE# #TAB# #TAB# except Exception: #LINE# #TAB# #TAB# #TAB# pass #LINE# #TAB# return names"
#LINE# #TAB# resp = nexus_client.scripts.delete(name) #LINE# #TAB# return resp
"#LINE# #TAB# #TAB# logging.basicConfig(level=logging.INFO, format=""%(message)s"") #LINE# #TAB# #TAB# logging.getLogger().setLevel(logging.DEBUG) #LINE# #TAB# #TAB# if opts.quiet: #LINE# #TAB# #TAB# #TAB# logging.basicConfig(level=logging.WARNING) #LINE# #TAB# #TAB# #TAB# logging.getLogger().propagate = True"
"#LINE# #TAB# if options is None: #LINE# #TAB# #TAB# options = {} #LINE# #TAB# try: #LINE# #TAB# #TAB# compatibility = options[environment['COMPOSE_COMPATIBILITY']] #LINE# #TAB# except KeyError: #LINE# #TAB# #TAB# compatibility = os.environ.get(environment['COMPOSE_COMPATIBILITY'], 'false') #LINE# #TAB# if compatibility == 'true': #LINE# #TAB# #TAB# return True #LINE# #TAB# try: #LINE# #TAB# #TAB# return validate_compose_version(working_dir, compatibility) #LINE# #TAB# except ValueError: #LINE# #TAB# #TAB# return False"
#LINE# #TAB# start = 0 #LINE# #TAB# stop = start + size #LINE# #TAB# while stop < len(data): #LINE# #TAB# #TAB# yield data[start:stop] #LINE# #TAB# #TAB# start = stop
#LINE# #TAB# if connection: #LINE# #TAB# #TAB# try: #LINE# #TAB# #TAB# #TAB# p = connection.cursor() #LINE# #TAB# #TAB# #TAB# p.execute('PRAGMA foreign_keys = ON') #LINE# #TAB# #TAB# except psycopg2.OperationalError: #LINE# #TAB# #TAB# #TAB# return False #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# return True #LINE# #TAB# else: #LINE# #TAB# #TAB# return False
"#LINE# #TAB# return {'server_default': '127.0.0.1','server_secret': '', #LINE# #TAB# #TAB#'server_type': 'http','server_host': '127.0.0.1','server_port': #LINE# #TAB# #TAB# '443','server_name': '127.0.0.1','server_type': 'http', #LINE# #TAB# #TAB#'server_port': 443,'server_name': 'localhost','server_secure': False, #LINE# #TAB# #TAB#'server_listen': '127.0.0.1:8888','server_listen': '127.0.0.1:8888'}"
"#LINE# #TAB# with safeopen.restore_open(): #LINE# #TAB# #TAB# bucket = get_bucket(content_path) #LINE# #TAB# #TAB# key = bucket.key() #LINE# #TAB# #TAB# result = bucket.put(key, content) #LINE# #TAB# return result"
"#LINE# #TAB# pathname = pathname.replace('\\', '\\\\') #LINE# #TAB# pathname = pathname.replace('`', '\\`') #LINE# #TAB# pathname = pathname.replace('-', '\\-') #LINE# #TAB# return pathname"
"#LINE# #TAB# response.status_code = 204 #LINE# #TAB# response.headers.add('Access-Control-Allow-Origin', '*') #LINE# #TAB# if response.status_code == 401: #LINE# #TAB# #TAB# response.headers.add('Access-Control-Allow-Headers', '*') #LINE# #TAB# #TAB# response.headers.add('Access-Control-Allow-Methods', 'GET, POST, OPTIONS') #LINE# #TAB# #TAB# if request.method == 'OPTIONS': #LINE# #TAB# #TAB# #TAB# response.headers.add('Access-Control-Allow-Headers', 'GET, POST, OPTIONS') #LINE# #TAB# #TAB# if request.method == 'OPTIONS': #LINE# #TAB# #TAB# #TAB# for k, v in request.headers.items(): #LINE# #TAB# #TAB# #TAB# #TAB# response.headers[k] = v #LINE# #TAB# return response"
"#LINE# #TAB# if isinstance(q, units.Quantity): #LINE# #TAB# #TAB# f[key] = q.to_hdf5() #LINE# #TAB# elif isinstance(q, units.LinearOperator): #LINE# #TAB# #TAB# f[key] = q.to_hdf5() #LINE# #TAB# else: #LINE# #TAB# #TAB# raise TypeError"
"#LINE# #TAB# url = f'{url}?{url.query}' #LINE# #TAB# if params: #LINE# #TAB# #TAB# data = parse_qs(params) #LINE# #TAB# #TAB# return url, data #LINE# #TAB# else: #LINE# #TAB# #TAB# idx = 0 #LINE# #TAB# #TAB# while True: #LINE# #TAB# #TAB# #TAB# key = data.pop(idx) #LINE# #TAB# #TAB# #TAB# value = data.pop(key) #LINE# #TAB# #TAB# #TAB# if isinstance(value, list): #LINE# #TAB# #TAB# #TAB# #TAB# data.append(value) #LINE# #TAB# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# #TAB# idx += 1 #LINE# #TAB# #TAB# return url, data"
"#LINE# #TAB# import scipy.spatial as spatial #LINE# #TAB# lon, lat = polygon.shape #LINE# #TAB# area = 0 #LINE# #TAB# for i in range(lon): #LINE# #TAB# #TAB# e = spatial.ConvexHull(polygon[i]) #LINE# #TAB# #TAB# u = spatial.ConvexHull(e) #LINE# #TAB# #TAB# v = spatial.ConvexHull(polygon[i]) #LINE# #TAB# #TAB# lb = spatial.ConvexHull(v) #LINE# #TAB# #TAB# area += abs(lb - lb) #LINE# #TAB# return area"
"#LINE# #TAB# info = {} #LINE# #TAB# try: #LINE# #TAB# #TAB# f = open(file, 'r') #LINE# #TAB# #TAB# for line in f: #LINE# #TAB# #TAB# #TAB# line = line.strip() #LINE# #TAB# #TAB# #TAB# if line.startswith('#'): #LINE# #TAB# #TAB# #TAB# #TAB# continue #LINE# #TAB# #TAB# #TAB# info[line[0]] = line[1:] #LINE# #TAB# #TAB# return info #LINE# #TAB# except IOError: #LINE# #TAB# #TAB# pass #LINE# #TAB# return {}"
#LINE# #TAB# root = section #LINE# #TAB# while section: #LINE# #TAB# #TAB# level = section.level #LINE# #TAB# #TAB# if level == 0: #LINE# #TAB# #TAB# #TAB# return root #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# root = root[:level] + [section] #LINE# #TAB# return root
"#LINE# #TAB# html = ET.tostring(elem, encoding='utf-8') #LINE# #TAB# if html.tag == 'html': #LINE# #TAB# #TAB# html = html.replace('&quot;', '""').replace('&apos;', ""'"") #LINE# #TAB# #TAB# return html #LINE# #TAB# if pretty_print: #LINE# #TAB# #TAB# html = html.replace('&amp;', '&') #LINE# #TAB# #TAB# return html #LINE# #TAB# return html"
#LINE# #TAB# key = str(objid) #LINE# #TAB# md5 = hashlib.md5() #LINE# #TAB# md5.update(table_name) #LINE# #TAB# key = md5.hexdigest() #LINE# #TAB# return key
"#LINE# #TAB# centroid = np.zeros((4, 4)) #LINE# #TAB# for p in points: #LINE# #TAB# #TAB# x = p[0] #LINE# #TAB# #TAB# y = p[1] #LINE# #TAB# #TAB# centroid[0] += x * np.cos(y) #LINE# #TAB# #TAB# centroid[1] += y * np.sin(x) #LINE# #TAB# return centroid"
#LINE# #TAB# if friendly: #LINE# #TAB# #TAB# return 'Alignak live state synthesis' #LINE# #TAB# return 'livesynthesis'
"#LINE# #TAB# lines = string.count('\n', 0, line_offset) #LINE# #TAB# if lines > 0: #LINE# #TAB# #TAB# column = index - string.rfind('\n', 0, line_offset) #LINE# #TAB# else: #LINE# #TAB# #TAB# column = 0 #LINE# #TAB# return lines, column"
#LINE# #TAB# if len(messages) == 1: #LINE# #TAB# #TAB# return messages[0] #LINE# #TAB# return messages[0]
"#LINE# #TAB# resources = skil.api.get_resources(resource_type) #LINE# #TAB# if 'compute' in resource_type: #LINE# #TAB# #TAB# return [skil.resource(resource_type) for resource in resources if #LINE# #TAB# #TAB# #TAB# skil.resource_type_is_compute(resource_type, resource)] #LINE# #TAB# if'storage' in resource_type: #LINE# #TAB# #TAB# return [skil.resource(resource_type) for resource in resources if #LINE# #TAB# #TAB# #TAB# skil.resource_type_is_storage(resource_type, resource)] #LINE# #TAB# return []"
"#LINE# #TAB# _, shape, _ = impact_function.shape #LINE# #TAB# contour_data = np.zeros((shape[0], 2), dtype=impact_function.dtype) #LINE# #TAB# z = 0 #LINE# #TAB# for i in range(shape[0]): #LINE# #TAB# #TAB# for j in range(shape[1]): #LINE# #TAB# #TAB# #TAB# contour_data[i][j] = 1 #LINE# #TAB# #TAB# #TAB# z += 1 #LINE# #TAB# return contour_data"
"#LINE# #TAB# if isinstance(obj, list): #LINE# #TAB# #TAB# return np.concatenate([str(x) for x in obj]) #LINE# #TAB# elif isinstance(obj, str): #LINE# #TAB# #TAB# return obj #LINE# #TAB# return obj"
#LINE# #TAB# if enabled is True: #LINE# #TAB# #TAB# g.enabled = True #LINE# #TAB# else: #LINE# #TAB# #TAB# g.enabled = False
#LINE# #TAB# if word[0].isupper(): #LINE# #TAB# #TAB# return word[0].capitalize() #LINE# #TAB# elif word[1].islower(): #LINE# #TAB# #TAB# return word[0].capitalize() #LINE# #TAB# elif len(word) == 3 and word[1].islower(): #LINE# #TAB# #TAB# return word[0].capitalize() #LINE# #TAB# else: #LINE# #TAB# #TAB# return ''
#LINE# #TAB# try: #LINE# #TAB# #TAB# return type(obj)() #LINE# #TAB# except TypeError: #LINE# #TAB# #TAB# return obj
#LINE# #TAB# fields = [] #LINE# #TAB# for x in get_fields(config): #LINE# #TAB# #TAB# if x not in fields: #LINE# #TAB# #TAB# #TAB# fields.append(x) #LINE# #TAB# return fields
#LINE# #TAB# import socket #LINE# #TAB# _table = str(table) #LINE# #TAB# try: #LINE# #TAB# #TAB# if '.' in table: #LINE# #TAB# #TAB# #TAB# _table = table.split('.') #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# _table = table.split('.')[-1] #LINE# #TAB# #TAB# return socket.AF_INET #LINE# #TAB# except Exception: #LINE# #TAB# #TAB# return socket.AF_INET6
#LINE# #TAB# if n == 0: #LINE# #TAB# #TAB# return '0' #LINE# #TAB# elif n < 10: #LINE# #TAB# #TAB# return f'1' #LINE# #TAB# elif n < 11: #LINE# #TAB# #TAB# return f'2' #LINE# #TAB# elif n < 12: #LINE# #TAB# #TAB# return f'3' #LINE# #TAB# else: #LINE# #TAB# #TAB# return f'0'
"#LINE# #TAB# if isinstance(obj, datetime): #LINE# #TAB# #TAB# return obj.isoformat() #LINE# #TAB# elif isinstance(obj, date): #LINE# #TAB# #TAB# return obj.isoformat() #LINE# #TAB# elif isinstance(obj, datetime): #LINE# #TAB# #TAB# return obj.isoformat() #LINE# #TAB# else: #LINE# #TAB# #TAB# return ''"
"#LINE# #TAB# for k in reversed(itertools.chain.from_iterable(nested_dict.values())): #LINE# #TAB# #TAB# if isinstance(nested_dict[k], dict): #LINE# #TAB# #TAB# #TAB# return foo(nested_dict[k]) #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# return nested_dict[k]"
#LINE# #TAB# data = [] #LINE# #TAB# lines = description.split('\n') #LINE# #TAB# for line in lines: #LINE# #TAB# #TAB# if line.startswith(':'): #LINE# #TAB# #TAB# #TAB# line = line[1:] #LINE# #TAB# #TAB# if line.endswith(':'): #LINE# #TAB# #TAB# #TAB# line = line[:-1] #LINE# #TAB# #TAB# data.append(line) #LINE# #TAB# return data
#LINE# #TAB# with _lock: #LINE# #TAB# #TAB# if _client._singleton_instance is None: #LINE# #TAB# #TAB# #TAB# _client._singleton_instance = Client() #LINE# #TAB# #TAB# return _client._singleton_instance
#LINE# #TAB# if i == 0: #LINE# #TAB# #TAB# return i #LINE# #TAB# elif i == 1: #LINE# #TAB# #TAB# return i #LINE# #TAB# elif i == 2: #LINE# #TAB# #TAB# return i + 1 #LINE# #TAB# elif i == 3: #LINE# #TAB# #TAB# return i + 2 #LINE# #TAB# else: #LINE# #TAB# #TAB# return i
"#LINE# #TAB# dirname = cls.task_dir_path(task_id) #LINE# #TAB# filename = os.path.join(dirname, cls.foo_name(task_id)) #LINE# #TAB# if not os.path.exists(filename): #LINE# #TAB# #TAB# if create: #LINE# #TAB# #TAB# #TAB# os.mkdir(filename) #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# with open(filename, 'w') as f: #LINE# #TAB# #TAB# #TAB# #TAB# f.write(f.read()) #LINE# #TAB# else: #LINE# #TAB# #TAB# return filename"
"#LINE# #TAB# attr_list = conn.search_s(filtr, dn, attr) #LINE# #TAB# if attr_list is None: #LINE# #TAB# #TAB# return None #LINE# #TAB# else: #LINE# #TAB# #TAB# ret = attr_list[0] #LINE# #TAB# #TAB# for item in attr_list: #LINE# #TAB# #TAB# #TAB# if item == filtr: #LINE# #TAB# #TAB# #TAB# #TAB# return item #LINE# #TAB# return None"
#LINE# #TAB# try: #LINE# #TAB# #TAB# return state['tap_stream'][tap_stream_id]['version'] #LINE# #TAB# except KeyError: #LINE# #TAB# #TAB# return 'unknown'
"#LINE# #TAB# root = ElementTree.fromstring(raw.text) #LINE# #TAB# name = root.tag.split('}')[0] #LINE# #TAB# attrib = {} #LINE# #TAB# for child in root: #LINE# #TAB# #TAB# attrib[child[0]] = child[1] #LINE# #TAB# return name, attrib"
#LINE# #TAB# try: #LINE# #TAB# #TAB# float(val) #LINE# #TAB# #TAB# return True #LINE# #TAB# except ValueError: #LINE# #TAB# #TAB# return False
"#LINE# #TAB# graph = graph.copy() #LINE# #TAB# if edges is None: #LINE# #TAB# #TAB# edges = graph.edges() #LINE# #TAB# for u, v in edges: #LINE# #TAB# #TAB# c = graph.get_edge(u, v) #LINE# #TAB# #TAB# graph.delete_edge((u, v)) #LINE# #TAB# #TAB# graph.add_edge((v, c)) #LINE# #TAB# for u, v in graph.edges(): #LINE# #TAB# #TAB# c = graph.get_edge(u, v) #LINE# #TAB# #TAB# graph.delete_edge((u, v)) #LINE# #TAB# #TAB# graph.add_edge((v, c)) #LINE# #TAB# return graph"
"#LINE# #TAB# with open(filename, 'w') as fobj: #LINE# #TAB# #TAB# fobj.truncate() #LINE# #TAB# #TAB# return filename"
#LINE# #TAB# if dir == 0: #LINE# #TAB# #TAB# return Fore.GREEN #LINE# #TAB# elif dir == 1: #LINE# #TAB# #TAB# return Fore.BLUE #LINE# #TAB# elif dir == 2: #LINE# #TAB# #TAB# return Fore.RED #LINE# #TAB# else: #LINE# #TAB# #TAB# return Fore.BLUE
"#LINE# #TAB# if pexpect is None: #LINE# #TAB# #TAB# raise ImportError(""pexpect unavailable, use paramiko"") #LINE# #TAB# cmd ='ssh -f '+ server #LINE# #TAB# if keyfile: #LINE# #TAB# #TAB# cmd +='-i'+ keyfile #LINE# #TAB# cmd +='exit' #LINE# #TAB# p = pexpect.spawn(cmd) #LINE# #TAB# while True: #LINE# #TAB# #TAB# try: #LINE# #TAB# #TAB# #TAB# p.expect('[Pp]assword:', timeout=.1) #LINE# #TAB# #TAB# except pexpect.TIMEOUT: #LINE# #TAB# #TAB# #TAB# pass #LINE# #TAB# #TAB# except pexpect.EOF: #LINE# #TAB# #TAB# #TAB# return True #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# return False"
#LINE# #TAB# if len(numbers) < 1: #LINE# #TAB# #TAB# return 0 #LINE# #TAB# elif numbers[0] == 1: #LINE# #TAB# #TAB# return 1 + numbers[1] #LINE# #TAB# else: #LINE# #TAB# #TAB# return numbers[0] ** 2
"#LINE# #TAB# for keyword in ('X', 'Y'): #LINE# #TAB# #TAB# if keyword in span.keywords: #LINE# #TAB# #TAB# #TAB# yield keyword, int(span.keywords[keyword]) #LINE# #TAB# for keyword in ('Q', 'Q'): #LINE# #TAB# #TAB# if keyword in span.keywords: #LINE# #TAB# #TAB# #TAB# yield keyword, int(span.keywords[keyword]) #LINE# #TAB# for keyword in ('X', 'Y'): #LINE# #TAB# #TAB# yield keyword, len(span.keywords) #LINE# #TAB# for keyword in ('Z', 't'): #LINE# #TAB# #TAB# yield keyword"
"#LINE# #TAB# ret = int(integer_string) #LINE# #TAB# if ret < 0 or ret == 0 and strict: #LINE# #TAB# #TAB# raise ValueError() #LINE# #TAB# if cutoff: #LINE# #TAB# #TAB# return min(ret, cutoff) #LINE# #TAB# return ret"
#LINE# #TAB# for i in range(p.GetNAtoms()): #LINE# #TAB# #TAB# if p.GetMolFrags(i)[0]!= 'I': #LINE# #TAB# #TAB# #TAB# yield i
"#LINE# #TAB# window_x = Screen().current_canvas.width #LINE# #TAB# window_y = Screen().current_canvas.height #LINE# #TAB# if x is not None and y is not None: #LINE# #TAB# #TAB# window_x += x #LINE# #TAB# #TAB# window_y += y #LINE# #TAB# else: #LINE# #TAB# #TAB# window_x = None #LINE# #TAB# #TAB# window_y = None #LINE# #TAB# return window_x, window_y"
"#LINE# #TAB# strainT = tuple([geneT[g] for g in genesO]) #LINE# #TAB# assert len(strainT) == len(geneT) #LINE# #TAB# assert geneT[0] in genesT #LINE# #TAB# assert strainT[0] in genesO #LINE# #TAB# xT = geneT[len(geneT) - 1, 0] #LINE# #TAB# yT = strainT[len(strainT) - 1, 0] #LINE# #TAB# if len(yT) == 0: #LINE# #TAB# #TAB# return None, None #LINE# #TAB# zT = strainT[len(geneT):] #LINE# #TAB# if len(zT) == 0: #LINE# #TAB# #TAB# return genesO[0], genesO[1] #LINE# #TAB# else: #LINE# #TAB# #TAB# return zT, genesO[1]"
"#LINE# #TAB# if isinstance(obj, Reference): #LINE# #TAB# #TAB# return obj._id #LINE# #TAB# elif isinstance(obj, list): #LINE# #TAB# #TAB# return [foo(i) for i in obj] #LINE# #TAB# elif isinstance(obj, dict): #LINE# #TAB# #TAB# return {key: foo(val) for key, val in obj.items()} #LINE# #TAB# return {}"
"#LINE# #TAB# for k, v in doc.items(): #LINE# #TAB# #TAB# if isinstance(v, dict): #LINE# #TAB# #TAB# #TAB# for entity in v: #LINE# #TAB# #TAB# #TAB# #TAB# doc[k] = merge_entities(doc[k], entity) #LINE# #TAB# return doc"
#LINE# #TAB# if day is None: #LINE# #TAB# #TAB# day = date.today().weekday() #LINE# #TAB# return day.month
#LINE# #TAB# try: #LINE# #TAB# #TAB# return config['urls'] #LINE# #TAB# except KeyError: #LINE# #TAB# #TAB# return []
#LINE# #TAB# debit_key = hashlib.sha256(address.encode('utf-8')).hexdigest() #LINE# #TAB# key = debit_key[16:20] #LINE# #TAB# key_hex = base64.b64decode(key) #LINE# #TAB# return key_hex
"#LINE# #TAB# if isinstance(params, dict): #LINE# #TAB# #TAB# if 'index' in params: #LINE# #TAB# #TAB# #TAB# return params['index'] #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# return 1 #LINE# #TAB# else: #LINE# #TAB# #TAB# return 0"
#LINE# #TAB# x = np.random.random(3) #LINE# #TAB# z = np.random.random(3) - 0.5 #LINE# #TAB# return z * np.sin(x / 2) + z * np.cos(x / 2) + z * np.sin(y / 2 #LINE# #TAB# #TAB# ) + z * np.cos(y / 2) + z * np.sin(z / 2) + z * np.cos(y / 2 #LINE# #TAB# #TAB# ) + z * np.sin(z / 2) + z * np.cos(z / 2) + z * np.sin(y / 2)
"#LINE# #TAB# assert isinstance(fnode, astroid.FunctionDef) #LINE# #TAB# pnames = [] #LINE# #TAB# for p in fnode.parameters: #LINE# #TAB# #TAB# if isinstance(p.expr, astroid.Name): #LINE# #TAB# #TAB# #TAB# pname = p.expr.name #LINE# #TAB# #TAB# elif isinstance(p.expr, astroid.Name): #LINE# #TAB# #TAB# #TAB# pname = p.expr.id #LINE# #TAB# #TAB# if pname.startswith('_'): #LINE# #TAB# #TAB# #TAB# continue #LINE# #TAB# #TAB# if pname.endswith('_list'): #LINE# #TAB# #TAB# #TAB# pnames.extend(foo(pname)) #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# pnames.append(pname) #LINE# #TAB# return pnames"
"#LINE# #TAB# if fin_txt.startswith(""#""): #LINE# #TAB# #TAB# return [] #LINE# #TAB# aliases = {} #LINE# #TAB# for line in fin_txt.splitlines(): #LINE# #TAB# #TAB# if line.startswith(""#""): #LINE# #TAB# #TAB# #TAB# continue #LINE# #TAB# #TAB# alias, val = line.strip().split() #LINE# #TAB# #TAB# if alias[0].isdigit(): #LINE# #TAB# #TAB# #TAB# aliases[alias[0]] = int(val) #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# aliases[alias] = line.strip() #LINE# #TAB# return aliases"
#LINE# #TAB# username = request.session['username'] #LINE# #TAB# password = request.session['password'] #LINE# #TAB# try: #LINE# #TAB# #TAB# auth_type = request.registry.settings['SESSION_TYPE'] #LINE# #TAB# except KeyError: #LINE# #TAB# #TAB# return None #LINE# #TAB# try: #LINE# #TAB# #TAB# auth_score = int(password) #LINE# #TAB# except ValueError: #LINE# #TAB# #TAB# return None #LINE# #TAB# if auth_type == 'password': #LINE# #TAB# #TAB# return request.session['password'] #LINE# #TAB# return None
#LINE# #TAB# dev_template = InputTemplate(dev_type=dev_type) #LINE# #TAB# dev = dev_template.create_input(dev_name) #LINE# #TAB# return dev
"#LINE# #TAB# if isinstance(obj, dict): #LINE# #TAB# #TAB# for k in list(obj.keys()): #LINE# #TAB# #TAB# #TAB# v = obj.pop(k) #LINE# #TAB# #TAB# #TAB# obj[k] = TitleCase(v) #LINE# #TAB# elif isinstance(obj, list): #LINE# #TAB# #TAB# for v in obj: #LINE# #TAB# #TAB# #TAB# obj = TitleCase(v) #LINE# #TAB# return obj"
"#LINE# #TAB# with open(path, 'r') as f: #LINE# #TAB# #TAB# f.read() #LINE# #TAB# #TAB# if f.endswith('.json'): #LINE# #TAB# #TAB# #TAB# return 'json' #LINE# #TAB# #TAB# elif f.endswith('.yaml'): #LINE# #TAB# #TAB# #TAB# return 'yaml' #LINE# #TAB# #TAB# elif f.endswith('.json'): #LINE# #TAB# #TAB# #TAB# return 'json' #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# return 'UNKNOWN'"
"#LINE# #TAB# with open(os.path.join(device, 'conf.json'), 'r') as f: #LINE# #TAB# #TAB# json.dump(device.conf, f, indent=2) #LINE# #TAB# #TAB# return True"
"#LINE# #TAB# try: #LINE# #TAB# #TAB# return datetime.date(int(year), int(month), int(weekday)) #LINE# #TAB# except ValueError: #LINE# #TAB# #TAB# return 0"
#LINE# #TAB# for method in BLACKLIST_URLS: #LINE# #TAB# #TAB# if url.endswith(method): #LINE# #TAB# #TAB# #TAB# return True #LINE# #TAB# return False
#LINE# #TAB# if not val: #LINE# #TAB# #TAB# return False #LINE# #TAB# if str(val).lower() == 'true': #LINE# #TAB# #TAB# return True #LINE# #TAB# return False
#LINE# #TAB# if len(results) == 0: #LINE# #TAB# #TAB# raise ValueError('No results') #LINE# #TAB# if len(results) > 1: #LINE# #TAB# #TAB# raise ValueError('More than one result') #LINE# #TAB# return results[0]
#LINE# #TAB# if np.isscalar(data) or len(data)!= 1: #LINE# #TAB# #TAB# return data #LINE# #TAB# key = list(data.keys())[0] #LINE# #TAB# if len(data[key]) == 1 and key in dataset.vdims: #LINE# #TAB# #TAB# return data[key][0]
#LINE# #TAB# try: #LINE# #TAB# #TAB# np.asarray(x) #LINE# #TAB# #TAB# if x.ndim == 2: #LINE# #TAB# #TAB# #TAB# return x.sum(axis=1) == 0 #LINE# #TAB# #TAB# elif x.ndim == 3: #LINE# #TAB# #TAB# #TAB# return x.sum(axis=1) == 0 #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# return x == list(range(ndim)) #LINE# #TAB# except: #LINE# #TAB# #TAB# raise ValueError
#LINE# #TAB# import os #LINE# #TAB# import errno #LINE# #TAB# try: #LINE# #TAB# #TAB# os.makedirs(path) #LINE# #TAB# except OSError as exc: #LINE# #TAB# #TAB# if exc.errno == errno.EEXIST: #LINE# #TAB# #TAB# #TAB# pass #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# raise
"#LINE# #TAB# if remove_brackets_content: #LINE# #TAB# #TAB# trans = pangloss.remove_content_in_brackets(trans, ""[]"") #LINE# #TAB# trans = fr_nlp("" "".join(trans.split()[:])) #LINE# #TAB# trans = "" "".join([token.lower_ for token in trans if not token.is_punct]) #LINE# #TAB# return trans"
#LINE# #TAB# a = name.count('.') #LINE# #TAB# if a: #LINE# #TAB# #TAB# ext = name.split('.')[-1] #LINE# #TAB# #TAB# if ext in VALID_SUFFIXES: #LINE# #TAB# #TAB# #TAB# return True #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# return False #LINE# #TAB# else: #LINE# #TAB# #TAB# return False
"#LINE# #TAB# python = textwrap.dedent( #LINE# #TAB# #TAB# ) #LINE# #TAB# python = textwrap.dedent( #LINE# #TAB# #TAB# ) #LINE# #TAB# python = textwrap.dedent(python) #LINE# #TAB# python = textwrap.dedent( #LINE# #TAB# #TAB# ) #LINE# #TAB# with open('entry.py', 'w') as f: #LINE# #TAB# #TAB# python += f.read() #LINE# #TAB# python += '\n' #LINE# #TAB# return python"
#LINE# #TAB# if value.lower() == 'true': #LINE# #TAB# #TAB# return 'TRUE' #LINE# #TAB# elif value.lower() == 'false': #LINE# #TAB# #TAB# return 'FALSE' #LINE# #TAB# else: #LINE# #TAB# #TAB# return value
#LINE# #TAB# power_state = __nova.compute.power_state(pvm_state) #LINE# #TAB# return power_state
#LINE# #TAB# slope = (y2 - y1 * x2 - x1) / (x2 - x1) #LINE# #TAB# return slope
#LINE# #TAB# try: #LINE# #TAB# #TAB# if len(data) > 1: #LINE# #TAB# #TAB# #TAB# return True #LINE# #TAB# #TAB# return False #LINE# #TAB# except TypeError: #LINE# #TAB# #TAB# return False
"#LINE# #TAB# try: #LINE# #TAB# #TAB# return datetime.date(iso_year, 1, 4).isocalendar()[1] #LINE# #TAB# except Exception: #LINE# #TAB# #TAB# return 0"
#LINE# #TAB# t.value = t.value[1:].upper() #LINE# #TAB# return t
"#LINE# #TAB# sa = mac2str(source) #LINE# #TAB# sa += b'\x00' * (4 - len(sa)) #LINE# #TAB# mac = mac2str(dest) #LINE# #TAB# mic = MIC(mic_key, sa, sa + b'\x00' * (4 - len(sa)) + b'\x00' * (4 - len(sa)) + data) #LINE# #TAB# return mic.decrypt(data)[:4]"
"#LINE# #TAB# try: #LINE# #TAB# #TAB# return np.sqrt(np.sum(np.square(a), axis=0)) #LINE# #TAB# except np.linalg.LinAlgError: #LINE# #TAB# #TAB# return 0.0"
"#LINE# #TAB# d = {} #LINE# #TAB# for op, blob_name, version in ssa: #LINE# #TAB# #TAB# d.setdefault(op, []).append((blob_name, version)) #LINE# #TAB# return d"
"#LINE# #TAB# assert n >= 0.0 #LINE# #TAB# if n == 1: #LINE# #TAB# #TAB# return x1, y1 #LINE# #TAB# elif n == 2: #LINE# #TAB# #TAB# return x2, y2 #LINE# #TAB# else: #LINE# #TAB# #TAB# dx = abs(x2 - x1) / n #LINE# #TAB# #TAB# dy = abs(y2 - y1) / n #LINE# #TAB# #TAB# return x1 + dx, y1 + dy"
"#LINE# #TAB# if isinstance(pObj, ClusterNode): #LINE# #TAB# #TAB# return True #LINE# #TAB# elif isinstance(pObj, Hypothesis_Node): #LINE# #TAB# #TAB# return True #LINE# #TAB# elif isinstance(pObj, Hypothesis_Node): #LINE# #TAB# #TAB# return True #LINE# #TAB# return False"
"#LINE# #TAB# val = None #LINE# #TAB# try: #LINE# #TAB# #TAB# if os.path.exists(filename): #LINE# #TAB# #TAB# #TAB# with open(filename, 'r') as f: #LINE# #TAB# #TAB# #TAB# #TAB# val = f.read() #LINE# #TAB# except IOError: #LINE# #TAB# #TAB# pass #LINE# #TAB# return val"
"#LINE# #TAB# ""Monkey-patch urllib3 with PyOpenSSL-backed SSL-support."" #LINE# #TAB# import urllib3 #LINE# #TAB# urllib3.urlopen = urllib3.urlopen #LINE# #TAB# urllib3.urlopen.sslContext = PyOpenSSLContext #LINE# #TAB# import urllib3.urlopen #LINE# #TAB# if hasattr(urllib3, 'urlopen'): #LINE# #TAB# #TAB# urllib3.urlopen.sslContext = PyOpenSSLContext"
"#LINE# #TAB# if not value: #LINE# #TAB# #TAB# return False #LINE# #TAB# if not re.match('^[0-9a-fA-F]{8}$', value): #LINE# #TAB# #TAB# return False #LINE# #TAB# try: #LINE# #TAB# #TAB# int(value) #LINE# #TAB# #TAB# return True #LINE# #TAB# except: #LINE# #TAB# #TAB# return False"
#LINE# #TAB# try: #LINE# #TAB# #TAB# yield from gen #LINE# #TAB# except KeyboardInterrupt: #LINE# #TAB# #TAB# if logger: #LINE# #TAB# #TAB# #TAB# logger.info('Aborted.') #LINE# #TAB# #TAB# raise
#LINE# #TAB# try: #LINE# #TAB# #TAB# return int(value) #LINE# #TAB# except ValueError: #LINE# #TAB# #TAB# try: #LINE# #TAB# #TAB# #TAB# return float(value) #LINE# #TAB# #TAB# except ValueError: #LINE# #TAB# #TAB# #TAB# return value
"#LINE# #TAB# if node.children[0] == node: #LINE# #TAB# #TAB# if isinstance(node.children[1], ast.Op): #LINE# #TAB# #TAB# #TAB# return [node.children[0]] #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# return [node.children[0]] #LINE# #TAB# return [node]"
"#LINE# #TAB# _path = Path(AbstractSample._full_path('map_data')) #LINE# #TAB# df = pd.read_csv(_path, encoding='latin1') #LINE# #TAB# return df.iloc[:size]"
"#LINE# #TAB# import os #LINE# #TAB# try: #LINE# #TAB# #TAB# source_id = int(source[0]) #LINE# #TAB# #TAB# if source_id not in os.listdir(os.getcwd()): #LINE# #TAB# #TAB# #TAB# os.mkdir(os.path.join(os.getcwd(), source_id)) #LINE# #TAB# #TAB# with open('{}/data.json'.format(source_id)) as f: #LINE# #TAB# #TAB# #TAB# data = json.load(f) #LINE# #TAB# #TAB# #TAB# return data #LINE# #TAB# except: #LINE# #TAB# #TAB# return {}"
"#LINE# #TAB# if isinstance(place, PetriNet): #LINE# #TAB# #TAB# for p in net.places: #LINE# #TAB# #TAB# #TAB# if p == place: #LINE# #TAB# #TAB# #TAB# #TAB# net.remove(p) #LINE# #TAB# #TAB# #TAB# #TAB# return net #LINE# #TAB# #TAB# pass #LINE# #TAB# return net"
#LINE# #TAB# s = Suite(name=name) #LINE# #TAB# s.unique = True #LINE# #TAB# s.rows = cdf.rows #LINE# #TAB# s.cols = cdf.cols #LINE# #TAB# return s
"#LINE# #TAB# f = open(filename, 'rb') #LINE# #TAB# f.seek(2048) #LINE# #TAB# posbyte = 0 #LINE# #TAB# allsentences = '' #LINE# #TAB# for _ in list(range(32)): #LINE# #TAB# #TAB# tt = f.read(32) #LINE# #TAB# #TAB# s1 = tt.strip('\x00') #LINE# #TAB# #TAB# if s1!= '': #LINE# #TAB# #TAB# #TAB# allsentences += s1 + '\n' #LINE# #TAB# #TAB# posbyte += 32 #LINE# #TAB# tt = f.read(1024) #LINE# #TAB# s1 = tt.strip('\x00') #LINE# #TAB# if s1!= '': #LINE# #TAB# #TAB# allsentences += s1 + '\n' #LINE# #TAB# f.close() #LINE# #TAB# return allsentences"
#LINE# #TAB# with open(json_fn) as f: #LINE# #TAB# #TAB# data = json.load(f) #LINE# #TAB# data = [item for sublist in data for item in sublist] #LINE# #TAB# return data
"#LINE# #TAB# if num_bins is None: #LINE# #TAB# #TAB# num_bins=len(G.nodes()) #LINE# #TAB# bin_labels = range(num_bins) #LINE# #TAB# attr_values = pd.Series([data[attr] for u, v, key, data in G.nodes(data=True)]) #LINE# #TAB# cats = pd.qcut(x=attr_values, q=num_bins, labels=bin_labels) #LINE# #TAB# colors = get_colors(num_bins, cmap, start, stop) #LINE# #TAB# return [colors[int(cat)] if pd.notnull(cat) else na_color for cat in cats]"
"#LINE# #TAB# if isinstance(schema, dict): #LINE# #TAB# #TAB# if schema['type'] == 'array': #LINE# #TAB# #TAB# #TAB# return '_array_' #LINE# #TAB# #TAB# elif schema['type'] == 'array': #LINE# #TAB# #TAB# #TAB# return '_array_' #LINE# #TAB# #TAB# elif schema['type'] == 'date': #LINE# #TAB# #TAB# #TAB# return '_date_' #LINE# #TAB# #TAB# elif schema['type'] == 'datetime': #LINE# #TAB# #TAB# #TAB# return '_datetime_' #LINE# #TAB# return ''"
#LINE# #TAB# try: #LINE# #TAB# #TAB# return array.get_volume(module.params['name']) #LINE# #TAB# except Exception: #LINE# #TAB# #TAB# return None
#LINE# #TAB# try: #LINE# #TAB# #TAB# parts = sender.split(' ') #LINE# #TAB# except ValueError: #LINE# #TAB# #TAB# parts = sender #LINE# #TAB# for part in parts: #LINE# #TAB# #TAB# try: #LINE# #TAB# #TAB# #TAB# if part == 'foo': #LINE# #TAB# #TAB# #TAB# #TAB# return _from_name(parts[0]) #LINE# #TAB# #TAB# #TAB# if part == 'name': #LINE# #TAB# #TAB# #TAB# #TAB# return _from_name(parts[1]) #LINE# #TAB# #TAB# except ValueError: #LINE# #TAB# #TAB# #TAB# pass #LINE# #TAB# return None
"#LINE# #TAB# if cache.writeable(): #LINE# #TAB# #TAB# status = return_status.HANDLED #LINE# #TAB# else: #LINE# #TAB# #TAB# times = e.payload['times'] #LINE# #TAB# #TAB# timeout = random.uniform(0.001, cache.timeout(times)) #LINE# #TAB# #TAB# cache.post_fifo(Event(signal=signals.cache_file_write, payload={ #LINE# #TAB# #TAB# #TAB# 'times': times + 1}), period=timeout, times=1, deferred=True) #LINE# #TAB# #TAB# status = return_status.HANDLED #LINE# #TAB# return status"
"#LINE# #TAB# b0 = 0.0215 #LINE# #TAB# b1 = 0.2122 #LINE# #TAB# b2 = 0 #LINE# #TAB# Cphi = -0.00084 #LINE# #TAB# C0 = Cphi / (2 * sqrt(np_abs(i2c['In'] * i2c['Cl']))) #LINE# #TAB# C1 = 0 #LINE# #TAB# alph1 = 2 #LINE# #TAB# alph2 = -9 #LINE# #TAB# omega = -9 #LINE# #TAB# valid = T == 298.15 #LINE# #TAB# return b0, b1, b2, C0, C1, alph1, alph2, omega, valid"
"#LINE# #TAB# elements = browser.execute_script( #LINE# #TAB# #TAB# ""return ($ || jQuery)(arguments[0]).get();"", selector) #LINE# #TAB# elements = elements or [] #LINE# #TAB# if not elements: #LINE# #TAB# #TAB# return browser.execute_script( #LINE# #TAB# #TAB# #TAB# ""return ($ || jQuery)(arguments[0]).get();"", selector) #LINE# #TAB# return elements[0]"
#LINE# #TAB# ar = np.asanyarray(ar) #LINE# #TAB# ar.sort() #LINE# #TAB# if sort: #LINE# #TAB# #TAB# ar = ar[ar.argsort()] #LINE# #TAB# return ar
#LINE# #TAB# if noupdate: #LINE# #TAB# #TAB# cr.update(xmlid) #LINE# #TAB# else: #LINE# #TAB# #TAB# try: #LINE# #TAB# #TAB# #TAB# cr.delete(xmlid) #LINE# #TAB# #TAB# except: #LINE# #TAB# #TAB# #TAB# if warn: #LINE# #TAB# #TAB# #TAB# #TAB# pass #LINE# #TAB# return cr
#LINE# #TAB# indices = [] #LINE# #TAB# for char in string: #LINE# #TAB# #TAB# if len(char) > width: #LINE# #TAB# #TAB# #TAB# indices.append(char) #LINE# #TAB# return indices
#LINE# #TAB# sample = np.asarray(sample) #LINE# #TAB# n = len(sample) #LINE# #TAB# if n < 2: #LINE# #TAB# #TAB# return sample #LINE# #TAB# elif interval < 0.95: #LINE# #TAB# #TAB# return sample + interval #LINE# #TAB# else: #LINE# #TAB# #TAB# return sample - interval
#LINE# #TAB# if impact_function.op =='store': #LINE# #TAB# #TAB# return True #LINE# #TAB# else: #LINE# #TAB# #TAB# return False
"#LINE# #TAB# locked = False #LINE# #TAB# if os.path.isfile(filepath): #LINE# #TAB# #TAB# try: #LINE# #TAB# #TAB# #TAB# f = open(filepath, 'r') #LINE# #TAB# #TAB# #TAB# f.close() #LINE# #TAB# #TAB# #TAB# locked = True #LINE# #TAB# #TAB# except IOError: #LINE# #TAB# #TAB# #TAB# pass #LINE# #TAB# else: #LINE# #TAB# #TAB# return locked"
#LINE# #TAB# d = Contours._max_tangents_per_image(contour) #LINE# #TAB# return d
"#LINE# #TAB# return { #LINE# #TAB# #TAB# key: format_value_for_spreadsheet(value) #LINE# #TAB# #TAB# for key, value in data_dicts.items() #LINE# #TAB# }"
#LINE# #TAB# if key not in rundata: #LINE# #TAB# #TAB# raise KeyError('key not found in rundata') #LINE# #TAB# return rundata[key]
"#LINE# #TAB# try: #LINE# #TAB# #TAB# result = requests.get(url, headers={'User-Agent': USER_AGENT}) #LINE# #TAB# #TAB# result.raise_for_status() #LINE# #TAB# #TAB# return result.text #LINE# #TAB# except Exception: #LINE# #TAB# #TAB# raise"
"#LINE# #TAB# X_train = scipy.sparse.dia_matrix((X_test, X_history), shape=(n_components, #LINE# #TAB# #TAB# X_test.shape[1]), dtype=X_test.dtype) #LINE# #TAB# X_history = scipy.sparse.dia_matrix((X_history, X_history), shape=(n_components, #LINE# #TAB# #TAB# X_test.shape[1])) #LINE# #TAB# S = scipy.sparse.linalg.svd(X_train) #LINE# #TAB# Y_train = S.dot(S) #LINE# #TAB# Y_history = S.dot(Y_train) #LINE# #TAB# return Y_train, Y_history"
"#LINE# #TAB# x_order = np.argsort(x_samples) #LINE# #TAB# geno_order = np.argsort(geno_samples) #LINE# #TAB# return x_order, geno_order"
#LINE# #TAB# try: #LINE# #TAB# #TAB# shutil.rmtree(dirpath) #LINE# #TAB# except OSError as e: #LINE# #TAB# #TAB# if e.errno!= errno.ENOENT: #LINE# #TAB# #TAB# #TAB# raise
"#LINE# #TAB# s = _socket.socket() #LINE# #TAB# s.setsockopt(_socket.SOL_SOCKET, _socket.SO_REUSEADDR, True) #LINE# #TAB# s.setsockopt(_socket.SOL_SOCKET, _socket.SO_REUSEPORT, timeout) #LINE# #TAB# s.connect(proxy) #LINE# #TAB# s.setsockopt(_socket.SOL_SOCKET, _socket.SO_REUSEADDR, True) #LINE# #TAB# return s"
#LINE# #TAB# if object_dict.get('value') == 'true': #LINE# #TAB# #TAB# return True #LINE# #TAB# if object_dict.get('value') == 'false': #LINE# #TAB# #TAB# return False #LINE# #TAB# if parent_object_dict and parent_object_dict.get('value') == 'true': #LINE# #TAB# #TAB# return True #LINE# #TAB# return False
#LINE# #TAB# gui = str(gui) #LINE# #TAB# if kernel is None: #LINE# #TAB# #TAB# kernel = default_kernel #LINE# #TAB# try: #LINE# #TAB# #TAB# int(gui) #LINE# #TAB# except ValueError: #LINE# #TAB# #TAB# raise ValueError('Invalid GUI name: %s' % gui) #LINE# #TAB# else: #LINE# #TAB# #TAB# return True
"#LINE# #TAB# lv[(lt1[0]), :] = lt1[0] + lt2[0] #LINE# #TAB# lv[(lt2[0]), :] = lv[(lt1[1]), :] + lt2[1] #LINE# #TAB# return lv"
"#LINE# #TAB# obs = xw.sum(axis=1) #LINE# #TAB# Nw = weights.shape[0] #LINE# #TAB# s = np.zeros((Nw, Nw), dtype=float) #LINE# #TAB# for ii in range(Nw): #LINE# #TAB# #TAB# for jj in range(Nw): #LINE# #TAB# #TAB# #TAB# iif = ii[jj] #LINE# #TAB# #TAB# #TAB# s[iif, jj] = 1.0 / weights[iif] * (xw[iii] - xw[jj]) #LINE# #TAB# return s"
#LINE# #TAB# if len(ops) == 1: #LINE# #TAB# #TAB# return ops[0] #LINE# #TAB# elif len(ops) > 1: #LINE# #TAB# #TAB# new_ops = [] #LINE# #TAB# #TAB# for op in ops: #LINE# #TAB# #TAB# #TAB# new_ops += foo(op) #LINE# #TAB# #TAB# return new_ops #LINE# #TAB# else: #LINE# #TAB# #TAB# return None
"#LINE# #TAB# newd = dict(d) #LINE# #TAB# for k in d: #LINE# #TAB# #TAB# if isinstance(d[k], dict): #LINE# #TAB# #TAB# #TAB# newd[k] = foo(d[k]) #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# newd[k] = d[k] #LINE# #TAB# return newd"
"#LINE# #TAB# return get_blockchain_overview(coin_symbol=coin_symbol, api_key=api_key)[ #LINE# #TAB# #TAB# 'height']"
"#LINE# #TAB# hash_obj = hashlib.sha256() #LINE# #TAB# with open(image_file, 'rb') as f: #LINE# #TAB# #TAB# while True: #LINE# #TAB# #TAB# #TAB# data = f.read(1024) #LINE# #TAB# #TAB# #TAB# if not data: #LINE# #TAB# #TAB# #TAB# #TAB# break #LINE# #TAB# #TAB# #TAB# hash_obj.update(data) #LINE# #TAB# return hash_obj.hexdigest()[:7]"
"#LINE# #TAB# if isinstance(file_path_or_generator, str): #LINE# #TAB# #TAB# for line in file_path_or_generator: #LINE# #TAB# #TAB# #TAB# line = line.strip() #LINE# #TAB# #TAB# #TAB# if not line: #LINE# #TAB# #TAB# #TAB# #TAB# return #LINE# #TAB# #TAB# if isinstance(line, dict): #LINE# #TAB# #TAB# #TAB# for k, v in line.items(): #LINE# #TAB# #TAB# #TAB# #TAB# yield k, v"
#LINE# #TAB# text = [] #LINE# #TAB# for email in emails: #LINE# #TAB# #TAB# for part in email: #LINE# #TAB# #TAB# #TAB# text += f'{part} <{email}>' #LINE# #TAB# #TAB# text += '\n' #LINE# #TAB# return text
"#LINE# #TAB# for i in range(data.shape[0]): #LINE# #TAB# #TAB# if data[i, 0] == 'E': #LINE# #TAB# #TAB# #TAB# data[i, 0] = 'nu' #LINE# #TAB# #TAB# if data[i, 1] == 'N': #LINE# #TAB# #TAB# #TAB# data[i, 1] = 'e' #LINE# #TAB# return data"
#LINE# #TAB# df = df[config['engine'].contains(config['contaminant_tag']).any( #LINE# #TAB# #TAB# )] #LINE# #TAB# return df
"#LINE# #TAB# if overwrite: #LINE# #TAB# #TAB# files = [os.path.join(output_dir, filename) for filename in barcodes] #LINE# #TAB# else: #LINE# #TAB# #TAB# files = [os.path.join(output_dir, filename) for filename in barcodes] #LINE# #TAB# return files"
"#LINE# #TAB# sz_str = '{0} {1}'.format(int(time.time()), int(time.time())) #LINE# #TAB# sh_str = '{0} {1}'.format(int(time.time()), int(time.time())) #LINE# #TAB# sz = int(sz_str) #LINE# #TAB# sh = int(sh_str) #LINE# #TAB# return {'sz': sz,'sh': sh}"
#LINE# #TAB# out_list = [] #LINE# #TAB# for i1 in range(len(input_list)): #LINE# #TAB# #TAB# for i2 in range(len(input_list) - 1): #LINE# #TAB# #TAB# #TAB# if input_list[i1] == input_list[i2]: #LINE# #TAB# #TAB# #TAB# #TAB# out_list.append(input_list[i1]) #LINE# #TAB# #TAB# #TAB# #TAB# break #LINE# #TAB# return out_list
"#LINE# #TAB# if ax is None: #LINE# #TAB# #TAB# fig, ax = plt.subplots(1, 1, figsize=(15, 10)) #LINE# #TAB# fig.scatter(net_exposures, '-o', 'compute_cap_exposures') #LINE# #TAB# ax.set_xlabel('Time [s]', fontsize=12) #LINE# #TAB# ax.set_ylabel('Duration [s]', fontsize=12) #LINE# #TAB# if ax is None: #LINE# #TAB# #TAB# ax = plt.gca() #LINE# #TAB# return ax"
"#LINE# #TAB# fd = os.open(os.devnull, os.O_RDONLY) #LINE# #TAB# fd.seek(num_bytes, 0) #LINE# #TAB# buf = fd.read() #LINE# #TAB# fd.close() #LINE# #TAB# if num_bytes > 0: #LINE# #TAB# #TAB# x = bytes(buf) #LINE# #TAB# #TAB# _free(buf) #LINE# #TAB# #TAB# return x #LINE# #TAB# else: #LINE# #TAB# #TAB# return None"
"#LINE# #TAB# titles = [] #LINE# #TAB# with open('rfc-index.txt', 'r') as f: #LINE# #TAB# #TAB# for line in f: #LINE# #TAB# #TAB# #TAB# split_line = line.split('\t') #LINE# #TAB# #TAB# #TAB# if len(split_line) > 1: #LINE# #TAB# #TAB# #TAB# #TAB# titles.append(split_line[0]) #LINE# #TAB# return titles"
"#LINE# #TAB# qfont = QFont() #LINE# #TAB# for key, value in font.properties().items(): #LINE# #TAB# #TAB# if value is not None: #LINE# #TAB# #TAB# #TAB# qfont.setAttribute(key, value) #LINE# #TAB# return qfont"
#LINE# #TAB# while True: #LINE# #TAB# #TAB# try: #LINE# #TAB# #TAB# #TAB# yield receiver.recv() #LINE# #TAB# #TAB# except Exception: #LINE# #TAB# #TAB# #TAB# break
#LINE# #TAB# return {'id': '{0}'.format(fake.id())}
#LINE# #TAB# module_path = os.path.dirname(__file__) #LINE# #TAB# return module_path + '/foo'
"#LINE# #TAB# if n.dtype == str: #LINE# #TAB# #TAB# col_names = [col_name for col_name in n.columns] #LINE# #TAB# elif n.dtype == int: #LINE# #TAB# #TAB# col_names = [col_name for col_name in n.columns] #LINE# #TAB# else: #LINE# #TAB# #TAB# raise Exception('Unrecognized data type.') #LINE# #TAB# t = namedtuple('Column', n.columns) #LINE# #TAB# for col_name in col_names: #LINE# #TAB# #TAB# t[col_name] = t[col_name] #LINE# #TAB# return t"
#LINE# #TAB# if f1 and f2: #LINE# #TAB# #TAB# return f1 * f2 #LINE# #TAB# if f1: #LINE# #TAB# #TAB# return f1 #LINE# #TAB# if f2 and f1 < f2: #LINE# #TAB# #TAB# return f2 #LINE# #TAB# return f1
#LINE# #TAB# if item is None: #LINE# #TAB# #TAB# yield #LINE# #TAB# else: #LINE# #TAB# #TAB# yield item
"#LINE# #TAB# routes = [] #LINE# #TAB# for route in app.config['routes']: #LINE# #TAB# #TAB# if '.' in route: #LINE# #TAB# #TAB# #TAB# route = '.'.join([route, route]) #LINE# #TAB# #TAB# if not route.startswith('/'): #LINE# #TAB# #TAB# #TAB# route = '/' + route #LINE# #TAB# #TAB# routes.append(route) #LINE# #TAB# return routes"
#LINE# #TAB# code1 = list(s) #LINE# #TAB# code2 = list(s) #LINE# #TAB# for i in range(len(code1)): #LINE# #TAB# #TAB# code1.append(code1[i]) #LINE# #TAB# #TAB# code2.append(code2[i]) #LINE# #TAB# return code2
"#LINE# #TAB# obj = cls() #LINE# #TAB# for attr in dir(cls): #LINE# #TAB# #TAB# obj = getattr(obj, attr) #LINE# #TAB# if isinstance(obj, models.ManyToManyRel): #LINE# #TAB# #TAB# pass #LINE# #TAB# elif isinstance(obj, models.DateField): #LINE# #TAB# #TAB# obj = models.DateField() #LINE# #TAB# elif isinstance(obj, models.TimeField): #LINE# #TAB# #TAB# obj = models.TimeField() #LINE# #TAB# return {'type': obj, 'prefix': type_prefix + '_date'}"
"#LINE# #TAB# arr = np.asarray(arr) #LINE# #TAB# if diff is not None: #LINE# #TAB# #TAB# diff = _to_blob(diff) #LINE# #TAB# if arr.ndim == 2: #LINE# #TAB# #TAB# arr = arr[:, :, (None)] #LINE# #TAB# return arr"
#LINE# #TAB# for node in nodes: #LINE# #TAB# #TAB# if node.tag_ == 'nav_extender': #LINE# #TAB# #TAB# #TAB# return node
"#LINE# #TAB# if incremental_state is not None: #LINE# #TAB# #TAB# full_key = _get_full_module_key(module, key) #LINE# #TAB# #TAB# if full_key in incremental_state: #LINE# #TAB# #TAB# #TAB# return incremental_state[full_key] #LINE# #TAB# return False"
#LINE# #TAB# if 'SLURM_CONFIG' in os.environ: #LINE# #TAB# #TAB# config = os.environ['SLURM_CONFIG'] #LINE# #TAB# else: #LINE# #TAB# #TAB# config = None #LINE# #TAB# return config
"#LINE# #TAB# if isinstance(uri, Namespace): #LINE# #TAB# #TAB# return uri.uri #LINE# #TAB# return uri"
#LINE# #TAB# if user is not None: #LINE# #TAB# #TAB# user = f'{user}' #LINE# #TAB# if password is not None: #LINE# #TAB# #TAB# password = f'{password}' #LINE# #TAB# return f'{user}:{password}'
"#LINE# #TAB# chain = {} #LINE# #TAB# data = textwrap.dedent(data) #LINE# #TAB# for line in data.splitlines(True): #LINE# #TAB# #TAB# if not line.strip(): #LINE# #TAB# #TAB# #TAB# continue #LINE# #TAB# #TAB# if '=' not in line: #LINE# #TAB# #TAB# #TAB# k, v = line.split('=', 1) #LINE# #TAB# #TAB# #TAB# chain[k] = v #LINE# #TAB# return chain"
"#LINE# #TAB# if type(t) is list: #LINE# #TAB# #TAB# r = [] #LINE# #TAB# #TAB# for l in t: #LINE# #TAB# #TAB# #TAB# if isinstance(l, dict): #LINE# #TAB# #TAB# #TAB# #TAB# r.extend(foo(l)) #LINE# #TAB# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# #TAB# r.append(l) #LINE# #TAB# #TAB# elif type(t) is tuple: #LINE# #TAB# #TAB# #TAB# r = [] #LINE# #TAB# #TAB# #TAB# for l in t: #LINE# #TAB# #TAB# #TAB# #TAB# if not isinstance(l, str): #LINE# #TAB# #TAB# #TAB# #TAB# #TAB# r.append(l) #LINE# #TAB# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# #TAB# r.append(l) #LINE# #TAB#"
#LINE# #TAB# if flags & 4: #LINE# #TAB# #TAB# return '%s' % ('b' if flags & 8 else 'a') #LINE# #TAB# elif flags & 20: #LINE# #TAB# #TAB# return '%d' % int(flags & 16) #LINE# #TAB# elif flags & 80: #LINE# #TAB# #TAB# return '%d' % int(flags & 80) #LINE# #TAB# else: #LINE# #TAB# #TAB# return 'unknown'
"#LINE# #TAB# penn_tree = re.sub('\\s+','', penn_tree) #LINE# #TAB# penn_tree = re.sub('\\s+','', penn_tree) #LINE# #TAB# return penn_tree"
#LINE# #TAB# index2 = index + pd.to_datetime(index.dt) #LINE# #TAB# index = index2 - pd.to_datetime(index.dt) #LINE# #TAB# return index
#LINE# #TAB# if ch == 'foo': #LINE# #TAB# #TAB# return config['foo'][service_name] #LINE# #TAB# elif ch == 'bar': #LINE# #TAB# #TAB# return bar(service_name) #LINE# #TAB# return {}
#LINE# #TAB# global _vi #LINE# #TAB# return _vi
"#LINE# #TAB# if file is None: #LINE# #TAB# #TAB# config = default_config() #LINE# #TAB# else: #LINE# #TAB# #TAB# config = configparser.ConfigParser() #LINE# #TAB# try: #LINE# #TAB# #TAB# if os.path.exists(file): #LINE# #TAB# #TAB# #TAB# f = open(file, 'r') #LINE# #TAB# #TAB# #TAB# config.readfp(f) #LINE# #TAB# #TAB# #TAB# return json.loads(f.read()) #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# return {} #LINE# #TAB# except IOError: #LINE# #TAB# #TAB# return {}"
"#LINE# #TAB# try: #LINE# #TAB# #TAB# subprocess.check_output(['youtube-dl', '--help']) #LINE# #TAB# #TAB# return True #LINE# #TAB# except subprocess.CalledProcessError: #LINE# #TAB# #TAB# return False"
"#LINE# #TAB# result = np.zeros((n_features, n_features)) #LINE# #TAB# n_off_diag = int((n_features ** 2 - n_features) / 2) #LINE# #TAB# for i in range(n_features): #LINE# #TAB# #TAB# result[i, i] = 0.1 * lam_scale * prng.randn(n_off_diag) + 0.25 * lam_scale #LINE# #TAB# return result"
"#LINE# #TAB# datamean = data.mean(axis=2).imag #LINE# #TAB# datameanmin, datameanmax = rtlib.sigma_clip(datamean.flatten()) #LINE# #TAB# good = n.where((datamean > datameanmin) & (datamean < datameanmax)) #LINE# #TAB# noise = datamean[good].std() #LINE# #TAB# logger.debug('Clipped to %d%% of data (%.3f to %.3f). Noise = %.3f.' % #LINE# #TAB# #TAB# (100.0 * len(good[0]) / len(datamean.flatten()), datameanmin, #LINE# #TAB# #TAB# datameanmax, noise)) #LINE# #TAB# return noise"
#LINE# #TAB# rr = [] #LINE# #TAB# for rea in fvaMinmax: #LINE# #TAB# #TAB# if rea < 0.2: #LINE# #TAB# #TAB# #TAB# continue #LINE# #TAB# #TAB# if flux < 0.2: #LINE# #TAB# #TAB# #TAB# rr.append(rea) #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# rr.append(rea) #LINE# #TAB# return rr
#LINE# #TAB# if value == 'on': #LINE# #TAB# #TAB# return 'on' #LINE# #TAB# if value == 'off': #LINE# #TAB# #TAB# return 'off' #LINE# #TAB# if value =='red': #LINE# #TAB# #TAB# return'red' #LINE# #TAB# if value == 'y': #LINE# #TAB# #TAB# return 'green' #LINE# #TAB# return value
#LINE# #TAB# if is_tdt(path): #LINE# #TAB# #TAB# return True #LINE# #TAB# return False
"#LINE# #TAB# if is_float(n): #LINE# #TAB# #TAB# if n > 0.5: #LINE# #TAB# #TAB# #TAB# raise ValueError('Cannot convert {} to int'.format(n)) #LINE# #TAB# #TAB# return int(n) #LINE# #TAB# if isinstance(n, int): #LINE# #TAB# #TAB# return n #LINE# #TAB# if isinstance(n, str) and n.isdigit(): #LINE# #TAB# #TAB# return f'{n}' #LINE# #TAB# else: #LINE# #TAB# #TAB# return n"
"#LINE# #TAB# user = context['request'].user #LINE# #TAB# obj = User.objects.get(slug=slug) #LINE# #TAB# if not obj: #LINE# #TAB# #TAB# return {'error': 'User not found'} #LINE# #TAB# if title: #LINE# #TAB# #TAB# return {'title': format_html(slug), 'text': format_html(obj.title)} #LINE# #TAB# if limit: #LINE# #TAB# #TAB# return {'limit': limit, 'title': format_html(slug)}"
"#LINE# #TAB# assert_type_or_raise(array, dict, parameter_name='array') #LINE# #TAB# data = Receivable.validate_array(array) #LINE# #TAB# data['id'] = u(array.get('id')) #LINE# #TAB# data['first_name'] = u(array.get('first_name')) #LINE# #TAB# data['last_name'] = u(array.get('last_name')) if array.get('last_name' #LINE# #TAB# #TAB# ) is not None else None #LINE# #TAB# data['first_email'] = u(array.get('first_email')) if array.get('first_email' #LINE# #TAB# #TAB# ) is not None else None #LINE# #TAB# data['last_email_hash'] = u(array.get('last_email_hash')) if array.get('last_email_hash' #LINE# #TAB# #TAB# ) is not None else None #LINE# #TAB# return data"
"#LINE# #TAB# startyear -= 1 #LINE# #TAB# try: #LINE# #TAB# #TAB# y = int(startyear) #LINE# #TAB# #TAB# return y - 1, y #LINE# #TAB# except ValueError: #LINE# #TAB# #TAB# pass #LINE# #TAB# try: #LINE# #TAB# #TAB# y = int(startyear) + 1 #LINE# #TAB# #TAB# return y - 1, y #LINE# #TAB# except ValueError: #LINE# #TAB# #TAB# return False, False"
#LINE# #TAB# image = Image.open(io.BytesIO(image_bytes)) #LINE# #TAB# return image
"#LINE# #TAB# l = g #LINE# #TAB# if isinstance(rt, rt.Tuple): #LINE# #TAB# #TAB# if len(l) == 2: #LINE# #TAB# #TAB# #TAB# for i in l: #LINE# #TAB# #TAB# #TAB# #TAB# g.l[i] = rt.value(i) #LINE# #TAB# elif isinstance(rt, rt.Set): #LINE# #TAB# #TAB# for i in l: #LINE# #TAB# #TAB# #TAB# g.l[i] = rt.set_get(i, -Value) #LINE# #TAB# return True"
"#LINE# #TAB# r = [] #LINE# #TAB# for i in range(len(sys.argv)): #LINE# #TAB# #TAB# if sys.argv[i] == ['-c', '-f', '__init__.py']: #LINE# #TAB# #TAB# #TAB# r.append('/bin/sh') #LINE# #TAB# #TAB# if i == 0: #LINE# #TAB# #TAB# #TAB# r.append('/bin/sh') #LINE# #TAB# #TAB# if i == 1: #LINE# #TAB# #TAB# #TAB# r.append('/bin/bash') #LINE# #TAB# #TAB# #TAB# r.append('/bin/bash') #LINE# #TAB# #TAB# return r #LINE# #TAB# return []"
#LINE# #TAB# for child in root.iter('softwareReleaseMetadata'): #LINE# #TAB# #TAB# print(child) #LINE# #TAB# return
"#LINE# #TAB# #TAB# if not host: #LINE# #TAB# #TAB# #TAB# return None #LINE# #TAB# #TAB# if ':' in host: #LINE# #TAB# #TAB# #TAB# host, port = host.rsplit(':', 1) #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# host, port = host, port #LINE# #TAB# #TAB# try: #LINE# #TAB# #TAB# #TAB# return int(host), port #LINE# #TAB# #TAB# except ValueError: #LINE# #TAB# #TAB# #TAB# pass #LINE# #TAB# #TAB# return host, port"
#LINE# #TAB# result = MapConverter.to_nullable_map(value) #LINE# #TAB# return result if result!= None else {}
#LINE# #TAB# logging.info('Got content of type {}'.format(type(content))) #LINE# #TAB# if type(content) == str: #LINE# #TAB# #TAB# return content #LINE# #TAB# response = {} #LINE# #TAB# response['Content-Type'] = 'application/json' #LINE# #TAB# try: #LINE# #TAB# #TAB# json_response = json.loads(content) #LINE# #TAB# except Exception as e: #LINE# #TAB# #TAB# return str(e) #LINE# #TAB# if 'error' in json_response: #LINE# #TAB# #TAB# return str(json_response['error']) #LINE# #TAB# return 500
"#LINE# #TAB# C = np.zeros((X.shape[1], num_folds)) #LINE# #TAB# for i in range(num_folds): #LINE# #TAB# #TAB# C[:, :, (i)] = np.dot(X[:, :, (i)], X[:, :, (i)]) #LINE# #TAB# return C"
"#LINE# #TAB# img = np.expand_dims(img, 0) #LINE# #TAB# out = ndimage.plot_with_points(img, ncomp, norm_type=norm_type) #LINE# #TAB# if norm_type == 'perc': #LINE# #TAB# #TAB# out = ndimage.norm.perc_image(out) #LINE# #TAB# return out"
"#LINE# #TAB# if user.is_active and user.is_superuser: #LINE# #TAB# #TAB# return True #LINE# #TAB# model_name = model.__name__ #LINE# #TAB# if user.has_perm('add', model_name): #LINE# #TAB# #TAB# return True #LINE# #TAB# if user.has_perm('change', model_name): #LINE# #TAB# #TAB# return True #LINE# #TAB# if user.has_perm('delete', model_name): #LINE# #TAB# #TAB# return True #LINE# #TAB# return False"
"#LINE# #TAB# if 'fid' in params: #LINE# #TAB# #TAB# fid = params['fid'] #LINE# #TAB# if 'img' in fid: #LINE# #TAB# #TAB# img = imread(fid) #LINE# #TAB# elif 'format' in params: #LINE# #TAB# #TAB# img = imread(params['format']) #LINE# #TAB# if 'handle' in params: #LINE# #TAB# #TAB# handle = open(params['handle'], 'r') #LINE# #TAB# else: #LINE# #TAB# #TAB# handle = open(params['filename'], 'r') #LINE# #TAB# data = handle.read() #LINE# #TAB# handle.close() #LINE# #TAB# return data"
#LINE# #TAB# try: #LINE# #TAB# #TAB# C = 1 / (-xm / (1 - a) - xm / a + math.exp(a) * xm / a) #LINE# #TAB# except OverflowError: #LINE# #TAB# #TAB# C = 1 / (-xm / (1 - a)) #LINE# #TAB# return C
"#LINE# #TAB# matches = [] #LINE# #TAB# for f in find_artist_fields(artist, albumartist): #LINE# #TAB# #TAB# if f: #LINE# #TAB# #TAB# #TAB# matches.append(f) #LINE# #TAB# return matches"
"#LINE# #TAB# b = cls() #LINE# #TAB# for k, v in dic.items(): #LINE# #TAB# #TAB# if isinstance(v, dict): #LINE# #TAB# #TAB# #TAB# b.bar = v #LINE# #TAB# #TAB# elif isinstance(v, list): #LINE# #TAB# #TAB# #TAB# b.bar = [cls.bar(v) for v in v] #LINE# #TAB# #TAB# elif isinstance(v, Bar): #LINE# #TAB# #TAB# #TAB# b.bar = v #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# raise NotImplementedError() #LINE# #TAB# return b"
#LINE# #TAB# epilog = parser.parse() #LINE# #TAB# return epilog
#LINE# #TAB# neuron.h.load_file('morphology.hoc') #LINE# #TAB# neuron.h.load_file('biophysics.hoc') #LINE# #TAB# neuron.h.load_file('template.hoc') #LINE# #TAB# print('Loading cell bAC217_L5_BP_d0cc8d7615') #LINE# #TAB# cell = neuron.h.bAC217_L5_BP_d0cc8d7615(1 if add_synapses else 0) #LINE# #TAB# return cell
#LINE# #TAB# for i in times_needed: #LINE# #TAB# #TAB# keys = i.keys() #LINE# #TAB# #TAB# sorted_keys = sorted(keys) #LINE# #TAB# #TAB# result = np.zeros(len(sorted_keys)) #LINE# #TAB# #TAB# for k in sorted_keys: #LINE# #TAB# #TAB# #TAB# result[k] = i - times_needed[k] #LINE# #TAB# #TAB# print('Found {} times in database'.format(len(result))) #LINE# #TAB# return result
#LINE# #TAB# if name.startswith(prefix + '%'): #LINE# #TAB# #TAB# return name #LINE# #TAB# if name.endswith('.'): #LINE# #TAB# #TAB# return name[:-1] #LINE# #TAB# return name
"#LINE# #TAB# if not dst.exists(): #LINE# #TAB# #TAB# dst.mkdir(parents=True, exist_ok=True) #LINE# #TAB# for root in dst.parents.values(): #LINE# #TAB# #TAB# try: #LINE# #TAB# #TAB# #TAB# root.mkdir(parents=True) #LINE# #TAB# #TAB# except OSError: #LINE# #TAB# #TAB# #TAB# pass"
"#LINE# #TAB# if not hasattr(cls, '_upper'): #LINE# #TAB# cls._upper = timestamp #LINE# #TAB# return #LINE# #TAB# if timestamp > cls._upper: #LINE# #TAB# cls._upper = timestamp"
"#LINE# #TAB# with open(file_name, 'rb') as f: #LINE# #TAB# #TAB# image = Image.open(f) #LINE# #TAB# #TAB# texture = image.convert('RGB') #LINE# #TAB# #TAB# resolver.resolve(file_name, texture) #LINE# #TAB# return image"
"#LINE# #TAB# typing.Any) ->tf.Tensor: #LINE# #TAB# mask_shape = attention_mask.shape[0] #LINE# #TAB# attention_input_shape = tf.reshape(attention_input, [mask_shape, 1]) #LINE# #TAB# attention_output = tf.transpose(attention_input_shape, [1, 0, 2]) #LINE# #TAB# return attention_output"
#LINE# #TAB# r = session.get(url) #LINE# #TAB# r.raise_for_status() #LINE# #TAB# return r.url
#LINE# #TAB# #TAB# check = 0 #LINE# #TAB# #TAB# for byte in line: #LINE# #TAB# #TAB# #TAB# check = (check << 5) + ord(byte) #LINE# #TAB# #TAB# return check
#LINE# #TAB# if max_prime == 2: #LINE# #TAB# #TAB# return True #LINE# #TAB# elif max_prime == 3: #LINE# #TAB# #TAB# return True #LINE# #TAB# elif max_prime == 4: #LINE# #TAB# #TAB# return True #LINE# #TAB# elif max_prime == 5: #LINE# #TAB# #TAB# return True #LINE# #TAB# elif max_prime == 6: #LINE# #TAB# #TAB# return True #LINE# #TAB# else: #LINE# #TAB# #TAB# return False
"#LINE# #TAB# obj = cls._si_unit_objects.get(name, None) #LINE# #TAB# if obj is None: #LINE# #TAB# #TAB# myokit_unit = cls._si_units.get(name, None) #LINE# #TAB# #TAB# if myokit_unit is None: #LINE# #TAB# #TAB# #TAB# raise CellMLError('Unknown units name ""' + str(name) + '"".') #LINE# #TAB# #TAB# obj = cls(name, myokit_unit, predefined=True) #LINE# #TAB# #TAB# cls._si_unit_objects[name] = obj #LINE# #TAB# return obj"
"#LINE# #TAB# matching = [] #LINE# #TAB# non_matching = [] #LINE# #TAB# for item in iterable: #LINE# #TAB# #TAB# if cond(item): #LINE# #TAB# #TAB# #TAB# matching.append(item) #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# non_matching.append(item) #LINE# #TAB# return matching, non_matching"
"#LINE# #TAB# return {'name': req.name,'version': req.version, 'display': req. #LINE# #TAB# #TAB# display,'status': req.status, 'tags': req.tags}"
#LINE# #TAB# import numpy as np #LINE# #TAB# area = np.abs((pt1[0] - pt2[0]) ** 2 + (pt1[1] - pt2[1]) ** 2 + (pt3[0] - #LINE# #TAB# #TAB# pt3[1]) ** 2) #LINE# #TAB# return area
#LINE# #TAB# with threading.Thread(target=callback) as th: #LINE# #TAB# #TAB# th.daemon = True #LINE# #TAB# #TAB# th.start() #LINE# #TAB# #TAB# return th
#LINE# #TAB# if warningstuple[2] is ProxyWarning: #LINE# #TAB# #TAB# return _proxy_map[warningstuple[4]] #LINE# #TAB# else: #LINE# #TAB# #TAB# return warningstuple
"#LINE# #TAB# packet = p.Packet(MsgType.Base) #LINE# #TAB# packet.add_subpacket(p.NoPayload(BaseMsgCode.GetSerialNumber, AckCode.OK)) #LINE# #TAB# return packet"
"#LINE# #TAB# assert kind in (""linear"", ""quadratic"", ""linear"") #LINE# #TAB# k = 0 #LINE# #TAB# for i in range(len(h)): #LINE# #TAB# #TAB# k += 1 #LINE# #TAB# #TAB# mask = foo(h[i], lon, lat, dx, kind=kind) #LINE# #TAB# if plot: #LINE# #TAB# #TAB# plt.plot(mask) #LINE# #TAB# return mask"
"#LINE# #TAB# for task_instance in task_instances: #LINE# #TAB# #TAB# if isinstance(task_instance, astroid.Task): #LINE# #TAB# #TAB# #TAB# return task_instance"
#LINE# #TAB# region_name = service.split(':')[-1] #LINE# #TAB# return {'region_name': region_name}
#LINE# #TAB# if not group: #LINE# #TAB# #TAB# return group #LINE# #TAB# group.host = host #LINE# #TAB# group.scheduled_at = now() #LINE# #TAB# return group
"#LINE# #TAB# theta = 0.06 #LINE# #TAB# valid = T == 298.15 #LINE# #TAB# return theta, valid"
#LINE# #TAB# if op in opc_cache: #LINE# #TAB# #TAB# return opc_cache[op] #LINE# #TAB# size = 0 #LINE# #TAB# if op == OP_PUSHDATA_0: #LINE# #TAB# #TAB# if opc & OP_PUSHDATA_1: #LINE# #TAB# #TAB# #TAB# size += 4 #LINE# #TAB# #TAB# if op == OP_PUSHDATA_2: #LINE# #TAB# #TAB# #TAB# size += 8 #LINE# #TAB# #TAB# if op == OP_PUSHDATA_3: #LINE# #TAB# #TAB# #TAB# size += 4 #LINE# #TAB# return size
#LINE# #TAB# i = 0 #LINE# #TAB# while True: #LINE# #TAB# #TAB# try: #LINE# #TAB# #TAB# #TAB# i += 1 #LINE# #TAB# #TAB# except: #LINE# #TAB# #TAB# #TAB# break #LINE# #TAB# #TAB# try: #LINE# #TAB# #TAB# #TAB# if test is None: #LINE# #TAB# #TAB# #TAB# #TAB# yield i #LINE# #TAB# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# #TAB# yield test(i) #LINE# #TAB# #TAB# except: #LINE# #TAB# #TAB# #TAB# pass
#LINE# #TAB# if rotate: #LINE# #TAB# #TAB# images = rot_images(images) #LINE# #TAB# if flip: #LINE# #TAB# #TAB# images = flip_images(images) #LINE# #TAB# images = rot_images(images) #LINE# #TAB# return images
"#LINE# #TAB# songToSplit = songToSplit.replace(songToSplit[0], start1) #LINE# #TAB# songToSplit = songToSplit.replace(songToSplit[1], start2) #LINE# #TAB# return songToSplit[:2], songToSplit[2:]"
"#LINE# #TAB# data = load_imdb() #LINE# #TAB# if n_gram is None: #LINE# #TAB# #TAB# n_gram = sys.maxsize #LINE# #TAB# X = np.zeros((data.shape[0], data.shape[1])) #LINE# #TAB# for i, tuple_ in enumerate(range(data.shape[1])): #LINE# #TAB# #TAB# X[i, tuple_] = ngram #LINE# #TAB# y = np.zeros((data.shape[0], data.shape[1])) #LINE# #TAB# for i, tuple_ in enumerate(X): #LINE# #TAB# #TAB# y[i, tuple_] = ngram #LINE# #TAB# return X, y"
#LINE# #TAB# if cls._dialect is None: #LINE# #TAB# #TAB# from. dial import Speed dial #LINE# #TAB# #TAB# cls._dialect = Speed dial() #LINE# #TAB# return cls._dialect
#LINE# #TAB# with foo(): #LINE# #TAB# #TAB# try: #LINE# #TAB# #TAB# #TAB# return relation_id(1) #LINE# #TAB# #TAB# except ValueError: #LINE# #TAB# #TAB# #TAB# pass #LINE# #TAB# #TAB# return None
#LINE# #TAB# #TAB# axis_idx = [] #LINE# #TAB# #TAB# for var in vars_list: #LINE# #TAB# #TAB# #TAB# if var.startswith('_'): #LINE# #TAB# #TAB# #TAB# #TAB# axis_idx.append(fluent.scope.indices[var].idx) #LINE# #TAB# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# #TAB# axis_idx.append(fluent.scope.indices[var]) #LINE# #TAB# #TAB# return axis_idx
"#LINE# #TAB# config_path = find_config_file(config_dir) #LINE# #TAB# if config_path is None: #LINE# #TAB# #TAB# print('Unable to find configuration. Creating default one in', #LINE# #TAB# #TAB# #TAB# config_dir) #LINE# #TAB# #TAB# config_path = create_default_config(config_dir, detect_location) #LINE# #TAB# return config_path"
"#LINE# #TAB# return { #LINE# #TAB# #TAB#'method':'su', #LINE# #TAB# #TAB# 'enable_lru': True, #LINE# #TAB# #TAB# 'kwargs': { #LINE# #TAB# #TAB# #TAB# 'username': spec.become_user(), #LINE# #TAB# #TAB# #TAB# 'password': spec.become_pass(), #LINE# #TAB# #TAB# #TAB# 'python_path': spec.python_path(), #LINE# #TAB# #TAB# #TAB#'su_path': spec.become_exe(), #LINE# #TAB# #TAB# #TAB# 'connect_timeout': spec.timeout(), #LINE# #TAB# #TAB# #TAB#'remote_name': get_remote_name(spec), #LINE# #TAB# #TAB# } #LINE# #TAB# }"
"#LINE# #TAB# read_bytes = f.read(4) #LINE# #TAB# return struct.unpack('>I', read_bytes)[0]"
"#LINE# #TAB# ses, auto_close = ensure_session(engine_or_session) #LINE# #TAB# obj = ses.query(cls).get(_id) #LINE# #TAB# if auto_close: #LINE# #TAB# #TAB# ses.close() #LINE# #TAB# return obj"
"#LINE# #TAB# ngrams = [] #LINE# #TAB# with open(path, ""r"") as f: #LINE# #TAB# #TAB# for line in f: #LINE# #TAB# #TAB# #TAB# ngram = line.strip() #LINE# #TAB# #TAB# #TAB# if ngram!= """": #LINE# #TAB# #TAB# #TAB# #TAB# ngrams.append(ngram) #LINE# #TAB# return ngrams"
#LINE# #TAB# if 'task_name' in details and 'foo' in details['task_name']: #LINE# #TAB# #TAB# return True #LINE# #TAB# return False
"#LINE# #TAB# result = {} #LINE# #TAB# with open(path, 'r') as f: #LINE# #TAB# #TAB# f.readline() #LINE# #TAB# #TAB# while True: #LINE# #TAB# #TAB# #TAB# line = f.readline() #LINE# #TAB# #TAB# #TAB# if line == '': #LINE# #TAB# #TAB# #TAB# #TAB# break #LINE# #TAB# #TAB# #TAB# result[line.strip()] = True #LINE# #TAB# return result"
#LINE# #TAB# try: #LINE# #TAB# #TAB# if _foo is None: #LINE# #TAB# #TAB# #TAB# raise NotImplementedError #LINE# #TAB# #TAB# return _foo() #LINE# #TAB# except AttributeError: #LINE# #TAB# #TAB# pass #LINE# #TAB# return _foo
#LINE# #TAB# doc_type = doc_type.lower() #LINE# #TAB# for declaration in page.DOC_TYPES: #LINE# #TAB# #TAB# if doc_type == declaration.lower(): #LINE# #TAB# #TAB# #TAB# return declaration #LINE# #TAB# return 'UNKNOWN'
"#LINE# #TAB# verts = np.array(vertices) #LINE# #TAB# faces = np.array(faces) #LINE# #TAB# n = np.shape(vertices)[0] #LINE# #TAB# normals = np.zeros(n) #LINE# #TAB# for i, face in enumerate(faces): #LINE# #TAB# #TAB# f0 = faces[i] #LINE# #TAB# #TAB# f1 = faces[i + 1] #LINE# #TAB# #TAB# f2 = faces[i] #LINE# #TAB# #TAB# normal = np.cross(f0 - f1, f2 - f1) #LINE# #TAB# #TAB# normal[i] = normalize(normal[i]) #LINE# #TAB# #TAB# normals[i] = normalize(normal[i]) #LINE# #TAB# return normals"
#LINE# #TAB# w = np.sqrt(qx ** 2 + qy ** 2 + qz ** 2) #LINE# #TAB# if qx.shape[0] == 0: #LINE# #TAB# #TAB# w[0] = 0 #LINE# #TAB# if qy.shape[0] == 0: #LINE# #TAB# #TAB# w[1] = 1 #LINE# #TAB# if qz.shape[0] == 1: #LINE# #TAB# #TAB# w[1] = 1 #LINE# #TAB# return w
"#LINE# #TAB# res = [] #LINE# #TAB# for i in range(0, size): #LINE# #TAB# #TAB# res.append(f'F{i:0{chunk_size}d}') #LINE# #TAB# return res"
"#LINE# #TAB# reqs = set() #LINE# #TAB# with open('requirements.in', 'r') as f: #LINE# #TAB# #TAB# for line in f: #LINE# #TAB# #TAB# #TAB# line = line.strip() #LINE# #TAB# #TAB# #TAB# if not line or line.startswith('#'): #LINE# #TAB# #TAB# #TAB# #TAB# if line.startswith('pipfile.lock'): #LINE# #TAB# #TAB# #TAB# #TAB# #TAB# continue #LINE# #TAB# #TAB# #TAB# #TAB# reqs.add(line.split(' ')[0]) #LINE# #TAB# return reqs"
#LINE# #TAB# for i in l: #LINE# #TAB# #TAB# if i: #LINE# #TAB# #TAB# #TAB# return True #LINE# #TAB# return False
#LINE# #TAB# if path.is_dir(): #LINE# #TAB# #TAB# paths = [path] #LINE# #TAB# else: #LINE# #TAB# #TAB# paths = [path] #LINE# #TAB# for p in paths: #LINE# #TAB# #TAB# if p.name == name: #LINE# #TAB# #TAB# #TAB# return path #LINE# #TAB# #TAB# if p.exists(): #LINE# #TAB# #TAB# #TAB# return p #LINE# #TAB# return None
"#LINE# #TAB# while True: #LINE# #TAB# #TAB# line = f.readline() #LINE# #TAB# #TAB# if not line: #LINE# #TAB# #TAB# #TAB# raise SpacegroupNotFoundError( #LINE# #TAB# #TAB# #TAB# #TAB# 'invalid spacegroup %s, setting %i not found in data base' % #LINE# #TAB# #TAB# #TAB# #TAB# ( spacegroup, setting ) ) #LINE# #TAB# #TAB# if not line.strip(): #LINE# #TAB# #TAB# #TAB# break"
"#LINE# #TAB# for key in dir(obj): #LINE# #TAB# #TAB# if isinstance(obj, key): #LINE# #TAB# #TAB# #TAB# return True #LINE# #TAB# return False"
"#LINE# #TAB# try: #LINE# #TAB# #TAB# return predicate(path, value) #LINE# #TAB# except ValueError: #LINE# #TAB# #TAB# return False"
"#LINE# #TAB# with cls.cls_lock: #LINE# #TAB# #TAB# cls.foo_cache[domain, name, version] = dict() #LINE# #TAB# #TAB# return cls.foo_cache[domain, name, version]"
"#LINE# #TAB# with open(cmds_file, 'r') as f: #LINE# #TAB# #TAB# for line in f: #LINE# #TAB# #TAB# #TAB# if line.startswith('#'): #LINE# #TAB# #TAB# #TAB# #TAB# continue #LINE# #TAB# #TAB# #TAB# for which in which_list: #LINE# #TAB# #TAB# #TAB# #TAB# if which in line: #LINE# #TAB# #TAB# #TAB# #TAB# #TAB# yield 1"
"#LINE# #TAB# if type(time) is str: #LINE# #TAB# #TAB# time = eval(time) #LINE# #TAB# if type(mem) is str: #LINE# #TAB# #TAB# mem = eval(mem) #LINE# #TAB# if type(time) is int or type(mem) is float: #LINE# #TAB# #TAB# time = int(time) #LINE# #TAB# if type(mem) is float: #LINE# #TAB# #TAB# mem = float(mem) #LINE# #TAB# return time, mem"
#LINE# #TAB# size = 0 #LINE# #TAB# for _ in range(handle.size(key)): #LINE# #TAB# #TAB# size += _sizeof(key) #LINE# #TAB# return size
#LINE# #TAB# if mana_div < 10: #LINE# #TAB# #TAB# return 'No' #LINE# #TAB# elif mana_div == 100: #LINE# #TAB# #TAB# return 'A' #LINE# #TAB# elif mana_div == 10: #LINE# #TAB# #TAB# return 'B' #LINE# #TAB# else: #LINE# #TAB# #TAB# return 'W'
#LINE# #TAB# out = np.empty_like(s) #LINE# #TAB# if s.size!= n: #LINE# #TAB# #TAB# for i in range(s.size): #LINE# #TAB# #TAB# #TAB# out[i] = s[i] * 10 ** (n - i) #LINE# #TAB# else: #LINE# #TAB# #TAB# for i in range(s.size): #LINE# #TAB# #TAB# #TAB# out[i] = s[i] * (n - i) / 10 ** (n - i) #LINE# #TAB# return out
"#LINE# #TAB# return {'prefix': 'pipdeptree', 'task': 'pipdeptree.demo','version': #LINE# #TAB# #TAB# 'pipdeptree.version', 'build': 'pipdeptree.build'}"
"#LINE# #TAB# ps_script = ( #LINE# #TAB# #TAB# 'Get-VM snapshots -VMName ""{}"" | Select VMName, SnapshotName | ConvertTo-Json' #LINE# #TAB# #TAB#.format(vm_name)) #LINE# #TAB# rs = run_ps(ps_script) #LINE# #TAB# return rs"
"#LINE# #TAB# CleavingContextList = [] #LINE# #TAB# for c in broker.keys(): #LINE# #TAB# #TAB# if isinstance(c, CleavingContext): #LINE# #TAB# #TAB# #TAB# cleaving_context = c #LINE# #TAB# #TAB# if not cleaving_context.done: #LINE# #TAB# #TAB# #TAB# continue #LINE# #TAB# #TAB# timestamp = now() #LINE# #TAB# #TAB# CleavingContext.store(cleaving_context) #LINE# #TAB# #TAB# CleavingContextList.append((cleaving_context, timestamp)) #LINE# #TAB# return CleavingContextList"
#LINE# #TAB# if os.path.exists(file_path): #LINE# #TAB# #TAB# return True #LINE# #TAB# return False
"#LINE# #TAB# if soup is None: #LINE# #TAB# #TAB# soup = _get_soup_from_url(url) #LINE# #TAB# icon_links = soup.find_all('link', attrs={'rel': 'icon'}) #LINE# #TAB# if icon_links: #LINE# #TAB# #TAB# return icon_links[0]"
"#LINE# #TAB# if not isinstance(number, str): #LINE# #TAB# #TAB# return False #LINE# #TAB# if number[0]!= '4': #LINE# #TAB# #TAB# return False #LINE# #TAB# try: #LINE# #TAB# #TAB# int(number) #LINE# #TAB# except ValueError: #LINE# #TAB# #TAB# return False #LINE# #TAB# return True"
"#LINE# #TAB# username = click.prompt('Please enter your One Codex (email)') #LINE# #TAB# password = click.prompt('Please enter your password', hide_input=True) #LINE# #TAB# if api_key is not None: #LINE# #TAB# #TAB# return username, password #LINE# #TAB# password = click.prompt( #LINE# #TAB# #TAB# 'Please enter your password (typing will be hidden)', hide_input=True) #LINE# #TAB# api_key = fetch_api_key_from_url(username, password, server) #LINE# #TAB# return api_key"
#LINE# #TAB# if value in node.children: #LINE# #TAB# #TAB# return value #LINE# #TAB# else: #LINE# #TAB# #TAB# node.children.append(value) #LINE# #TAB# #TAB# return node
#LINE# #TAB# if type(data) == str: #LINE# #TAB# #TAB# data = bytearray(data) #LINE# #TAB# n = len(data) #LINE# #TAB# crc = 0 #LINE# #TAB# for i in range(n): #LINE# #TAB# #TAB# l = data[i] #LINE# #TAB# #TAB# crc = ((crc << 1) ^ l) & 0x7fffffff #LINE# #TAB# return crc
#LINE# #TAB# _filters[fun.__name__] = fun #LINE# #TAB# return fun
"#LINE# #TAB# if start_time is None: #LINE# #TAB# #TAB# start_time = time.time() #LINE# #TAB# df = pd.DataFrame(source, index=source.index, columns=source.columns) #LINE# #TAB# df.index = pd.to_datetime(start_time, unit='s') #LINE# #TAB# return df"
#LINE# #TAB# test_client = org_client.get_test_client() #LINE# #TAB# for org in test_client.get_orgs(): #LINE# #TAB# #TAB# yield org
#LINE# #TAB# m = Manifold() #LINE# #TAB# s = open(fn) #LINE# #TAB# try: #LINE# #TAB# #TAB# m.from_file(s) #LINE# #TAB# except ValueError: #LINE# #TAB# #TAB# return m #LINE# #TAB# else: #LINE# #TAB# #TAB# return m
#LINE# #TAB# customer_idurl = packetid.CustomerIDURL(backupID) #LINE# #TAB# if backupID not in customer_idurl.keys(): #LINE# #TAB# #TAB# return None #LINE# #TAB# url = customer_idurl.get(customer_idurl.format(backupID)) #LINE# #TAB# if url is None: #LINE# #TAB# #TAB# return None #LINE# #TAB# response = requests.get(url) #LINE# #TAB# if response.status_code == 200: #LINE# #TAB# #TAB# data = response.json() #LINE# #TAB# #TAB# if 'data' in data: #LINE# #TAB# #TAB# #TAB# return data['data'] #LINE# #TAB# return None
"#LINE# #TAB# settings = current_app.config.get('RESTX_XML', {}) #LINE# #TAB# if current_app.debug: #LINE# #TAB# #TAB# settings.setdefault('indent', 4) #LINE# #TAB# #TAB# settings.setdefault('sort_keys', not PY3) #LINE# #TAB# dumped = dumps(data, **settings) + '\n' #LINE# #TAB# resp = make_response(dumped, code) #LINE# #TAB# resp.headers.extend(headers or {}) #LINE# #TAB# return resp"
#LINE# #TAB# s = '' #LINE# #TAB# for c in buff: #LINE# #TAB# #TAB# s += '%02x'% ord(c) #LINE# #TAB# return s
"#LINE# #TAB# if val is None: #LINE# #TAB# #TAB# return False #LINE# #TAB# if not isinstance(val, bool): #LINE# #TAB# #TAB# return False #LINE# #TAB# return val"
#LINE# #TAB# out = sys.stdout #LINE# #TAB# try: #LINE# #TAB# #TAB# old_out = sys.stdout #LINE# #TAB# #TAB# sys.stdout = StringIO() #LINE# #TAB# #TAB# yield out #LINE# #TAB# finally: #LINE# #TAB# #TAB# sys.stdout = old_out
"#LINE# #TAB# paths = set() #LINE# #TAB# for f in maya.cmds.ls(long=True, type='file'): #LINE# #TAB# #TAB# if maya.cmds.referenceQuery(f, isNodeReferenced=True): #LINE# #TAB# #TAB# #TAB# continue #LINE# #TAB# #TAB# texture_path = maya.cmds.getAttr(os.path.normpath('.'.join([f, #LINE# #TAB# #TAB# #TAB# 'fileTextureName']))) #LINE# #TAB# #TAB# if texture_path: #LINE# #TAB# #TAB# #TAB# paths.add(texture_path) #LINE# #TAB# return paths"
"#LINE# #TAB# path = find_file(file_name) #LINE# #TAB# if path is not None: #LINE# #TAB# #TAB# return path, get_format(file_name) #LINE# #TAB# else: #LINE# #TAB# #TAB# return None, None"
"#LINE# #TAB# df = pd.DataFrame({'a': [1, 2, 3, 4, 5], 'b': [6, 7, 8, 9], 'c': [ #LINE# #TAB# #TAB# 'x', 'y', 'z', 'h', 'i']}) #LINE# #TAB# return df"
"#LINE# #TAB# sorted_response = OrderedDict() #LINE# #TAB# for key, value in response.items(): #LINE# #TAB# #TAB# if isinstance(value, list): #LINE# #TAB# #TAB# #TAB# sorted_response[key] = [foo(item) for item in value] #LINE# #TAB# #TAB# elif isinstance(value, dict): #LINE# #TAB# #TAB# #TAB# sorted_response[key] = foo(value) #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# sorted_response[key] = value #LINE# #TAB# return sorted_response"
"#LINE# #TAB# signature = sign_request_signature(req, cano_req, scope) #LINE# #TAB# if 'X-Amz-Credential' not in signature: #LINE# #TAB# #TAB# sig_string = sign_request_signature(req, scope) #LINE# #TAB# else: #LINE# #TAB# #TAB# sig_string = sign_request_signature(req, scope) #LINE# #TAB# return sig_string"
"#LINE# #TAB# pos = cio.tell() #LINE# #TAB# try: #LINE# #TAB# #TAB# pos = struct.unpack('<I', cio.read(1))[0] #LINE# #TAB# except struct.error: #LINE# #TAB# #TAB# pass #LINE# #TAB# return pos"
"#LINE# #TAB# x, y = bb[:4] #LINE# #TAB# if x == 0 and y == 0: #LINE# #TAB# #TAB# return bb #LINE# #TAB# while x > 0 and y > 0: #LINE# #TAB# #TAB# x -= factor #LINE# #TAB# #TAB# y -= factor #LINE# #TAB# return bb"
#LINE# #TAB# try: #LINE# #TAB# #TAB# key = int(chr_str.split('_')[0]) #LINE# #TAB# except ValueError: #LINE# #TAB# #TAB# key = chr_str #LINE# #TAB# return key
#LINE# #TAB# if urlconf is None: #LINE# #TAB# #TAB# urlconf = get_default_urlconf() #LINE# #TAB# if urlconf.resolve(path): #LINE# #TAB# #TAB# return True #LINE# #TAB# try: #LINE# #TAB# #TAB# return urlconf.resolve(path) #LINE# #TAB# except Resolver404: #LINE# #TAB# #TAB# return False
#LINE# #TAB# try: #LINE# #TAB# #TAB# if in_ipython(): #LINE# #TAB# #TAB# #TAB# return True #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# return False #LINE# #TAB# except NameError: #LINE# #TAB# #TAB# return False
#LINE# #TAB# try: #LINE# #TAB# #TAB# n = len(s) #LINE# #TAB# #TAB# if n == 1: #LINE# #TAB# #TAB# #TAB# t = s #LINE# #TAB# #TAB# elif n == 2: #LINE# #TAB# #TAB# #TAB# t = [s] #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# t = list(range(len(s))) #LINE# #TAB# #TAB# return t #LINE# #TAB# except Exception: #LINE# #TAB# #TAB# pass
"#LINE# #TAB# LOG.debug('remove_foo() called') #LINE# #TAB# session = bc.get_writer_session() #LINE# #TAB# binding = session.query(nexus_models_v2.NexusNVEBinding).filter_by(vni #LINE# #TAB# #TAB# =vni, switch_ip=switch_ip, device_id=device_id).one() #LINE# #TAB# if binding: #LINE# #TAB# #TAB# session.delete(binding) #LINE# #TAB# #TAB# session.flush() #LINE# #TAB# #TAB# return binding"
#LINE# #TAB# if value is None: #LINE# #TAB# #TAB# return None #LINE# #TAB# try: #LINE# #TAB# #TAB# return parse_date(value) #LINE# #TAB# except ValueError: #LINE# #TAB# #TAB# return None
#LINE# #TAB# with warnings.catch_warnings(): #LINE# #TAB# #TAB# warnings.simplefilter('ignore') #LINE# #TAB# #TAB# return [x for x in lst] #LINE# #TAB# i = 0 #LINE# #TAB# while i < len(lst): #LINE# #TAB# #TAB# x = lst[i] #LINE# #TAB# #TAB# if key not in x: #LINE# #TAB# #TAB# #TAB# lst[i] = key #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# lst[i] = lst[i - 1] #LINE# #TAB# #TAB# i += 1 #LINE# #TAB# return lst
"#LINE# #TAB# return [{'id': rep.id, 'name': rep.name} for rep in Repository.query. #LINE# #TAB# #TAB# all()]"
"#LINE# #TAB# if not os.path.isdir(restore_dir): #LINE# #TAB# #TAB# return None #LINE# #TAB# files = os.listdir(restore_dir) #LINE# #TAB# for f in files: #LINE# #TAB# #TAB# if f.endswith("".cfg""): #LINE# #TAB# #TAB# #TAB# cfg = os.path.join(restore_dir, f) #LINE# #TAB# #TAB# #TAB# if os.path.isfile(cfg): #LINE# #TAB# #TAB# #TAB# #TAB# return cfg #LINE# #TAB# return None"
"#LINE# #TAB# if not isinstance(trace, tuple): #LINE# #TAB# #TAB# trace = (trace,) #LINE# #TAB# x, y = trace #LINE# #TAB# map = {} #LINE# #TAB# for x, y in zip(x, y): #LINE# #TAB# #TAB# if x == x and y in map: #LINE# #TAB# #TAB# #TAB# map[y] += 1 #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# map[x] = y / len(trace) #LINE# #TAB# return map"
"#LINE# #TAB# assert len(version) == 5 #LINE# #TAB# assert version[3] in ('alpha', 'beta', 'rc', 'final') #LINE# #TAB# parts = 3 #LINE# #TAB# main = '.'.join(str(x) for x in version[:parts]) #LINE# #TAB# sub = '' #LINE# #TAB# if version[3] == 'alpha' and version[4] == 0: #LINE# #TAB# #TAB# git_changeset = _get_git_changeset() #LINE# #TAB# #TAB# if git_changeset: #LINE# #TAB# #TAB# #TAB# sub = '.dev%s' % git_changeset #LINE# #TAB# elif version[3]!= 'final': #LINE# #TAB# #TAB# mapping = {'alpha': 'a', 'beta': 'b', 'rc': 'c'} #LINE# #TAB# #TAB# sub = mapping[version[3]] + str(version[4]) #LINE# #TAB# return main + sub"
"#LINE# #TAB# exit_code = call([api,'show'], stdout=PIPE, stderr=PIPE) #LINE# #TAB# if exit_code: #LINE# #TAB# #TAB# return exit_code #LINE# #TAB# return 0"
"#LINE# #TAB# _, _, header_list = [], [] #LINE# #TAB# for lib in pkg_libraries: #LINE# #TAB# #TAB# try: #LINE# #TAB# #TAB# #TAB# f = open(lib, 'r') #LINE# #TAB# #TAB# #TAB# for line in f: #LINE# #TAB# #TAB# #TAB# #TAB# if line.startswith('!'): #LINE# #TAB# #TAB# #TAB# #TAB# #TAB# if header_list: #LINE# #TAB# #TAB# #TAB# #TAB# #TAB# #TAB# header_list.append('~') #LINE# #TAB# #TAB# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# #TAB# #TAB# header_list.append(line.strip()) #LINE# #TAB# #TAB# finally: #LINE# #TAB# #TAB# #TAB# f.close() #LINE# #TAB# return header_list"
"#LINE# #TAB# obj = {} #LINE# #TAB# with open(path, 'r') as f: #LINE# #TAB# #TAB# for line in f: #LINE# #TAB# #TAB# #TAB# line = line.strip() #LINE# #TAB# #TAB# #TAB# if line.startswith('#'): #LINE# #TAB# #TAB# #TAB# #TAB# continue #LINE# #TAB# #TAB# #TAB# if '=' not in line: #LINE# #TAB# #TAB# #TAB# #TAB# try: #LINE# #TAB# #TAB# #TAB# #TAB# #TAB# key, val = line.split('=', 1) #LINE# #TAB# #TAB# #TAB# #TAB# #TAB# obj[key] = float(val) #LINE# #TAB# #TAB# #TAB# #TAB# except ValueError: #LINE# #TAB# #TAB# #TAB# #TAB# #TAB# pass #LINE# #TAB# return obj"
#LINE# #TAB# for prop_name in model.relationships: #LINE# #TAB# #TAB# props[prop_name] = model.relationships[prop_name]
#LINE# #TAB# logger.info('Looking for maps...') #LINE# #TAB# maps = [] #LINE# #TAB# for d in pkg_resources.iter_entry_points('escher._maps'): #LINE# #TAB# #TAB# if d.name not in maps: #LINE# #TAB# #TAB# #TAB# maps.append(d.name) #LINE# #TAB# logger.info('Done!') #LINE# #TAB# return maps
"#LINE# #TAB# return {'name': wallet_name, 'engine': 'postgres', 'host': 'localhost', #LINE# #TAB# #TAB# 'port': 443, 'user': {'name': 'localhost', 'password': '127.0.0.1', #LINE# #TAB# #TAB# 'type': 'int', 'value': 0}, 'credentials': {'host': '127.0.0.1', #LINE# #TAB# #TAB# 'password': '127.0.0.1', 'type': 'int'}}"
#LINE# #TAB# try: #LINE# #TAB# #TAB# int(s) #LINE# #TAB# #TAB# return True #LINE# #TAB# except ValueError: #LINE# #TAB# #TAB# return False
#LINE# #TAB# cmd = 'flux -f %s' % flux_path #LINE# #TAB# if no_errors: #LINE# #TAB# #TAB# return cmd #LINE# #TAB# return cmd
"#LINE# #TAB# try: #LINE# #TAB# #TAB# return api.nova.servers.list(request) #LINE# #TAB# except Exception: #LINE# #TAB# #TAB# exceptions.handle(request, _('Unable to retrieve server groups.')) #LINE# #TAB# #TAB# return []"
"#LINE# #TAB# parent_dir = os.path.dirname(os.path.realpath(__file__)) #LINE# #TAB# result = {} #LINE# #TAB# fname = os.path.join(parent_dir, file_name) #LINE# #TAB# if force or fname.endswith('.json'): #LINE# #TAB# #TAB# with open(fname, 'r') as fp: #LINE# #TAB# #TAB# #TAB# result = json.load(fp) #LINE# #TAB# else: #LINE# #TAB# #TAB# result = _load_json(fname) #LINE# #TAB# return result"
"#LINE# #TAB# if path is None: #LINE# #TAB# #TAB# path = [] #LINE# #TAB# for key in b: #LINE# #TAB# #TAB# if key in a: #LINE# #TAB# #TAB# #TAB# if key in a: #LINE# #TAB# #TAB# #TAB# #TAB# if isinstance(a[key], dict) and isinstance(b[key], dict): #LINE# #TAB# #TAB# #TAB# #TAB# #TAB# foo(a[key], b[key]) #LINE# #TAB# #TAB# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# #TAB# #TAB# a[key] = b[key] #LINE# #TAB# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# #TAB# continue #LINE# #TAB# a.update(b) #LINE# #TAB# return a"
#LINE# #TAB# for item in delta: #LINE# #TAB# #TAB# item['file_id'] = item['file'] #LINE# #TAB# #TAB# if item['file'] is None: #LINE# #TAB# #TAB# #TAB# raise errors.InconsistentDelta(item['path']) #LINE# #TAB# #TAB# yield item
"#LINE# #TAB# filter_fn = filter_fn or fn_filter #LINE# #TAB# matches = [] #LINE# #TAB# for u in obs: #LINE# #TAB# #TAB# match = _unit_matcher(u, filter_fn, owner, unit_type, tag) #LINE# #TAB# #TAB# if match: #LINE# #TAB# #TAB# #TAB# units = {} #LINE# #TAB# #TAB# #TAB# for k, v in match.items(): #LINE# #TAB# #TAB# #TAB# #TAB# units[k] = v #LINE# #TAB# #TAB# #TAB# if len(units) == 1: #LINE# #TAB# #TAB# #TAB# #TAB# matches.append(u) #LINE# #TAB# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# #TAB# matches.append(u) #LINE# #TAB# return matches"
"#LINE# #TAB# val = isinstance(pe, _bp('PhysicalEntity')) or \ #LINE# #TAB# #TAB# #TAB# isinstance(pe, _bpimpl('PhysicalEntity')) or \ #LINE# #TAB# #TAB# #TAB# isinstance(pe, _bpimpl('PhysicalEntity')) #LINE# #TAB# return val"
"#LINE# #TAB# shelf = {} #LINE# #TAB# shelf['name'] = table.name #LINE# #TAB# shelf['description'] = table.description #LINE# #TAB# shelf['type'] = table.type #LINE# #TAB# if isinstance(table.primary_key, Column): #LINE# #TAB# #TAB# shelf['primary_key'] = table.primary_key.name #LINE# #TAB# if isinstance(table.related_key, Association): #LINE# #TAB# #TAB# shelf['related_key'] = table.related_key.name #LINE# #TAB# return shelf"
"#LINE# #TAB# status = 1 #LINE# #TAB# if os.path.isfile(file): #LINE# #TAB# #TAB# with open(file, 'r+b') as f: #LINE# #TAB# #TAB# #TAB# data = f.read() #LINE# #TAB# #TAB# #TAB# f.close() #LINE# #TAB# #TAB# #TAB# status = 0 #LINE# #TAB# else: #LINE# #TAB# #TAB# with open(file, 'rb') as f: #LINE# #TAB# #TAB# #TAB# data = json.load(f) #LINE# #TAB# #TAB# #TAB# f.close() #LINE# #TAB# return status"
"#LINE# #TAB# text = re.sub('---\\d+', '---', text) #LINE# #TAB# text = re.sub('---\\d+', '---', text) #LINE# #TAB# return text"
"#LINE# #TAB# #TAB# EXPIRED_MESSAGE = 'Expired oauth2 access token' #LINE# #TAB# #TAB# INVALID_MESSAGE = 'Invalid oauth2 access token' #LINE# #TAB# #TAB# if response.status_code == 400: #LINE# #TAB# #TAB# #TAB# try: #LINE# #TAB# #TAB# #TAB# #TAB# body = response.json() #LINE# #TAB# #TAB# #TAB# #TAB# if str(body.get('error_description')) in [EXPIRED_MESSAGE, #LINE# #TAB# #TAB# #TAB# #TAB# #TAB# INVALID_MESSAGE]: #LINE# #TAB# #TAB# #TAB# #TAB# #TAB# return True #LINE# #TAB# #TAB# #TAB# except: #LINE# #TAB# #TAB# #TAB# #TAB# pass #LINE# #TAB# #TAB# return False"
"#LINE# #TAB# if not s: #LINE# #TAB# #TAB# return '' #LINE# #TAB# if isinstance(s, str): #LINE# #TAB# #TAB# return s.encode('utf-8') #LINE# #TAB# return s"
"#LINE# #TAB# if not regex: #LINE# #TAB# #TAB# return urls #LINE# #TAB# for url in urls: #LINE# #TAB# #TAB# if not re.search(regex, url): #LINE# #TAB# #TAB# #TAB# yield url"
#LINE# #TAB# if not bs_terms or not bp_terms: #LINE# #TAB# #TAB# return True #LINE# #TAB# for term in bs_terms: #LINE# #TAB# #TAB# if term in bp_terms: #LINE# #TAB# #TAB# #TAB# return False #LINE# #TAB# return True
"#LINE# #TAB# for i in range(1, 100): #LINE# #TAB# #TAB# pass"
"#LINE# #TAB# function = LegacyFunctionSpecification() #LINE# #TAB# function.can_handle_array = True #LINE# #TAB# function.addParameter('burst', dtype='float64', direction=function.IN, #LINE# #TAB# #TAB# description='Burst and emit from center') #LINE# #TAB# function.addParameter('velocity', dtype='float64', direction=function.IN, #LINE# #TAB# #TAB# description='velocity in fixed angle') #LINE# #TAB# function.addParameter('random_speed', dtype='float64', direction=function.IN, #LINE# #TAB# #TAB# description='random speed') #LINE# #TAB# function.result_type = 'int32' #LINE# #TAB# return function"
"#LINE# #TAB# if ignore is None: #LINE# #TAB# #TAB# return None #LINE# #TAB# for item in os.listdir(path): #LINE# #TAB# #TAB# full_path = os.path.join(path, item) #LINE# #TAB# #TAB# if os.path.isdir(full_path) and foo(full_path, ignore): #LINE# #TAB# #TAB# #TAB# return None #LINE# #TAB# #TAB# if os.path.isfile(os.path.join(full_path, ignore)): #LINE# #TAB# #TAB# #TAB# return foo(full_path) #LINE# #TAB# return None"
"#LINE# #TAB# result = copy.deepcopy(input_toml) #LINE# #TAB# for key, value in result.items(): #LINE# #TAB# #TAB# if isinstance(value, dict): #LINE# #TAB# #TAB# #TAB# for sub_key, sub_value in value.items(): #LINE# #TAB# #TAB# #TAB# #TAB# result[key + '/' + sub_key] = sub_value #LINE# #TAB# #TAB# elif isinstance(value, list): #LINE# #TAB# #TAB# #TAB# for item in value: #LINE# #TAB# #TAB# #TAB# #TAB# result[key + '/' + item] = foo(item) #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# result[key] = value #LINE# #TAB# return result"
"#LINE# #TAB# if index > 0: #LINE# #TAB# #TAB# return '%s%s:' % (index, '.') #LINE# #TAB# return index"
"#LINE# #TAB# mag_spectrum = np.zeros(image.shape) #LINE# #TAB# if image.ndim == 2: #LINE# #TAB# #TAB# mag_spectrum[0, 0] = image[:, (0)] #LINE# #TAB# if image.ndim == 3: #LINE# #TAB# #TAB# mag_spectrum[1, 1] = image[:, (1)] #LINE# #TAB# return mag_spectrum"
"#LINE# #TAB# is_history = False #LINE# #TAB# if os.path.isfile(path): #LINE# #TAB# #TAB# try: #LINE# #TAB# #TAB# #TAB# with open(path, 'r') as fh: #LINE# #TAB# #TAB# #TAB# #TAB# is_history = fh.readline().strip() == 'history' #LINE# #TAB# #TAB# except IOError: #LINE# #TAB# #TAB# #TAB# pass #LINE# #TAB# if is_history: #LINE# #TAB# #TAB# return True #LINE# #TAB# else: #LINE# #TAB# #TAB# return False"
"#LINE# #TAB# if isinstance(exp, CommException): #LINE# #TAB# #TAB# if exp.status in ERROR_CODES: #LINE# #TAB# #TAB# #TAB# return ERROR_CODES[exp.status](exp.message) #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# return exp #LINE# #TAB# else: #LINE# #TAB# #TAB# return exp"
#LINE# #TAB# session = db.get_reader_session() #LINE# #TAB# user = session.query(User).filter_by(login=login_or_id).one() #LINE# #TAB# if user: #LINE# #TAB# #TAB# user.unlock() #LINE# #TAB# #TAB# return 'User locked' #LINE# #TAB# else: #LINE# #TAB# #TAB# return 'User not locked'
"#LINE# #TAB# deriv_first = np.diff(feature, axis=0) #LINE# #TAB# deriv_second = np.diff(feature, axis=0) #LINE# #TAB# return [deriv_first, deriv_second]"
"#LINE# #TAB# with open(in_file) as in_handle: #LINE# #TAB# #TAB# in_handle.readline() #LINE# #TAB# #TAB# try: #LINE# #TAB# #TAB# #TAB# res = json.loads(in_handle.readline()) #LINE# #TAB# #TAB# #TAB# return res['bounding_box'] #LINE# #TAB# #TAB# except ValueError: #LINE# #TAB# #TAB# #TAB# logging.error(""Couldn't parse {} to json."".format(in_file)) #LINE# #TAB# #TAB# #TAB# return None"
#LINE# #TAB# if type(_yaml_bool_value) == bool: #LINE# #TAB# #TAB# return True #LINE# #TAB# else: #LINE# #TAB# #TAB# return False
#LINE# #TAB# req.router.add_route('/static/foo') #LINE# #TAB# req.router.add_route('/static/foo') #LINE# #TAB# req.router.add_route('/static/foo2') #LINE# #TAB# req.router.add_route('/static/foo3') #LINE# #TAB# req.router.add_route('/static/foo4') #LINE# #TAB# req.router.add_route('/static/foo5') #LINE# #TAB# return req
#LINE# #TAB# try: #LINE# #TAB# #TAB# data = zk.get(topic) #LINE# #TAB# except KazooError as e: #LINE# #TAB# #TAB# if e.key == 'error': #LINE# #TAB# #TAB# #TAB# return None #LINE# #TAB# #TAB# elif e.key =='min-isr': #LINE# #TAB# #TAB# #TAB# return'min-isr' #LINE# #TAB# #TAB# else: #LINE# #TAB# #TAB# #TAB# raise #LINE# #TAB# else: #LINE# #TAB# #TAB# return data
"#LINE# #TAB# mins = np.isinf(values) | np.isnan(values) #LINE# #TAB# maxes = np.isinf(values) | np.isnan(values) #LINE# #TAB# min_values = values.min() #LINE# #TAB# if mines == values.min(): #LINE# #TAB# #TAB# mines = None #LINE# #TAB# if maxes == values.max(): #LINE# #TAB# #TAB# maxes = None #LINE# #TAB# return mins, max_values"
